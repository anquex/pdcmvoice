\documentclass[a4paper,14pt,openright]{report}

\usepackage[latin1]{inputenc}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{amsmath,amssymb,amsthm}
\usepackage[none]{hyphenat} 
\usepackage{float} % parametro H in figur : posizionamento esattamente li
\usepackage{verbatim}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage{algorithmic}
\usepackage[boxed]{algorithm}



\usepackage{fancyhdr}
\setcounter{tocdepth}{3}

\include{miei_comandi}
\frenchspacing
%\pagestyle{headings} % {headings,plain ,empty}
\linespread{1.3}
\DeclareGraphicsRule{.eps,.ps,.png}{bmp}{.bb}{} % formati utilizzabili con ordine di preferenza 
                                                % cosi non devo indicare le estensioni
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}


%\author{\emph{Marco Bettiol}\quad{} 586580\\\emph{Antonio Quercia}\quad{}  588537}

\title{}
\begin{document}

\include{mytitle}

\tableofcontents


\chapter{DFT}
La trasformata discreta di Fourier, talvolta chiamata anche \emph{trasformata di Fourier finita}, \`e la trasformata di Fourier di un segnale a tempo discreto e con \emph{dominio finito}. Come le altre trasformate di Fourier, essa esprime un segnale in termini di una somma di componenti sinusoidali, determinandone ampiezza e fase per ciascun componente. Tuttavia, la DFT si distingue dal fatto che la funzione d'ingresso \`e \emph{discreta e finita}: ossia \`e una sequenza finita di numeri reali o complessi, e questo fatto rende la DFT ideale per processare le informazioni memorizzate nei calcolatori. Nel seguito verranno discusse alcune applicazioni della DFT e come pu\`o essere efficientemente implementata in un calcolatore, attraverso algoritmi di \emph{FFT (Fast Fourier Transform)}.

\section{Definizione}

Un vettore $x$ di lunghezza N può essere visto come una sequenza $x_0,...,x_{N-1}$ di N numeri complessi. Si definisce $X$ \emph{trasformata discreta di Fourier (DFT, discrete Fourier transform)}  di $x$ la sequenza $X_0,...,X_{N-1}$ espressa dalla seguente relazione:
\begin{equation}
\label{eq:def-dft}
X_k=\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn} \quad k=0,...,N-1
\end{equation}
Ricordando la \emph{Formula di Eulero}

\begin{equation*} 
e^{\pm i 2\pi\omega x} = \cos( 2\pi \omega x) \pm i \sin(2\pi \omega x)
\end{equation*}
è evidente come, in generale, $X$ possa risultare in una sequenza complessa sebbene $x$ fosse reale.\\
La relazione inversa della \eqref{eq:def-dft}, chiamata \emph{trasformata discreta inversa di Fourier (IDFT, inverse discrete Fourier transform)} è data da:
\begin{equation}
x_n=\frac{1}{N}\sum_{k=0}^{N-1}X_ke^{\jmath\frac{2\pi}{N}kn} \quad k=0,...,N-1
\label{def_idft}
\end{equation}
Da \ref{def_idft} si può notare che i numeri complessi $X_k$ rappresentano l'ampiezza e la fase delle diverse componenti sinusoidali del "`segnale"' d'ingresso $x_n$.
\\Introduciamo quindi la seguente notazione per indicare DFT e IDFT
\begin{align*}
X &= \mathcal{F}x\\
x &= \mathcal{F}^{-1}X
\label{def_idft}
\end{align*}
e inoltre indichiamo esplicitamente con $x_N$ (pedice maiuscolo) un vettore $x$ $N$-dimensionale e con $X_N$ la sua trasformata.


%A normalization of 1/\sqrt{N} for both the DFT and IDFT makes the transforms unitary, which has some theoretical advantages, but it is often more practical in numerical computation to perform the scaling all at once as above (and a unit scaling can be convenient in other ways).

\section{Proprietà}

Descriviamo alcune delle proprietà più significative della DFT, ovvero consideriamo quelle proprietà che sono alla base delle applicazioni della DFT. Le prime proprietà discendono direttamente dalla definizione dell'operatore DFT e riguardano la linearità,la periodicità e la simmetria. La linearità viene utilizzata specialmente nelle applicazioni
in cui il vettore di cui bisogna calcolare la DFT si può decomporre nelle sue componenti armoniche e attraverso l'analisi della DFT di tali componenti si possono trarre informazioni significative sul vettore iniziale (questo è ad esempio il principio alla base dell'analisi armonica di funzioni periodiche). La proprietà di periodicità consente
di prolungare periodicamente il vettore di cui calcolare la DFT senza alterarne il risultato numerico. Infine la simmetria trova applicazione negli schemi di memorizzazione alla base degli algoritmi numerici per il calcolo di una DFT.\\
La maggior parte delle proprietà valide per la trasformata di Fourier a tempo continuo hanno un analogo equivalente anche per la DFT.\\ Il cambiamento più significativo da apportare ai teoremi per adattarli al caso finito-discreto è quello di modificare gli indici per tenere conto della periodicità della DFT, ovvero prendere gli indici modulo $\mathbf{N}$.

\noindent Date $X$ e $Y$ le DFT di $x$ e $y$ rispettivamente, valgono:

\begin{enumerate}[i.]
\item Completezza:\\
La DFT è una trasformazione \emph{lineare e invertibile}:
\begin{equation}
\mathcal{F} : \mathbb{C}^N\longrightarrow\mathbb{C}^N
\end{equation}
dove $\mathbb{C}$ è l'insieme complesso.
\[x\xrightleftharpoons[\mathcal{F}^{-1}]{\mathcal{F}} X \]
DFT e IDFT mappano vettori complessi $N$-dimensionali in vettori complessi $N$-dimensionali attraverso una corrispondenza biunivoca.

\item Ortogonalità:\\
I vettori $e^{\jmath \frac{2\pi}{N}kn}$ formano una \emph{base ortogonale} per l'insieme dei vettori complessi $N$-dimensionali:
\begin{equation}
\label{eq:dft-orthogonality}
\sum_{n=0}^{N-1}(e^{\jmath\frac{2\pi}{N} kn})(e^{-\jmath\frac{2\pi}{N}k'n})=N\delta_{kk'}
\end{equation}
dove $\delta_{kk'}$ \`e il delta di Kronecker. 
\[\delta_{kk'} = 
\begin{cases} 
1 & \text{if } k = k' \\
0 & \text{if } k \neq k'
\end{cases}\]
Questa condizione pu\`o essere sfruttata per ricavare la formula della IDFT dalla definizione di DFT.

\item Teorema di Parseval:\\
in generale per segnali ortognolali si ha che
\begin{equation}
\sum_{n=0}^{N-1}x_ny_n^*=\frac{1}{N}\sum_{k=0}^{N-1}X_kY_k^*
\end{equation}
se $y=x^*$ otteniamo il  \emph{teorema di Parseval}
\begin{equation}
\sum_{n=0}^{N-1}|x_n|^2=\frac{1}{N}\sum_{k=0}^{N-1}|X_k|^2
\end{equation}

\item Periodicità:\\
Se la relazione \ref{eq:def-dft} che definisce la DFT è valutata per tutti i $k$ interi anzichè soltanto $k=0,...,N-1$, allora la sequenza infinita risultante \`e un'\emph{estensione periodica} di periodo $N$ della DFT. Tale periodicità può essere mostrata direttamente dalla definizione:
\begin{eqnarray}
X_{k+N}&=&\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}(k+N)n}\\
&=&\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn}e^{-\jmath 2\pi n}\\
&=&\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn}\\
&=&X_k
\end{eqnarray}
dove si è utilizzato il fatto che $e^{-2\pi \jmath}=1$. Allo stesso modo pu\`o essere mostrato che la \ref{def_idft} porta a un'estensione periodica della IDFT.

\item Il \emph{Circular shift theorem}:\\
Moltiplicare $x_N$ per una fase lineare $e^{-\jmath\frac{2\pi}{N}nm}$, per un qualche $m$ intero, è equivalente ad uno shift circolare di $X_N$ di $m$ posizioni: $X_k$ diventa $X_{k-m}$, il cui pedice si deve intendere come \emph{modulo N}. Analogamente, uno shift circolare di $x_N$ corrisponde alla moltiplicazione di $X_N$ per una fase lineare.
\begin{equation}
se\;\mathcal{F}((x_n))_k=X_k
\end{equation}
\begin{equation}
allora\;\mathcal{F}((x_ne^{\jmath\frac{2\pi}{N}nm}))_k=X_{k-m}
\end{equation}
\begin{equation}
e\;\mathcal{F}((x_{n-m}))_k=X_ke^{-\jmath\frac{2\pi}{N}km}
\end{equation}

\item \emph{Linear Convolution Theorem}\\
Siano $x=x_N$ e $y=y_N$ due vettori arbitrari $N$-dimensionali e sia $z=x \ast y$, un vettore di $2N-1$ componenti ottenuto dalla convoluzione lineare $\ast$.\\ Allora,\\
\begin{equation}
	z_i=\sum_{j=\max\{0,i-N+1\}}^{\min\{i,N-1\}}{x_i y_{i-j}} \qquad 0\leq i \leq 2N-1
\end{equation}
\\
dove i limiti superiore e inferiore della sommatoria sono scelti in modo tale che $i$ e $i-j$ siano sempre nell'intervalllo $[0$ $N-1]$.
Possiamo calcolare la convoluzione lineare utilizzando la DFT nel seguente modo:\\
\begin{equation}	
	(z|0_1)= \mathcal{F}_{2N}^{-1}(\mathcal{F}_{2N} (x|0_{N}) \odot \mathcal{F}_{2N} (y|0_{N})
\end{equation}\\
dove $\odot$ indica il prodotto componente per componente e $(x|0_k)$ indica il vettore ottenuto estendendo il vettore $x_{N}$ con padding di $k$ zero in coda.

\item \emph{Cyclic Convolution Theorem}\\
Siano $x=x_N$ e $y=y_N$ due vettori arbitrari $N$-dimensionali, definiamo \emph{convoluzione ciclica} di $x$ e $y$, indicata con $x \circledast y$, il vettore w di $N$ componenti dato da:
\\
\begin{equation}
	w_i=\sum_{j=0}^{N-1}{x_i y_{(i-j) \mod N }} \qquad 0\leq i \leq N-1
\end{equation}
\\
Possiamo calcolare la convoluzione ciclica utilizzando la DFT nel seguente modo:\\
\begin{equation}	
	w= \mathcal{F}_{N}^{-1}(\mathcal{F}_{N} x \odot \mathcal{F}_{N} y)
\end{equation}\\
dove $\odot$ indica il prodotto componente per componente.

%
% Corollari convoluzione ciclica <--> lineare (pucci)
%
\end{enumerate}

\section{Definizione Matriciale}
Dalla definizione \eqref{eq:def-dft} di DFT emerge immadiatamente una interpretazione matriciale della \emph{trasformata discreta di Fourier} \\
\begin{equation}
X=\mathcal{F}(x) = F_N x
\end{equation}\\
con 
\begin{equation}
x=
\left(
\begin{array}{c}
x_0\\
x_1\\
...\\
x_{N-1}	
\end{array}\right)
\end{equation}
\vskip 5pt e\vskip 5pt
\begin{equation}
F_N=
\left(
\begin{array}{clrr}
\omega_N^{0\cdot0} & \omega_N^{0\cdot1} & ... & \omega_N^{0\cdot(N-1)}\\
\omega_N^{1\cdot0} & \omega_N^{1\cdot1} & ... & \omega_N^{1\cdot(N-1)}\\
      ...     &     ...       & ... &         ...\\
\omega_N^{(N-1)\cdot0} & \omega_N^{(N-1)\cdot1} & ... & \omega_N^{(N-1)\cdot(N-1)}	
\end{array}\right)
\end{equation}
Il termine 
\begin{equation}
\omega_N=e^{-\jmath \frac{2\pi}{N}}
\end{equation}
\`e una \emph{radice complessa N-esima dell'unita}.\\
L'elemento in posizione $(i,j)$ della matrice \`e $\omega_N^{ij}$, con $i,j=0,1,...,N-1$.\\

\noindent Analogamente è possibile esprimere la IDFT come:
\begin{equation}
x=\mathcal{F}^{-1}(X)=F_N^{-1}X
\end{equation}
Dove $F_N^{-1}$ \`e la \emph{matrice inversa} di $F_N$ e può essere facilmente ottenuta da $F$ attraverso
\begin{equation}
	F_N^{-1} =\frac{1}{N} F_N^{*}
\end{equation}
dove pertanto in posizione $(i,j)$ di $F_N^{-1}$ è presente il valore
 $\frac{1}{N}\omega_N^{-ij}$
 
Dalla proprietà \eqref{eq:dft-orthogonality} emerge che 
\begin{equation*}
	F_N^*F_N=N\cdot I
\end{equation*}
questo significa che le colonne di $F$ sono \emph{ortogonali}. Indicando con $F^j$ la j-esima colonna di $F_N$ possiamo scrivere:
\begin{align}
\mathbf{F}_N^*\mathbf{F}_N&=
\begin{bmatrix}
	\langle F^0, F^0\rangle & \left\langle F^0, F^1\right\rangle &\left\langle F^0, F^2\right\rangle & \cdots & \left\langle F^0, F^{N-1}\right\rangle\\
	\left\langle F^1, F^0\right\rangle & \left\langle F^1, F^1\right\rangle &\left\langle F^1, F^2\right\rangle & \cdots & \left\langle F^1, F^{N-1}\right\rangle\\
	\left\langle F^2, F^0\right\rangle & \left\langle F^2, F^1\right\rangle &\left\langle F^2, F^2\right\rangle & \cdots & \left\langle F^2, F^{N-1}\right\rangle\\
	\vdots &\vdots & \vdots & \ddots & \vdots \\
	\left\langle F^{N-1}, F^0\right\rangle & \left\langle F^{N-1}, F^1\right\rangle &\left\langle F^{N-1}, F^2\right\rangle & \cdots & \left\langle F^{N-1}, F^{N-1}\right\rangle\\
\end{bmatrix}\\
&=
\begin{bmatrix}
 N & 0 & 0 & ... & 0\\  0 & N & 0 & ... & 0\\  0 & 0 & N & ... & 0\\ \vdots &\vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & ... & N\\
\end{bmatrix} = N\cdot \mathbf{I}
\end{align}
Questo ci è utile per definire le versioni normalizzate  della DFT/IDFT con matrici unitarie
\begin{equation}
	\widetilde{F}_N=\frac{1}{\sqrt{N}} F_N  \qquad \qquad  \widetilde{F}_N^*=\frac{1}{\sqrt{N}} F_N^*
\end{equation}
Le matrici ortogonali (unitarie) sono infatti usate per garantire stabilità numerica e scarsa sensibilità agli errori di arrotondamento.\\
Riepiloghiamo brevemente alcune proprietà delle matrici ortogonali (unitarie):
\begin{itemize}
	\item $\left\|Sx\right\|_2=\left\|x\right\|_2 \qquad \forall x$
	\item $\left\|S\right\|_2=\left\|S^{-1}\right\|_2=1$
	\item $\left\|A\right\|_2=\left\|SAT\right\|_2 \qquad \forall S,T \quad \text{ortogonali (unitarie)}$
\end{itemize}
\subsection{Analogie tra DFT e IDFT}
Questa affinità tra $F_N$ e $F_N^{-1}$ mette in risalto come in realtà la procedura per il calcolo di DFT e IDFT sia esattamente la stessa a meno di minimi adattamenti.\\
In altre parole è possibile calcolare la IDFT attraverso lo stesso algoritmo di \emph{forward computation} della DFT attraverso un semplice preprocessing dell'input e moltiplicazione per un fattore di scala:
\begin{equation}
	\mathcal{F}^{-1}(\{x_n\})= \frac {1}{N}\mathcal{F}(\{x_{N-n}\})
\end{equation}
dove l'operazione effettuata sull'input risulta essere un \emph{inversione dell'input modulo $N$}:\vskip 5pt
\begin{equation}
\left(
\begin{array}{c}
x_0\\x_1\\x_2\\...\\x_{N-2}\\x_{N-1}\\
\end{array}\right)\longrightarrow
\left(
\begin{array}{c}
x_0\\x_{N-1}\\x_{N-2}\\...\\x_{2}\\x_{1}\\
\end{array}\right)
\end{equation}\vskip 5pt
Analogamente è possibile sfruttare la seguente proprietà per il calcolo della IDFT
\vskip 5pt
\begin{equation}	
	\mathcal{F}^{-1}\left( x \right) = \frac{1}{N}{(\mathcal{F} (x^*))}^*
	\label{eq:inverse_computing_rule}
\end{equation}
\vskip 5pt
coniugando l'input, applicando la DFT, coniugando l'output e quindi scalando.

\section{Segnali di durata finita: relazione tra trasformata di Fourier DTFT e DFT}

% CTFT Mitra 3.1.1
% DTFT M 3.2.1 3.2.2
% DFT intro pag 233, 5.3.1, (5.2.1) 5.3.2 5.3.3

In questo paragrafo si esaminerà la relazione fra la Discrete-Time Fourier Transform (DTFT) e la N-point DFT.

La DTFT  $X(e^{j\omega})$ di una sequenza $x[n]$ definita per $0 \leq n \leq N-1$ è data da:
\\
\begin{equation}
	X(e^{j\omega}) = \sum_{n=-\infty}^{\infty}{x_ne^{-j\omega n}} = \sum_{n=0}^{N-1}{x_ne^{-j\omega n}}
\end{equation}
\\
Campionando uniformemente $X(e^{j\omega})$ su N frequenze $\omega_k = \frac{2\pi k}{N} , 0 \leq k \leq N-1$, con $0 \leq \omega \leq 2\pi$, si ottiene
\\
\begin{equation}
\label{eq:dtft-campionamento}
	X(e^{j\omega})| _{\omega=\frac{2\pi k}{N}} = \sum_{n=0}^{N-1}{x_ne^{-j\frac{2\pi k}{N} n}} ,\qquad 0 \leq k \leq N-1
\end{equation}
\\
Confrontando la definizione di DFT (1.1)%\eqref{eq:def-dft}
\begin{equation*}
X_k=\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi k}{N}n} \quad k=0,...,N-1
\end{equation*}
con la \eqref{eq:dtft-campionamento}, è possibile osservare che la N-point DFT $X_k$ corrisponde esattamente alla DFTF $X(e^{j\omega})$ campionata  sulle frequenze $\omega_k = \frac{2\pi k}{N} , 0 \leq k \leq N-1$; di conseguenza la frequenza angolare $\omega$ associata all'elemento di indice $k$ è $\frac{2\pi k}{N}$.

La DFT costituisce un valido metodo per il calcolo della DTFT di una sequenza finita, in particolar modo se sono disponibili algoritmi efficienti (FFT) per la sua determinazione.

Si consideri di voler valutare $X(e^{j\omega})$, la DFTF di una sequenza $x_n$ di lunghezza N su un insieme più denso di frequenze $\omega _k=\frac{2\pi k}{M}, 0 \leq k \leq M-1$, dove $M>>N$:
\\
\begin{equation}
\label{eq:dtft-x-estesa-1}
	X(e^{j\omega _k}) = \sum_{n=0}^{N-1}{x_ne^{-j\omega _k n}} = \sum_{n=0}^{N-1}{x_ne^{-j\frac{2\pi k}{M} n}}
\end{equation}
\\
\'E possibile definire la sequenza $x_n^e$ ottenuta eseguendo su $x_n$ uno zero-padding di lunghezza $M - N$:

\begin{equation*}
\label{eq:dtft-x-estesa-2}
x_n^e = 
\begin{cases} 
x_n \qquad 0 \leq n \leq N-1 \\
0 \qquad N \leq n \leq M-1
\end{cases}
\end{equation*}
Tenendo in considerazione che le sequenze $x_n$ e $x_n^e$ sono definite su domini differenti, facendo uso della definizione di $x_n^e$ si giunge a:
\\
\begin{equation}
\label{eq:dtft-x-estesa-3}
	X(e^{j\omega _k}) = \sum_{n=0}^{M-1}{x_n^e e^{-j\frac{2\pi k}{M} n}} = X_k^e
\end{equation}
\\
che corrisponde alla M-point DFT $X_k^e$ (della sequenza $x_n^e$ di lunghezza M), che può essere facilmente calcolata avvalendosi della FFT se M è potenza di 2.
\\
\\
\textbf{DFTF come interpolazione della DFT}
\\
\\
Data la N-point DFT $X_k$ di una sequenza $x_n$ di lunghezza n è possibile determinare la DTFT $X(e^{j\omega})$ eseguendo l'operazione di intepolazione sui valori di  $X_k$.
Dalla definizione di DTFT
\\
\begin{equation}
\label{eq:dtft-def}
	X(e^{j\omega}) = \sum_{n=0}^{N-1}{x_n e^{-j\omega n}}
\end{equation}
\\
e dalla definizione di IDFT (1.2)
\\
\begin{equation*}
	x_n=\frac{1}{N}\sum_{k=0}^{N-1}X_ke^{\jmath\frac{2\pi}{N}kn}
\end{equation*}
\\
è possibile ricavare
\begin{eqnarray}
\label{eq:dft-interpolation-1}
	X(e^{j\omega}) &=& \sum_{n=0}^{N-1}{\left[\frac{1}{N}\sum_{k=0}^{N-1}X_ke^{\jmath\frac{2\pi}{N}kn}\right] e^{-j\omega n}}\\
	&=& \frac{1}{N}\sum_{k=0}^{N-1}{X_k \sum_{n=0}^{N-1}{e^{\jmath\frac{2\pi}{N}kn} e^{-j\omega n}}}
\end{eqnarray}
\\
Riscrivendo la parte destra della relazione precedente utilizzando la seguente proprietà
\\
\begin{equation*}
	\sum_{n=0}^{N-1}u^n = \frac{1-u^N}{1-u}
\end{equation*}
\\
si ottiene
\\
\begin{eqnarray}
\label{eq:dft-interpolation-2}
	\sum_{n=0}^{N-1}{e^{\jmath\frac{2\pi}{N}kn} e^{-j\omega n}} &=& \frac{1-e^{-j(\omega N-2\pi k)}}{1-e^{-j[\omega -(2\pi k/N)]}}
	\\
	&=& \frac{e^{-j[(\omega N-2\pi k)/2]}}{e^{-j[(\omega N-2\pi k)/2N)]}} \frac{\sin(\frac{\omega N-2\pi k}{2})}{\sin(\frac{\omega N-2\pi k}{2N})}
	\\
	&=& \frac{\sin(\frac{\omega N-2\pi k}{2})}{\sin(\frac{\omega N-2\pi k}{2N})} e^{-j[\omega -(2\pi k/N)][(N-1)/2]}
\end{eqnarray}
\\
Sostituendo la \eqref{eq:dft-interpolation-2} nella \eqref{eq:dft-interpolation-1} si giunge a
\\
\begin{equation}
\label{eq:dft-interpolation-3}
	X(e^{j\omega}) = \frac{1}{N}\sum_{k=0}^{N-1}{X_k \frac{\sin(\frac{\omega N-2\pi k}{2})}{\sin(\frac{\omega N-2\pi k}{2N})} e^{-j[\omega -(2\pi k/N)][(N-1)/2]} }
\end{equation}
\\
che può essere riscritta come
\\
\begin{equation}
\label{eq:dft-interpolation-4}
	X(e^{j\omega}) = \sum_{k=0}^{N-1}{X_k \phi(\omega -\frac{2\pi k}{N}) }
\end{equation}
\\
definendo
\\
\begin{equation}
\label{eq:dft-interpolation-5}
	\phi(\omega) = \frac{1}{N} \frac{\sin(\frac{\omega N}{2})}{\sin(\frac{\omega}{2})} e^{-j\omega[(N-1)/2]}
\end{equation}
\\
E' possibile verificare che
\\
\[\phi(\omega)|_{\omega=2\pi k/N} =  
\begin{cases} 
1 k = 0 \\
0 1 \leq k \leq N-1
\end{cases}\]
\\
e di conseguenza
\\
\begin{equation*}
	X(e^{j\omega})| _{\omega=2\pi k/N} = X_l \qquad 0 \leq k \leq N-1
\end{equation*}
\\
In definitiva è possibile ottenere $X(e^{j\omega})$ al variare di $\omega$ in $\mathbb{R}$ considerando gli elementi della DFT $X_k$ come i valori di $X(e^{j\omega})$ in \$omega = $ 2 \pi k \setminus N$, $0 \leq k \leq N-1$ e considerando, per gli altri valori di $\omega$, il risultato dell'interpolazione \eqref{eq:dft-interpolation-3}

\chapter{Calcolo della DFT}

La diffusione nell'utilizzo della DFT è principalmente dovuta all'introduzione, avvenuta negli anni '60, di una classe di algoritmi computazionale efficienti per la sua valutazione: la \emph{(Fast Fourier Transform, i.e. trasformata veloce di Fourier)}.\\ Essa rende possibile in taluni casi l'elaborazione in tempo reale (sistemi di navigazione, trasmissione e processo di segnali vocali o televisivi) e consente di risolvere alcuni problemi di grandi dimensioni che risulterebbero altrimenti intrattabili.\\
L'FFT viene normalmente attribuita a Cooley e Tukey. Di fatto questo particolare algoritmo venne scoperto (ed usato) da Gauss nel XIX secolo. Pare che in realtà l'algoritmo sia stato riscoperto ed utilizzato varie volte (anche prima del lavoro di Cooley e Tuckey menzionato sopra).
Grazie alla FFT, infatti, è possibile implementare al calcolatore operazioni nel dominio della frequenza, cioè utilizzando le trasformate di Fourier, con complessità di calcolo inferiore a quella ottenibile implementando lo stesso calcolo nel dominio del tempo.\\
\newpage
\section{Attraverso la definizione}
La tecnica di calcolo banale passa per la definizione stessa di DFT
\begin{equation*}
X_k=\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn} \quad k=0,...,N-1
\end{equation*}
ed essendo 
\begin{equation*}
\mathcal{F} : \mathbb{C}^N\longrightarrow\mathbb{C}^N
\end{equation*}
ci sono $N$ termini da calcolare, ognuno dei quali richiede $N$ moltiplicazioni e $N-1$ addizioni complesse. Anche evidando di calcolare le moltiplicazioni per $\omega_{N}^{0}=1$ si devono comunque effettuare in totale $2(N-1)^2$ operazioni complesse. Il costo è pertanto $O(N^2)$

Nel dettaglio ogni moltiplicazione complessa $\lambda = z_1 \cdot z_2 = (a + jb) \cdot (c + jd)$ si sviluppa in 
\begin{align*}
m1 &= (a + b) \cdot c\\
m2 &= (d + c) \cdot b\\
m3 &= (d - c) \cdot a\\
\rm{Re}(\lambda) &= m1 - m2\\
\rm{Im}(\lambda) &= m1 + m3\\
\end{align*}
richiedendo 4 moltiplicazioni reali e 2 addizioni e pertanto il numero di operazioni macchina totali risultante è $4(N-1)^2$ moltiplicazioni e $2N(N-1)+2(N-1)^2= 2(N-1)(2N-1)$ addizioni.

Nel modello di calcolo da noi considerato assumeremo, come effettivamente si verifica per i moderni apparecchi di calcolo, che il tempo impiegato per effetuare una addizione o moltiplicazione sia lo stesso.

Inoltre, poichè nel caso della FFT, tutte le moltiplicazioni complesse coinvolgono un "`twiddle factor"' $\omega_N^l = c + jd$, e un ulteriore termine è possibile precalcolare, oltre che precalcolarli è possibile salvarsi anche i risultati intermedi $c+d$ e $c-d$ in modo che una moltiplicazione complessa richeda solo $5$ operazioni totali. 

%Un'altra scomposizione che può risultare vantaggiosa è $(a+jb)(c+jd)=a(c+d)-d(a+b)+j[a(c+d)+c(b-a)]$
%3 moltiplicazioni e 5 addizioni reali.
%As noted earlier, most high-performance workstations can perform multiplications as additions
%fast as additions

\section{Algoritmi sequenziali per il calcolo di FFT}
Sia $T(N)$ il tempo di calcolo associato ad un problema di cardinalità $N$ e supponiamo per semplicità $N=2^\nu$.\\
Se partizioniamo gli $N$ dati in due sottoinsiemi di $N/2$ dati:
\begin{equation}
	N \longrightarrow \frac{N}{2} + \frac{N}{2},
\end{equation}
risolviamo i due sottoproblemi e ricombiniamo le due soluzioni, il tempo di calcolo diviene:
\begin{equation}	
	T(N) = 2 \cdot T\left(\frac{N}{2}\right)+ R(N)
\end{equation}
con $R(N)$ pari al costo di combinazione. Allo stesso risultato si arriva se $R(N)$ rappresenta il costo di costruzione e/o ricombinazione dei due sottoproblemi.

Non è difficile verificare che se $R(N)= O(N)$, cioè il costo di ricombinazione è lineare nei dati e si itera il procedimento fino ad $N$ sottoinsiemi di un solo dato, il tempo di calcolo relativo alla procedura diventa:
\begin{equation}
	T(N) = O(N \cdot \log_2(N))
\end{equation}
qualsiasi sia la complessita di calcolo originale $T(N)$, purchè di tipo polinomiale, cioè del tipo
\begin{equation}
T(N) = O(N^\alpha), \quad \alpha \in \mathbb{R}
\end{equation}
Ovviamente, minore è la complessità originaria (quindi l'esponente $\alpha$) e più piccolo sarà il tempo di calcolo al quare si arriva applicando il principio \emph{"`divide et impera"'}; in ogni caso, comunque, esso sarà dell'ordine di $N \cdot \log_2 N$

Osserviamo inoltre che il principio \emph{"`divide et impera"'} conduce spontaneamente a strutture di calcolo parallele. Con $N=2_\nu$, le partizioni dei dati più efficienti sono le più "`spontanee"', e sono "`schematizzate"' nella figura seguente per $N=8$
\vskip 30pt
\begin{figure}[h!]
  \centering
      \includegraphics[width=\textwidth]{immagini/tipi_algoritmi}
  \caption{Tipologie di FFT}
\end{figure}
%\includegraphics[scale=0.35]{tipi_algoritmi}
\vskip 10pt

\subsection{Cooley-Tukey Algorithm - DIT}

Il calcolo della DFT utilizzando la definizione richiede tempo $O(N^2)$, come \`e facilmente verificabile. Molti sono gli algoritmi studiati e progettati per ridurre questa complessit\`a computazionale.\\La DFT calcolata secondo questi algoritmi prende il nome di \textbf{Fast Fourier Transform} o \textbf{FFT}.\\Tra gli algoritmi studiati uno dei pi\`u famosi \`e l'algoritmo noto come Algoritmo di Cooley-Tukey con una delle sue implementazioni pi\`u frequenti che si articola in cinque fasi.\\

Dato un vettore $\mathbf{X}\in{}\mathbb{C}^n$, le cinque fasi dell'algoritmo di CT sono cos\`i articolate:
\begin{itemize}
\item Fase 1: il vettore di ingresso viene riorganizzato in forma matriciale pxq secondo un ordinamento row-major. Tipicamente o p o q \`e un fattore piccolo, non necessariamente primo, che \`e chiamato radice.\\Nelle pi\`u comuni implementazioni la DFT calcolata con l'algoritmo di Cooley-Tukey \`e di \textbf{radice 2} e, in particolare, se q \`e uguale a 2 si parla di decimazione in frequenza mentre se p \`e uaguale a 2 si parla di \textbf{decimazione nel tempo}.
\item Fase 2: q FFT vengono calcolate ricorsivamente sulle colonne della matrice ottenuta.
\item Fase 3: gli elementi della matrice risultante vengono moltiplicati per i twiddle factors, in particolare l'elemento di indice (i,j) viene moltiplicato per il fattore $\omega_n^{ij}$ ($i, j = 0,\ldots{},N-1$).
\item Fase 4: p FFT vengono calcolate ricorsivamente sulle righe della matrice risultante.
\item Fase 5: gli elementi della matrice vengono letti in ordine column-major al fine di ottenere il vettore finale.
\end{itemize}

Questo algoritmo \`e in grado di ridurre la complessit\`a computazionale a $O(Nlog_2N)$.\\

Gli algoritmi di decimazione radix-2 nel tempo si costituiscono a partire dalla seguente scomposizione ricorsiva.\\
Consideriamo un vettore $x$ di lunghezza $N=2^\nu$. Dividiamo i valori in ingresso in elementi di posizione pari e dispari\\
\[n = 
\begin{cases} 
2 \cdot r \\
2 \cdot r +1
\end{cases}\]

\subsubsection{Schema di scomposizione}

Sapendo che $\omega_N^2= \omega_{\frac{N}{2}}$, la componente $X_k$ della DFT può essere espressa come
\setlength{\jot}{17pt}{{\begin{align} 
X_k &=\sum_{n=0}^{N-1}x_n \omega_N^{nk} \qquad \text{con}\quad \omega_N=e^{-\jmath\frac{2\pi}{N}} \\
\label{eq:cooley-tukey-sommatorie-1}
&=\sum_{r=0}^{N/2-1}x_{2r} \omega_N^{2rk} + \sum_{r=0}^{N/2-1}x_{2r+1} \omega_N^{(2r+1)k}\\
\label{eq:cooley-tukey-sommatorie-2}
&=\underbrace{\sum_{r=0}^{N/2-1}x_{2r} \omega_{\frac{N}{2}}^{rk}}_{X_{even}} + \omega_N^{k} \underbrace{\sum_{r=0}^{N/2-1}x_{2r+1} \omega_{\frac{N}{2}}^{rk}}_{X_{odd}}\\
&=X_{even} \quad +\quad \omega_N^{k} \cdot X_{odd} \qquad k=0,1, ..., N-1
\end{align}}

Entrambe le sommatorie in \eqref{eq:cooley-tukey-sommatorie-2} possono quindi essere interpretate come DFT di taglia $N/2$: la prima coinvolge gli elementi in posizione pari $\{x_{2k}|k=0,1,...,N/2-1\}$ mentre la seconda gli elementi in posizione dispari $\{x_{2k+1}|k=0,1,...,N/2-1\}$. Ci siamo quindi ricondotti a due sottoproblemi analoghi a quello di partenza ma di daglia dimezzata.\\
Definiendo $y_r=x_{2r}$ e $z_r=x_{2r+1}$ e quindi le rispettive DFT
\begin{equation}
	Y_{k}=\sum_{r=0}^{\frac{N}{2}-1} y_r \omega_{\frac{N}{2}}^{rk}, \qquad k=0,1,...,N/2-1
\end{equation}
e
\begin{equation}
	Z_{k}=\sum_{r=0}^{\frac{N}{2}-1} z_r \omega_{\frac{N}{2}}^{rk}, \qquad k=0,1,...,N/2-1
\end{equation}
dopo che la soluzione di questi due problemi è stata ricorsivamente calcolata è possibile calcolare i primi $N/2$ termini di $X$ attraverso
\begin{equation}
\label{eq:CT-X_even}
	X_k= Y_k+\omega_N^k Z_k, \qquad k=0,1,...,N/2-1 
\end{equation}
e utilizzando il fatto che $\omega_N^{\frac{N}{2}+k}=-\omega_N^{k}$ e $\omega_{\frac{N}{2}}^{\frac{N}{2}}=1$, i rimanenti termini sono dati da:
\begin{align}
X_{k+\frac{N}{2}} &= \sum_{r=0}^{\frac{N}{2}-1} y_r \omega_{\frac{N}{2}}^{(r+\frac{N}{2})k}+\omega_{N}^{(k+\frac{N}{2})} \sum_{r=0}^{\frac{N}{2}-1} z_r \omega_{\frac{N}{2}}^{(r+\frac{N}{2})k}\\
&= \sum_{r=0}^{\frac{N}{2}-1} y_r \omega_{\frac{N}{2}}^{rk}+\omega_{N}^{k} \sum_{r=0}^{\frac{N}{2}-1} z_r \omega_{\frac{N}{2}}^{rk}\\
\label{eq:CT-X_odd}
&= Y_k-\omega_N^k Z_k, \qquad k=0,1,...,N/2-1
\end{align}
Solitamente le relazioni di calcolo espresse in \eqref{eq:CT-X_even} e \eqref{eq:CT-X_odd} sono graficamente rappresentate in un grafo computazione come \emph{"`Cooley-Tukey butterly"'}

\begin{figure}[h!]
  \centering
      \includegraphics[width=0.5\textwidth]{immagini/cooley-tukey-butterfly}
  \caption{Cooley-Tukey butterfly}
\end{figure}

\subsubsection{Complessità}
Il costo di ricombinazione è dato da $3N$ dovuto alla moltiplicazione per il "`twiddle factor"' e $2N$ dovuto alle somme. Pertanto risulta
\[T(N) =
\begin{cases} 
2T(\frac{N}{2}) + 5N & \text{se } N\geq 2 \\
0 & \text{se } N=1 
\end{cases}\]
e quindi
\begin{equation}
	T(N)= 5N\log(N)
\end{equation}

%!COMPLETARE!
%
% vedere se completare qui o dedicargli più spazio
% cooley-tukey N=pq paragrafo a parte?
%
%
 
\subsection{Gentleman-Sande Algorithm - DIF}
Una strategia leggermente diversa da quella dello schema di Cooley e Tukey sta alla base la versione dell'algoritmo FFT radix-2 introdotta da Gentleman e Sande. Tale variante si basa sul decomporre ripetutamente il vettore DFT da calcolare. Si osserva che le componoenti con indice pari della DFT si possono esprimere come una DFT di lunghezza $N/2$ costruita a partire da un vettore ottenuto combinando le componenti del vettore di input che distano di $N/2$. Analogo ragionamento si fa per le componenti con indice dispari della DFT da calcolare.

\subsubsection{Schema di scomposizione}
Se dividiamo gli $N=2^\nu$ elementi di $x_N$ nelle due sotto sequenze $x_{head}=(x_0,x_1,...,x_{\frac{N}{2}-1})$ e $x_{tail}=(x_{\frac{N}{2}},x_{\frac{N}{2}+1},...,x_{N-1})$, la DFT di $x_N$ si può scrivere nella forma

\setlength{\jot}{17pt}{\begin{align} 
X_k &=\sum_{n=0}^{N-1}x_n \omega_N^{nk} \qquad \text{con}\quad \omega_N=e^{-\jmath\frac{2\pi}{N}} \\
&=\sum_{n=0}^{N/2-1}x_n \omega_N^{nk} + \sum_{n=N/2-1}^{N-1}x_{n} \omega_N^{nk} \qquad \text{per} \quad n'=n-\frac{N}{2}\\
\label{eq:dft-dif-div}
&=\sum_{n=0}^{N/2-1}x_n \omega_N^{nk} + \sum_{n'=0}^{N/2-1}x_{\frac{N}{2}+n'} \omega_N^{(\frac{N}{2}+n')k} \qquad  \quad \omega_N^{\frac{N}{2}k}= (-1)^k\\
&=\sum_{n=0}^{N/2-1}\left[x_n  + (-1)^k x_{\frac{N}{2}+n}\right]\omega_N^{nk}
\end{align}}

Notiamo che la \eqref{eq:dft-dif-div} non è una DFT su $N/2$ punti in quanto è presente il termine $\omega_N^{nk}$ invece di $\omega_{\frac{N}{2}}^{nk}$

Procedendo separatamente con il calcolo dei valori di $X_k$ di posto pari $\left((-1)^K=1\right)$ e dispari $\left((-1)^K=-1\right)$ si ottiene


\setlength{\jot}{17pt}{\begin{align} 
X_{2r} &=\sum_{n=0}^{N/2-1}\left[\underbrace{x_n  + x_{\frac{N}{2}+n}}_{y_{n}}\right] \omega_{N/2}^{rn} \qquad r=0,1,...,N/2-1\\
X_{2r+1} &=\sum_{n=0}^{N/2-1}\left[(\underbrace{x_n  - x_{\frac{N}{2}+n}}_{z_{n}}) \omega_{N}^{n} \right] \omega_{N/2}^{rn}
\end{align}}

Il calcolo della DFT su $N=2^\nu$ punti viene quindi ricondotto a

\begin{enumerate}
	\item il calcolo di due segnali di lunghezza $N/2$ corrispondenti rispettivamente alla somma di $x_{head} +x_{tail}$ e alla differenza $x_{head}-x_{tail}$
	\setlength{\jot}{17pt}{\begin{align} 
	y_{n}&=x_{n}+x_{\frac{N}{2}+n} \qquad n=0,1,...,N/2-1\\
	z_{n}&=x_{n}-x_{\frac{N}{2}+n}
	\end{align}}
	che corrisponde a $N/2$ DFT su coppie punti, [$x_{n}$ $x_{\frac{N}{2}+n}$]. Infatti
	
			\begin{equation}
		F_2=
		\left(
		\begin{array}{cr}
		1 & 1\\1 & -1	
		\end{array}\right)
		\end{equation}
	\item alla moltiplicazione di $z_{n}$ per $\omega_{N}^{n}$
	\item al calcolo di due DFT su $N/2$ punti, una su $y_{n}$ e l'altra su $z_{n}\omega_{N}^{n}$
\end{enumerate}

Con l'algoritmo DIF quindi si precondizionano i dati dei due blocchi di lunghezza $N/2$ in modo che una trasformata su $N/2$ dati dia i valodi di $X_k$ per $k$ pari e l'altra sempre su $N/2$ dati dia i valori di $X_k$ per $k$ dispari.
Tutto il lavoro è quindi effettuato nel passo \emph{"`divide"'} che richiede di effettuare somma e sottrazione di coppie e moltiplicazione per il \emph{"`twiddle factor"'} mentre il passo \emph{"`conquer"'} è banale poichè l'output delle due trasformate, prese "`alternativamente"',fornisce immediatamente la trasformata dell'ingresso originale.

Solitamente il passo di suddivisione è graficamente rappresentato in un grafo computazione come \emph{"`Gentleman-Sande butterly"'}

\begin{figure}[h!]
  \centering
      \includegraphics[width=0.5\textwidth]{immagini/gentleman-sande-butterfly}
  \caption{Gentleman-Sande butterfly}
\end{figure}

\subsubsection{Complessità}

Il passo di suddivisione richiede $N$ addizioni complesse e $N/2$ moltiplicazioni complesse e pertanto anche in questo caso la complessità risulta $T(N)= 5N\log(N)$.
%!COMPLETARE!
%
% Manca analisi della complessità, dire che si usa sempre la radice N-esima dell'unità e che l'output è non ordinato (vedi slide), vedi mian pg 173
%
%
%
\subsection{Split-radix Algorithm}
L'idea che sta alla base dell'algoritmo Split-radix è quella di usare la decomposizione radix-2 e radix-4 contemporaneamente, ovvero il problema iniziale di taglia $N$ viene scomposto in un problema di taglia $N/2$ e 2 problemi di taglia $N/4$. La scomposizione di seguito è della tipologia DIT.

\subsubsection{Schema di scomposizione}
\begin{align}
X_r &= \sum_{l=0}^{N-1}{x_l\omega_N^{rl}}, \qquad r=0,1,...,N-1\\
&=\sum_{k=0}^{\frac{N}{2}-1}{x_{2k}\omega_N^{r(2k)}}+\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+1}\omega_N^{r(4k+1)}}+\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+3}\omega_N^{r(4k+3)}}\\
&=\sum_{k=0}^{\frac{N}{2}-1}{x_{2k}\omega_N^{r(2k)}}+\omega_N^{r}\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+1}\omega_N^{r(4k)}}+\omega_N^{3r}\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+3}\omega_N^{r(4k)}}
\end{align}
$x_N$ è quindi scomposto in 3 sottosequenze: $\{y_k|y_k= x_{2k}, 0\leq k \leq N/2-1\}$ , 
$\{z_k|z_k= x_{4k+1}, 0\leq k \leq N/4-1\}$ , $\{h_k|h_k= x_{4k+3}, 0\leq k \leq N/4-1\}$ e sono definiti 3 sotto problemi sfruttando il fatto che $\omega_{\frac{N}{2}} = \omega_{N}^2$ e
$\omega_{\frac{N}{4}}= \omega_{N}^4$

\begin{equation}
Y_r=\sum_{k=0}^{\frac{N}{2}-1}{x_{2k}\omega_{N}^{r(2k)}} =\sum_{k=0}^{\frac{N}{2}-1}{x_{2k}{(\omega_{N}^{2})}^{rk}} =\sum_{k=0}^{\frac{N}{2}-1}{y_{k}\omega_{\frac{N}{2}}^{rk}}, \qquad r=0,1,... ,N/2-1
\end{equation}

\begin{equation}
Z_r=\sum_{k=0}^{\frac{N}{2}-1}{x_{4k+1}\omega_{N}^{r(4k)}} =\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+1}{(\omega_{N}^{4})}^{rk}} =\sum_{k=0}^{\frac{N}{4}-1}{z_{k}\omega_{\frac{N}{4}}^{rk}}, \qquad r=0,1,... ,N/4-1
\end{equation}

\begin{equation}
H_r=\sum_{k=0}^{\frac{N}{2}-1}{x_{4k+3}\omega_{N}^{r(4k)}} =\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+3}{(\omega_{N}^{4})}^{rk}} =\sum_{k=0}^{\frac{N}{4}-1}{h_{k}\omega_{\frac{N}{4}}^{rk}}, \qquad r=0,1,... ,N/4-1
\end{equation}

dopo che ognuno dei tre sottoproblemi è stato risolto, ricordando che $Y_r$ è periodico di periodo $N/2$ e $Z_r$ e $H_R$ sono periodici di  $N/4$, la soluzione al problema originale di taglia N può essere ottenuta come:

\begin{align}
\label{eq:split-radix-conquer-1}
X_r &= Y_r+\omega_N^rZ_r+\omega_N^{3r}H_r \nonumber \\ 
&= Y_r+\left(\omega_N^rZ_r+\omega_N^{3r}H_r\right), \qquad 0\leq r\leq\frac{N}{4}-1,\\
\label{eq:split-radix-conquer-2}
X_{r+\frac{N}{4}} &= Y_{r+\frac{N}{4}}+\omega_N^{r+\frac{N}{4}}Z_r+\omega_N^{3({r+\frac{N}{4}})}H_r \nonumber\\
&= Y_{r+\frac{N}{4}}- j\left(\omega_N^{r}Z_r-\omega_N^{3r}H_r\right), \qquad 0\leq r\leq\frac{N}{4}-1,\\
\label{eq:split-radix-conquer-3}
X_{r+\frac{N}{2}} &= Y_{r}+\omega_N^{r+\frac{N}{2}}Z_r+\omega_N^{3({r+\frac{N}{2}})}H_r \nonumber\\
&= Y_{r}-\left(\omega_N^{r}Z_r+\omega_N^{3r}H_r\right), \qquad 0\leq r\leq\frac{N}{4}-1,\\
\label{eq:split-radix-conquer-4}
X_{r+\frac{3N}{4}} &= Y_{r+\frac{N}{4}}+\omega_N^{r+\frac{3N}{4}}Z_r+\omega_N^{3({r+\frac{3N}{4}})}H_r \nonumber\\
&= Y_{r+\frac{N}{4}}+ j\left(\omega_N^{r}Z_r-\omega_N^{3r}H_r\right), \qquad 0\leq r\leq\frac{N}{4}-1,
\end{align}

Le relazioni espresse in \eqref{eq:split-radix-conquer-1} \eqref{eq:split-radix-conquer-2} \eqref{eq:split-radix-conquer-3} \eqref{eq:split-radix-conquer-4} sono solitamente rappresentate in un grafo computazione come \emph{"`unsymmetric DIT split-radix butterly"'}
\vskip 10pt
\begin{figure}[h!]
  \centering
      \includegraphics[width=\textwidth]{immagini/split-radix-dit-butterfly}
  \caption{split-radix butterfly}
\end{figure}
Proprio questa struttura irregolare dello split-radix, sebbene non comporti problemi per le implementazioni sequenziali, rende molto difficile l'organizzazione del calcolo su sistemi paralleli.
%http://cnx.org/content/m12031/latest/#Bruun
       

\subsubsection{Complessità}
Essendo $Z_r$ e $H_r$ di taglia $N/4$ il calcolo dei prodotti $\omega_N^rZ_r$ e $\omega_N^{3r}H_r$ richiede in totale $N/2$ moltiplicazioni complesse e le somme parziali in \eqref{eq:split-radix-conquer-1} \eqref{eq:split-radix-conquer-2} \eqref{eq:split-radix-conquer-3} \eqref{eq:split-radix-conquer-4} richiedono in totale altre $N/2$ addizioni complesse.\\
Sfruttando le proprietà delle radici $\omega_N^{0}$, $\omega_N^{\pm\frac{N}{2}}$,$\omega_N^{\pm\frac{N}{4}}$, $\omega_N^{\pm\frac{N}{8}}$ $\omega_N^{\pm\frac{3N}{8}}$ è possibile ridurre ulteriormente il numero di moltiplicazioni complesse.\\
Riassumendo, il costo computazionale complessivo di una chiamata risorsiva è di $6N-16$ operazioni
Otteniamo quindi la relazione
\[T(N) =
\begin{cases} 
T(\frac{N}{2}) + 2T(\frac{N}{4})+6N-16 & \text{se } N=4^\nu > 4 \\
16 & \text{se } N=4\\
4 & \text{se } N=2\\ 
\end{cases}\]

\noindent e che, risolvendo, fornisce
\begin{equation}
	T(N)= 4N\log(N) -6N +8
\end{equation}
Il guadagno asintotico rispetto alle implementazioni radix-2 è quindi circa del 25\%.
\subsection{Altri Algoritmi}

\subsubsection*{Goertzel's Algorithm} %fft-lecture.pdf
Questo algoritmo, implementato come filtro IIR, è utilizzato in DSP quando si è interessati a conoscere solo alcune delle componenti in frequenza $X_k$ di una sequenza $x_N$

\begin{align*}
	X_{k} &\stackrel{\text{\emph{def}}}{=} \sum_{n=0}^{N-1} x[n] \omega_N^{nk} = 1 \cdot \sum_{n=0}^{N-1} x[n] \omega_N^{nk}, \quad \text{con}\quad \omega_N^{-kN}=1\\
	&= \omega_N^{-kN} \sum_{n=0}^{N-1} x[n] \omega_N^{nk} = \sum_{n=0}^{N-1} x[n] \omega_N^{-k(N-n)}\\
	\left.y_k[n]\right|_{n=N}&= \left.\left[x[n]\ast \left( \omega_N^{-nk} u[n]\right)\right]\right|_{n=N}
\end{align*}
che è una convoluzione discreta.
\begin{equation*}
	x[n] \longrightarrow \fbox{$h[n]=\omega_N^{-nk} u[n]$} \longrightarrow y_k[n]
\end{equation*}
L'algoritmo, espresso come equazione alle differenze del primo ordine, fornisce
\begin{equation*}
	y_k[n] = x [n] +  \omega_N^{-k} y_k[n-1]  \quad \text{con} \quad y_k[-1]=0
\end{equation*}
Notiamo che $x[n]$ è definito solo per $0\leq n \leq N-1$ e perciò $x[N]=0$ e che per calcolare la $k$-esima componente $X_k$  si utilizza solo la radice $\omega_N^{-k}$.
Il calcolo di $X_k$ richiede tempo $O(N)$. Quindi per calcolare tutta la DFT si ha complessità $O(N^2)$. Tuttavia se si è interessati solo a $M$ frequenze risulta vantaggiosa rispetto agli algoritmi FFT $O(N \log2(N))$ fin tanto che $ M\leq\log2(N)$
%
% propagazione errore veloce....
%
%

\subsubsection*{Good-Thomas - Prime Factor Algorithm} %fft-lecture.pdf
Il \emph{Prime Factor Algorithm (PFA)}, anche chiamato \emph{Good-Thomas algorithm}, permettere di ridefinire una FFT con $N=N_1\times N_2$ come \emph{DFT bidimensionali} $N_1\times N_2$, ma solo nel caso che $N_1$ e $N_2$ siano \emph{coprimi}. La valutazione di queste DFT di taglia $N_1$ o $N_2$ può essere effettuato applicando ricorsivamente PFA stesso, se possibile, o qualunque altro algoritmo FFT.
Avere $N_1$ e $N_2$ coprimi permette di individuare facilmente una funzione biettiva per ri-indicizzare l'input e l'output di \eqref{eq:def-dft}.
Ciò ci permette di scrivere
\begin{align}
n &=n_1 N_2 + n_2 N_1  \mod N,\\ \nonumber
k &= k_1 N_2^{-1} N_2 + k_2 N_1^{-1} N_1 \mod N,\\
X_{k_1 N_2^{-1} N_2 + k_2 N_1^{-1} N_1} &=\sum_{n_1=0}^{N_1-1} \left( \sum_{n_2=0}^{N_2-1} x_{n_1 N_2 + n_2 N_1}e^{-\frac{2\pi i}{N_2} n_2 k_2 } \right)e^{-\frac{2\pi i}{N_1} n_1 k_1 }.
\end{align}
dove $N_1^{-1}$ è l'inverso di $N_1$ in aritmetica modulo $N_2$ e analogamente per $N_2^{-1}$.
La complessità dopo la scomposizione è $N\cdot (N_1+N_2)$ e iterando $O(N\log(N))$. Il numero di operazioni complessive è confrontabile con quello dello split-radix ma il numero di moltiplicazioni globale è inferiore.


\section{Interpretazione Matriciale degli algoritmi}
\label{notazione-matriciale}
La visione matriciale proprosta da Van Loan \cite{van-loan} risulta molto comoda per la comprensine delle operazioni che si verificano nel calcolo della FFT.
Riprendendo la scomposizione di Cooley-Tukey
\begin{align}
\label{eq:ct-matrix-1}
	X_k&= Y_k+\omega_N^k Z_k, \qquad k=0,1,...,N/2-1\\ 
\label{eq:ct-matrix-2}
	X_{k+\frac{N}{2}} &= Y_k-\omega_N^k Z_k, \qquad k=0,1,...,N/2-1
\end{align}
la applichiamo al caso sufficientemente rappresentativo $N=16$ per ricavare lo schema di scomposizione matriciale ricorsivo.
Indicando con $\mathbf{Y}$ e $\mathbf{Z}$ i vettori corrispondenti alle sequenze $Y_k$ e $Z_k$, possiamo riscrivere le operazioni butterly \eqref{eq:ct-matrix-1} e \eqref{eq:ct-matrix-2} nella forma
\begin{equation}
	\mathbf{X}=\mathbf{F_{16}}\mathbf{x} = \begin{pmatrix} \mathbf{I_{8}} &\mathbf{\Omega_{8}} \\\mathbf{I_{8}} &-\mathbf{\Omega_{8}}  \end{pmatrix}\begin{pmatrix} \mathbf{Y} \\ \mathbf{Z} \end{pmatrix}\equiv\mathbf{B_{16}} \begin{pmatrix} \mathbf{Y} \\ \mathbf{Z} \end{pmatrix}
\end{equation}
dove $\mathbf{I_{8}}$ è la matrice identità di ordine \emph{m} e $\mathbf{\Omega_{8}}$ è la matrice diagnonale 
\begin{equation*}
	\mathbf\Omega_{m}= \text{diag} (1,\omega_{2m}^{1},\omega_{2m}^{2},...,\omega_{2m}^{m-1})
\end{equation*}
La matrice $\mathbf{B_{16}}$ utilizzata per il passo di ricombinazione è detta \emph{butterfly matrix}.\\
$\mathbf{Y}$ e $\mathbf{Z}$ sono a loro volta DFT di lunghezza 8 delle sotto-sequenze pari e dispari di x, che chiameremo $x_{even}$ e $x_{odd}$. Quindi procedendo analogamente,

\begin{equation}
	\mathbf{Y}=\mathbf{F_{8}}\mathbf{x_{even}} = \begin{pmatrix} \mathbf{I_{4}} &\mathbf{\Omega_{4}} \\\mathbf{I_{4}} &-\mathbf{\Omega_{4}}  \end{pmatrix}\begin{pmatrix} \mathbf{Y'} \\ \mathbf{Z'} \end{pmatrix}\equiv\mathbf{B_{8}} \begin{pmatrix} \mathbf{Y'} \\ \mathbf{Z'} \end{pmatrix}
\end{equation}
dove  $\mathbf{Y'}$ e $\mathbf{Z'}$ denotano le DFT di lunghezza 4 delle sottosequenze pari e dispari di $x_{even}$.

\begin{equation}
	\mathbf{Z}=\mathbf{F_{8}}\mathbf{x_{odd}} = \begin{pmatrix} \mathbf{I_{4}} &\mathbf{\Omega_{4}} \\\mathbf{I_{4}} &-\mathbf{\Omega_{4}}  \end{pmatrix}\begin{pmatrix} \mathbf{Y''} \\ \mathbf{Z''} \end{pmatrix}\equiv\mathbf{B_{8}} \begin{pmatrix} \mathbf{Y''} \\ \mathbf{Z''} \end{pmatrix}
\end{equation}
dove  $\mathbf{Y''}$ e $\mathbf{Z''}$ denotano le DFT di lunghezza 4 delle sottosequenze pari e dispari di $x_{odd}$.

\begin{equation}
	\mathbf{X}=\mathbf{F_{16}}\mathbf{x} =\mathbf{B_{16}}
	\begin{pmatrix}\mathbf{B_{8}} & 0\\0& \mathbf{B_{8}} \end{pmatrix}
	\begin{pmatrix} \mathbf{Y'} \\\mathbf{Y''} \\ \mathbf{Z'}\\\mathbf{Z''}\end{pmatrix}
\end{equation}
e continuando fino a N=2
\begin{align}
\begin{split}
	\mathbf{X}&=\mathbf{F_{16}}\mathbf{x} =\mathbf{B_{16}}
	\begin{pmatrix}\mathbf{B_{8}} & 0 \\0& \mathbf{B_{8}} \end{pmatrix}
	\begin{pmatrix}\mathbf{B_{4}} & 0& 0& 0\\ 0&\mathbf{B_{4}}& 0& 0 \\  0& 0&\mathbf{B_{4}}& 0 \\  0& 0& 0& \mathbf{B_{4}}  \end{pmatrix}\\
	&\times
	\label{eq:CT-factorization}
	\begin{pmatrix}
	\mathbf{B_{2}}& 0& 0& 0& 0& 0& 0& 0 \\
	0&\mathbf{B_{2}}& 0& 0& 0& 0& 0& 0 \\ 
	0&0&\mathbf{B_{2}}& 0& 0& 0& 0& 0 \\ 
	0&0&0&\mathbf{B_{2}}& 0& 0& 0& 0 \\ 
	0&0&0&0&\mathbf{B_{2}}& 0& 0& 0 \\ 
	0&0&0&0&0&\mathbf{B_{2}}& 0& 0 \\ 
	0&0&0&0&0&0&\mathbf{B_{2}}& 0 \\ 
	0&0&0&0&0&0&0&\mathbf{B_{2}} \\  \end{pmatrix}\mathbf{P}^{T}\mathbf{x}
\end{split}
\end{align}
Quindi la matrice $\mathbf{F_{16}}$ è stata espressa come prodotto di quattro matrici  $\mathbf{B}_m$ con $m=2,4,8,16$ e ad ogni passo la matrice  $\mathbf{B}_m$ implementa le relazioni di scambi e calcolo per passare da 2 DFT ti tagllia $m/2$ a una di taglia $m$.\\
Notiamo che man mano che la fattorizzazione è stata sviluppata, il riordinamento dell'input è stato espresso sempre alla destra dei prodotti di matrici. Pertanto, questa riorganizzazione dell'ingresso, detta \emph{scramble operation} viene effettuata solo all'inizio sul vettore di input e non sui passi intermedi.
La matrice $\mathbf{P}$ è ottenuta effettuando successivi riordinamenti pari/dispari delle colonne della matrice identità $\mathbf{I_{16}}$.
Dove un riordinamento di mensione N può essere espresso come una matrice $\mathbf{R_N}$  $NxN$ del tipo
$$\mathbf{R_{N}}=\begin{pmatrix}
0 & 1\\
&&0 & 1\\
&&&&...\\
&&&&&0 & 1\\
1 & 0\\
&&1 & 0\\
&&&&...\\
&&&&&1 & 0
\end{pmatrix}
$$
\begin{align*}
	\mathbf{P}=\mathbf{R_{16}}
	\begin{pmatrix}\mathbf{R_{8}} & 0 \\0& \mathbf{R_{8}} \end{pmatrix}
	\begin{pmatrix}\mathbf{R_{4}} & 0& 0& 0\\ 0&\mathbf{R_{4}}& 0& 0 \\  0& 0&\mathbf{R_{4}}& 0 \\  0& 0& 0& \mathbf{R_{4}}  \end{pmatrix}
	\times
	\begin{pmatrix}
	\mathbf{R_{2}}& 0& 0& 0& 0& 0& 0& 0 \\
	0&\mathbf{R_{2}}& 0& 0& 0& 0& 0& 0 \\ 
	0&0&\mathbf{R_{2}}& 0& 0& 0& 0& 0 \\ 
	0&0&0&\mathbf{R_{2}}& 0& 0& 0& 0 \\ 
	0&0&0&0&\mathbf{R_{2}}& 0& 0& 0 \\ 
	0&0&0&0&0&\mathbf{R_{2}}& 0& 0 \\ 
	0&0&0&0&0&0&\mathbf{R_{2}}& 0 \\ 
	0&0&0&0&0&0&0&\mathbf{R_{2}} \\  \end{pmatrix}
\end{align*}
L'effetto di questa permutazione è quello di ottenere un  \emph{riordinamento bitreversal} della sequenza di input x.

La fattorizzazione può inoltre essere espressa agevolmente attraverso  il \emph{Prodotto di Kronecker}
\footnote{Il prodotto di Kronecker di una matrice $\mathbf{A}$ $p\times q$ e $\mathbf{B}$ $r\times s$ è la matrice$pr \times qs$
$$
\mathbf{A}\otimes \mathbf{B}=
\begin{pmatrix}
a_{11}\mathbf{B} &\ldots & a_{1q}\mathbf{B}\\
\vdots &\ddots&\vdots\\
a_{p1}\mathbf{B} &\ldots & a_{pq}\mathbf{B}

\end{pmatrix}
$$
con $a_{ij}$ elementi di $\mathbf{A}$
}\\
La fattorizzazione  	\eqref{eq:CT-factorization} può quindi essere vista come
$$
\mathbf{X}=\mathbf{F_{16}} \mathbf{x}=(\mathbf{I_{1}}\otimes \mathbf{B_{16}})(\mathbf{I_{2}}\otimes \mathbf{B_{8}}) (\mathbf{I_{4}}\otimes \mathbf{B_{4}})(\mathbf{I_{8}}\otimes \mathbf{B_{2}})\mathbf{P}^T\mathbf{x}
$$
In generale la FFT di Cooley-Tukey per $N=2^M$ può essere espressa come
$$
\mathbf{X}=\mathbf{F_{N}} \mathbf{x}=\mathbf{A}_{M}\mathbf{A}_{M-1} ... \mathbf{A}_{2}\mathbf{A}_{1}\mathbf{P}^T\mathbf{x}
$$
dove$\mathbf{A}_{k}=\mathbf{I}_r\otimes\mathbf{B}_m $, $m=2^k$ e $rm=N$ per $k=1,...,M$ sono matrici diagnonali a blocchi.
Generalizzando l'esempio
$$
	\mathbf{B}_{2m}= \begin{pmatrix} \mathbf{I}_{m} &\mathbf{\Omega}_{m} \\\mathbf{I}_{m} &-\mathbf{\Omega}_{m}\end{pmatrix} \qquad \text{e} \qquad  	\mathbf\Omega_{m}= \text{diag} (1,\omega_{2m}^{1},\omega_{2m}^{2},...,\omega_{2m}^{m-1})
$$
Notando che $\mathbf{F}_N$ è una matrice simmetrica allora
$$
\mathbf{F}_{N}=\mathbf{F}_{N}^T =(\mathbf{A}_{M}\mathbf{A}_{M-1} ... \mathbf{A}_{2}\mathbf{A}_{1}\mathbf{P}^T)^T = \mathbf{P}\mathbf{A}_{1}^T\mathbf{A}_{2}^T ... \mathbf{A}_{M-1}^T\mathbf{A}_{M}^T
$$
che è proprio la fattorizzazione corrispondente all'algoritmo di Gentleman e Sande.\\
Un ulteriore modo per vedere $\mathbf{F}_{N}$ è
$$
\mathbf{F}_{N}=\mathbf{A}_{M}\mathbf{P}_{M}\mathbf{A}_{M-1}\mathbf{P}_{M-1} ... \mathbf{A}_{2}\mathbf{P}_{2}\mathbf{A}_{1}\mathbf{P}_{1}
$$
dove ogni stadio $i$ è costituito da una matrice di combinazione $\mathbf{A}_{i}$ e una di permutazione $\mathbf{P}_{i}$

\begin{algorithm}[H]                      % enter the algorithm environment
\caption{Cooley-Tukey Matriciale}          % give the algorithm a caption
\label{alg:ct-matrix}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
\REQUIRE $N = 2^n (n\geq1),\quad \mathbf{x}\in\mathbb{C}^N$\\
\ENSURE $\mathbf{x}_n \in\mathbb{C}^N$\\
\emph{Calcola i twiddle factor} $\omega_N^k$ $(k=1,...,N-1$)\\
\STATE $\mathbf{x}_0 \longleftarrow \mathbf{P}^T\mathbf{x}$\\
\FOR{$j=1$ to $n$}
\STATE $\mathbf{x}_j  \longleftarrow \mathbf{A}_j \mathbf{x}_{j-1} $
\ENDFOR
\end{algorithmic}
\end{algorithm}

\section{Algoritmi paralleli per il calcolo di FFT}

Gli algoritmi fino a questo momento presentati sono algoritmi prettamente sequenziali che, se pur diminuendo notevolmente la complessit\`a di calcolo rispetto all'algoritmo di base, non sfruttano il fatto che il calcolo della FFT presenta un elevato grado di parallelismo, che pu\`o essere sfruttato al meglio in presenza di pi\`u processori a patto di progettare algoritmi corretti ed adeguati alle risorse di sistema presenti.\\

Non \`e scopo di questa relazione discutere approfonditamente l'argomento ma \`e utile fornire comunque una panoramica sulla struttura e l'efficienza di due algoritmi paralleli molto utilizzati nel calcolo della FFT, il primo dei quali utilizza una struttura nota come rete ascendente per il calcolo mentre il secondo \`e un'opportuna rivisitazione dell'algoritmo gi\`a presentato di Cooley-Tukey.
\\Nella discussione che segue viene indicata con $n$ la lunghezza del vettore di ingresso e con \emph{size} il numero totale di processi utilizzati (numerati da $0$ a $size-1$).

\subsection{Primo algoritmo: Computazione in rete ascendente}
In questa sezione viene presentato il primo algoritmo che calcola la FFT utilizzando una rete ascendente (rete $\Omega^{-1}$) con i collegamenti tra le linee che rappresentano i cosiddetti operatori \emph{butterfly} (Figura 2.5).
\begin{figure}[h!]
\centering
\includegraphics[width=13cm,height=5cm]{immagini/rete-ascendente.eps}
\caption{Esempio di rete ascendente con 8 linee e illustrazione di un \emph{butterfly operator}. In figura il simbolo $\omega{}i$ rappresenta $\omega^i$.}
\end{figure}\\
Su ogni linea all'ingresso della rete va posto un elemento del vettore di ingresso, ed ogni processo \`e responsabile di una o pi\`u linee a seconda del numero di processi lanciati. Per semplicit\`a si assume che il numero di linee (e quindi la dimensione n del vettore di ingresso), cos\`i come il numero di processi, sia sempre una potenza di due con ovviamente il vincolo che il numero di processi sia minore o uguale ad n.

I dati di ingresso (elementi del vettore $\mathbf{X}$) vengono letti da un file di input dove ogni valore, composto dalla sua parte reale e dalla parte immaginaria, \`e scritto su una riga separata. Il processo 0 \`e il processo che si occupa sempre di leggere i valori di ingresso e salvarli opportunamente in un array \emph{double} di dimensione doppia rispetto alla dimensione del vettore $\mathbf{X}$, dato che la sistemazione dei valori all'interno dell'array avviene in maniera tale che l'elemento i-esimo abbia la sua parte reale salvata in posizione $2*i$ e la parte immaginaria in posizione $2*i+1$ nell'array di input.\\Successivamente, completata l'acquisizione, il processo 0 esegue un riordinamento \emph{bit-reversing} dei dati sulle linee ed infine esegue un broadcast dell'intero contenuto dell'array verso i rimanenti processi.

Dopo questa prima fase, ogni processo calcola indipendentemente i twiddle factors che saranno necessari durante la computazione. Ogni processo calcola gli stessi twiddle factors, in particolare le potenze di $\omega_n$ necessarie e calcolate vanno da $\omega_n^0$ a $\omega_n^{\frac{n}{2}-1}$.\\

Fatto ci\`o la computazione vera e propria ha inizio: essa si compone di $log_2(n)$ passi dove ogni passo coincide con un ``settore'' della rete ascendente. All'inizio di ogni passo ogni processo, se necessario, prima di effettuare qualunque calcolo esegue la primitiva non bloccante \verb+MPI_Irecv+ un numero di volte pari al numero di linee che gestisce al fine di preparare il buffer di ricezione per i dati che verranno ricevuti dai dovuti \emph{peers} al termine del passo. Conseguentemente, al termine di ogni passo e prima dell'inizio del successivo, se necessario ogni processo invia il/i dato/i calcolato/i durante il passo appena terminato al peer opportuno utilizzando una primitiva non bloccante \verb+MPI_Isend+. Prima del passaggio al passo successivo ogni processo attende il completamento delle operazioni di ricezione dati avviate all'inizio del passo precedente, dato che ovviamente tali dati saranno necessari per le prossime fasi.\\Al termine della computazione, infine, ogni processo invia al processo 0 i dati appartenenti alle linee di propria competenza affinch\`e vengano posti in un array comune ed infine visualizzati.

\subsection{Secondo algoritmo: Adattamento dell'algoritmo standard di Cooley-Tukey}

L'implementazione \emph{divide and conquer} tradizionale dell'algoritmo di CT richiede sostanzialmente cinque fasi per calcolare correttamente la FFT.\\
Nella versione parallela proposta le suddette cinque fasi sono state cos\`i adattate:
\begin{itemize}
 \item Fase 1: il vettore di ingresso $\mathbf{X}$, che per semplicit\`a si assume avere un numero pari ad una potenza di due, con esponente pari, di elementi, \`e riorganizzato idealmente in forma matriciale di tipo $\sqrt{n}$ x $\sqrt{n}$. Tale matrice \`e poi suddivisa secondo un layout organizzato per righe tra i vari processi disponibili (Figura 1.2). Si assume, conseguentemente, che il numero di processi totali \`e minore o uguale a $\sqrt{n}$. 
Dal punto di vista implementativo le righe di cui ogni processo \`e responsabile sono salvate consecutivamente in un array A, di dimensione $2*n/size$ dove \emph{size} \`e il numero di processi disponibili ed il coefficiente moltiplicativo 2 \`e dovuto al modo con cui vengono salvati i valori complessi, analogamente a quanto illustrato nel precedente algoritmo.
\item Fase 2: viene effettuata una prima trasposizione matriciale globale atta a fare in modo che ogni processo conservi nel proprio array locale A un numero pari a $\sqrt{n}/size$ colonne della matrice globale. In questo modo ogni processo pu\`o poi effettuare la FFT, sulle colonne di competenza, localmente, senza richiedere ulteriori comunicazioni inter-processore.
\item Fase 3: al termine della FFT calcolata sulle colonne, ogni processo moltiplica i propri elementi di competenza per i corrispondenti twiddle factors. Si noti a tal proposito che le potenze di $\omega_n$ che ogni processo calcola indipendentemente all'inizio dell'algoritmo vanno da $\omega_n^{0}$ a $\omega_n^{{(\sqrt{n}-1)}^2}$.
\item Fase 4: la quarta fase richiede una nuova trasposizione matriciale atta a trasferire localmente ad ogni processo le dovute $\sqrt{n}/size$ righe della matrice ideale su cui poi poter eseguire nuovamente un totale di $\sqrt{n}/size$ FFT locali, analogamente a quanto fatto per le colonne alla Fase 2.
\item Fase 5: completata la Fase 4 viene eseguita un'ultima trasposizione matriciale atta a trasferire ad ogni processo le colonne di competenza della matrice ideale. In questo modo la lettura dei valori finali, che come noto deve essere effettuata in ordine column-major, risulta pi\`u semplice dato che \`e sufficiente che tutti i processi comunichino al processo 0 i dati in loro possesso, quindi che 0 li disponga nell'ordine opportuno nel proprio array A (i $2*n/size$ elementi del processo i andranno di\-spo\-sti consecutivamente a partire dalla posizione $2*n*i/size$ nell'array finale) e che, infine, li visualizzi poi semplicemente scandendo l'array.
\end{itemize}

\begin{figure}[h!]
\centering
\includegraphics[width=10cm,height=5cm]{immagini/CT-processi.eps}
\caption{Esempio di suddivisione di una matrice 4x4 tra 4 processi secondo il layout proposto.}
\end{figure}
Come nel precedente algoritmo, anche in questo la raccolta dei valori iniziali e la distribuzione opportuna ai vari processi avviene ad opera del processo 0. Un'importante differenza \`e data dalla quantit\`a di dati distribuiti: se nel primo algoritmo il processo 0 effettuava un broadcast dell'intero array ini\-zia\-le verso tutti i processi, in questa versione 0 distribuisce soltanto i valori strettamente necessari ad ogni processo, ovvero un totale di $2*n/size$ valori.\\

Appare chiaro, dalla descrizione effettuata, che questo algoritmo richiede comunicazioni tra i processi solo durante le trasposizioni matriciali. Durante la singola trasposizione ogni processo deve inviare e ricevere un totale di $2*(n/size - n/size^2)$ valori double, essendo $2*n/size$ il totale di elementi che sono contenuti nell'array locale e $2*{(\sqrt{n}/size)}^2$ gli elementi che rimangono nel pool locale (ovvero il numero di colonne di competenza del processo elevato al quadrato) durante la trasposizione. L'algoritmo di trasposizione implementato, invocato contemporaneamente da tutti i processi, opera scandendo l'array a disposizione di ogni processo e determinando, sulla base dell'ID del processo (e quindi della disposizione dei suoi dati nella matrice ideale globale) se il singolo elemento, dopo la trasposizione, apparterr\`a ancora al pool di competenza del medesimo processo oppure se \`e richiesta una comunicazione con un peer. In quest'ultimo caso l'ID del peer viene determinato ed il valore inviatogli con l'uso della primitiva \verb+MPI_Isend+. Chiaramente, ad ogni elemento inviato corrisponde un elemento che deve essere ricevuto dallo stesso peer, perci\`o il processo si mette in attesa della ricezione con la primitiva \verb+MPI_Irecv+. \`E fondamentale l'uso di primitive non bloccanti, a differenza del precedente algoritmo, in virt\`u del fatto che l'ordine di determinazione dei peers da parte dei processi che devono comunicare non \`e lo stesso, ovvero non \`e detto che se il processo i, arrivato alla scansione dell'elemento k nel proprio array di competenza, ha richiesto l'invio di A[k] al processo j, a sua volta j si sia messo in attesa della ricezione, anzi pu\`o capitare che j abbia richiesto a sua volta l'invio di un altro valore ad un altro processo. Tutto ci\`o, se usate primitive bloccanti, porterebbe a \emph{deadlock}.\\
\`E anche importante osservare che i valori scambiati tra due processi i e j (valori che possono essere in numero superiore ad 1) non occupano le stesse posizioni relative all'interno dei singoli array perci\`o \`e indispensabile fare un uso attento dei \emph{tags} nelle comunicazioni al fine di non rischiare di confondere i dati ricevuti.\\

L'algoritmo utilizzato per il calcolo locale della FFT \`e il tradizionale algoritmo ricorsivo di natura D\verb+&+C che spezza l'array in due parti uguali, calcola ricorsivamente su queste parti la FFT, e ricompone correttamente in un unico array il tutto.


\subsection{Considerazioni sulle prestazioni}

\'E possibile considerare che il secondo algoritmo proposto \`e molto efficiente in ambito sequenziale (un processo). Tuttavia le cose cambiano anche notevolmente se si aumenta il numero di processi: con due processi si verifica un aumento del numero di istruzioni eseguite dal singolo processo rispetto al caso precedente. Ci\`o si spiega in parte con il fatto che, in presenza di due o pi\`u processi, l'algoritmo deve eseguire un numero molto maggiore di istruzioni, dovendo predisporre i dati necessari alle comunicazioni da effettuare per le trasposizioni matriciali (si pensi al gi\`a citato calcolo dei \emph{tags} e alla determinazione del peer con cui comunicare).

Le comunicazioni crescono con l'aumentare della dimensione del pool di elementi di competenza del singolo processo ed \`e questo il motivo per cui l'effetto descritto \`e parzialmene mitigato dall'aumentare del numero di processi, ovvero con la diminuzione sia della dimensione del pool di competenza del singolo processo, che del numero di invocazioni delle funzioni MPI che il processo deve eseguire.\\

Il fenomeno descritto sarebbe del tutto assente nel primo algoritmo: infatti, nel primo algoritmo \`e quasi immediata la determinazione del peer con cui comunicare e non vi \`e bi\-so\-gno, per il modo in cui \`e strutturato l'algoritmo stesso, di tag diversi tra loro nelle comunicazioni. Tuttavia, quando il numero degli elementi del vettore di ingresso aumenta troppo ed il numero dei processi \`e superiore ad uno ma non ele\-va\-to l'alto numero di buffer pre\-di\-spo\-sti per le comunicazioni inciderebbe in maniera notevolissima sulle prestazioni, causando un notevole degrado della performance.\\

Concludendo, quindi, si pu\`o dedurre che la prima versione dell'algoritmo per il calcolo della FFT \`e consigliabile solo in presenza di grandi vettori di input e pochi processi a disposizione (purch\`e pi\`u di uno) mentre la seconda versione dell'algoritmo \`e teoricamente tanto pi\`u efficiente, in presenza di comunicazioni inter-processore, quanto pi\`u il rapporto tra dimensione del vettore di ingresso e numero dei processi tende a 0.


\chapter{Stabilità Numerica}
Fin'ora abbiamo trattato la \emph{discrete Fourier transform} e la \emph{fast Fourier transform} pensando che potessero idealmente essere calcolate con assoluta precisione.\\
Tuttavia i calcolatori reali utilizzano parole di lunghezza finita e quindi anche i numeri e le operazioni aritmetiche sono soggetti ai limiti della 	\emph{rappresentazione in virgola mobile}.\\
E' fondamentale infatti che un algoritmo, oltre ad essere veloce, sia anche stabile quando opera in un contesto in virgola mobile con errore di arrotondamento $u$.\\
Mostreremo quindi come DFT e FFT siano estremamente sensibili rispetto alla precisione con cui vengono precalcolati i \emph{twiddle factors}, quale rapporto intercorre tra l'errore con DFT e FFT e come, sotto opportune ipotesi, gli algoritmi FFT possano essere considerati stabili.

Utilizando un modello standard di aritmetica binaria reale a precisione finita \cite{higham} se $x$ e $y$ sono numeri complessi esattamente rappresentabili si assume che

%ROUNDOFF ERROR pg 565
\newtheorem{lemma}{Lemma}
\begin{lemma}\textbf{Modello di Wilkinson}
Siano $x,y \in \mathbb{C}$, allora
\begin{alignat}{3}
\label{eq:error-sum}
fl(x\pm y) = (x\pm y) (1+\varepsilon^+) 	\qquad \qquad && |\varepsilon^+| &\leq u\\
\label{eq:error-prod}
fl(x\ast y) = (x\ast y) (1+\varepsilon^\times) 	\qquad \qquad&& |\varepsilon^\times| &\leq \sqrt{2}\frac{2u}{1-2u}=2\sqrt{2}u+ O(u^2)\\
\label{eq:error-div}
fl(x\div y) = (x\div y) (1+\varepsilon^\div) 	\qquad \qquad && |\varepsilon^\div| &\leq \sqrt{2}\frac{4u}{1-4u}=4\sqrt{2}u+ O(u^2)\\
\end{alignat}
\end{lemma}

dove $\delta\approx 2^{-b}$ con $b$ lunghezza della mantissa.
Indichiamo con $\mathbf{\hat{z}}$ il risultato ottenuto da $fl(x \circ y)$ mentre con $\mathbf {z}$ il risultato esatto di $(x \circ y)$ dove l'operazione $\circ \in\{+,-,\cdot,\div\}$\\
\noindent Si suppone inoltre che gli esponenziali complessi $\omega_k$ siano pre-calcolati e su di essi sia stato commesso un errore $|\epsilon_{ik}|$ tale che:

\begin{equation*}
\hat{\omega}_j^k= fl(\omega_j^k)=\omega_j^k+\epsilon_{jk} \qquad |\epsilon_{jk}|\leq u
\end{equation*}

Per lo standard IEEE 754, operando in doppia precisione, la mantissa è di 53 bit (con 1 bit di segno) per cui $u\approx 1.11 \times 10^{-16}$ mentre in singola precisione è di 24 bit per cui $u\approx 5.96 \times 10^{-8}$.
\section{Worst Case Error DFT}

\newtheorem{lemma2}[lemma]{Lemma}
\begin{lemma2}\label{wilkinson}
\textbf{(di Wilkinson)}
Se $\mathbf{A}$ è una matrice reale $p \times q$, $\mathbf{B}$ è una matrice reale $q \times r$ e  $b$ è il numero di bit della mantissa, Allora
\begin{equation}
\left\|{fl(\mathbf{AB})-\mathbf{AB}}\right\|_2\leq 1.06 \cdot q\cdot 2^{-b} \left\|\mathbf{A}\right\|_2 \left\|\mathbf{B}\right\|_2
\end{equation}
\end{lemma2}
\vskip 15pt
\newtheorem{Teorema}{Teorema}
\begin{Teorema} \textbf{(Gentleman-Sande)}\label{Teorema:bound-dft}
Se si utilizza la definizione di DFT per calcolare la trasformata di Fourier discreta $\mathbf{X}$ di una sequenza $\mathbf{x}$ di lunghezza $N$ in aritmetica a virgola mobile a lunghezza di parola costante con mantissa di $b$ bit, Allora
\begin{equation}
\left\|\mathbf{\hat{X}-X}\right\|_2\leq 1.06 \;{(2N)}^{3/2} 2^{-b} \left\|\mathbf{X}\right\|_2
\end{equation}
\end{Teorema}
\begin{proof}
Il calcolo per definizione della DFT è esprimibile attraverso una matrice $\mathbf{F} \in \mathbb{C}^{N \times N}$ dove $$\mathbf{F}_{i,j} =(\omega_N^{ij})_{i,k=0}^{N-1}$$
\begin{equation}
	\mathbf{\hat{x}}=\mathbf{F}\mathbf{x}
\end{equation}
$\mathbf{x}$ può essere visto come $\mathbf{x}={\rm Re}(\mathbf{x})+i{\rm Im}(\mathbf{x}) \leftrightarrow [{\rm Re}(\mathbf{x}), {\rm Im}(\mathbf{x})]$, vettore di lunghezza $2N$. Per definizione
\begin{align}
X_k&=\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn} \quad k=0,...,N-1\\
&= \sum_{n=0}^{N-1}({\rm Re}(x)+\jmath{\rm Im}(x)) \left[ \cos\left( \frac{2\pi}{N}kn\right) - \jmath \sin \left(\frac{2\pi}{N}kn\right)\right]
\end{align}
Le operazioni complesse possono quindi essere espresse come operazioni reali attraverso una matrice $2N \times 2N$:
\[ \begin{bmatrix}
  {\rm Re}(\mathbf{\hat{x}}) \\
	{\rm Im}(\mathbf{\hat{x}})
 \end{bmatrix}= 
 \begin{bmatrix}
  \mathbf{C} & -\mathbf{S} \\
  \mathbf{S} & \mathbf{C}
 \end{bmatrix}
  \begin{bmatrix}
  {\rm Re}(\mathbf{x}) \\
	{\rm Im}(\mathbf{x}) \end{bmatrix} = \mathbf{\Phi}
  \begin{bmatrix}
  {\rm Re}(\mathbf{x}) \\
	{\rm Im}(\mathbf{x}) \end{bmatrix}
\]
dove $\mathbf{C}_{i,j}=\cos\left(\frac{2\pi i j}{N}\right)$ e $\mathbf{S}_{i,j}=\sin\left(\frac{2\pi i j}{N}\right)$. Inoltre la norma 2 della matrice è

\begin{align*}
 \left\|\mathbf{\Phi}\right\|_2&=\sqrt{\sum_{i=0}^{N-1}\sum_{j=0}^{N-1}\left\{ \cos^2\left(\frac{2\pi ij}{N}\right) +\sin^2\left(\frac{2\pi ij}{N}\right)+\cos^2\left(\frac{2\pi ij}{N}\right)+\sin^2\left(\frac{2\pi ij}{N}\right) \right\}}\\
 &=\sqrt{2N^2}
\end{align*}
\begin{align*}
\Phi^*\Phi= \underbrace{\begin{bmatrix}
1 & 0 & ... & 0\\ 0 & 1 & ... & 0\\ \vdots & \vdots & \ddots & \vdots\\ 0 & 0 & ... & 1\\
\end{bmatrix}}_{2N} \longrightarrow \left\|\Phi^*\Phi \right\|_2=\sqrt{2N}
\end{align*}
\begin{equation}
\mathbf{X} = \Phi \mathbf{x} \longrightarrow \left\|\mathbf{X}\right\|_2=\frac{\left\|\Phi \right\|_2}{\left\|\Phi^*\Phi \right\|_2}\left\|\mathbf{x} \right\|_2 = \frac{\sqrt{2}N}{\sqrt{2N}}\left\|\mathbf{x} \right\|_2=\sqrt{N} \left\|\mathbf{x}\right\|_2
\end{equation}

Applicando il \emph{Lemma di Wilkinson} con, nel nostro caso $q=2N$, $\left\|\mathbf{\Phi}\right\|_2=\sqrt{2} N$, ricordando che $\left\|\mathbf{X}\right\|_2=\sqrt N \left \| \mathbf{x} \right \|_2$
\begin{align*}
\left\|{fl(\mathbf{\Phi x})-\mathbf{\Phi x}}\right\|_2&\leq 1.06 \cdot q \cdot 2^{-b} \left\|\mathbf{\Phi}\right\|_2 \left\|\mathbf{x}\right\|_2\\ 
\left\|{fl(\mathbf{X})-\mathbf{X}}\right\|_2&\leq 1.06 \cdot 2N \cdot 2^{-b} \sqrt{2}N \frac{\left\|\mathbf{X}\right\|_2}{\sqrt{N}}\\ 
\left\|\mathbf{\hat{X}-X}\right\|_2&\leq 1.06 {(2N)}^{3/2} 2^{-b} \left\|\mathbf{X}\right\|_2
\end{align*}
\end{proof}

\section{Worst Case Error FFT}

%% TEOREMA Worst Case Error FFT
Per questa dimostrazione faremo riferimento alla notazione matriciale introdotta nella sezione \ref{notazione-matriciale} per l'algoritmo di Cooley-Tukey.

Introduciamo alcune proprietà della matrici $\mathbf{A}_j$ che useremo nella dimostrazione.
La matrice FFT può essere espressa come:
\begin{equation}
	\mathbf{F}_N=\mathbf{A}_n \mathbf{A}_{n-1} ... \mathbf{A}_1 \mathbf{P}^T \qquad (N=2^n)
	\label{eq:3.1}
\end{equation}
dove
\begin{equation}
	\mathbf{A}_j=\mathbf{I}_{2^{n-j}} \otimes \mathbf{B}_{2^j}, \quad
		\mathbf{B}_{2m}= \begin{pmatrix} \mathbf{I}_{m} &\mathbf{\Omega}_{m}\\ \mathbf{I}_{m} &-\mathbf{\Omega}_{m}\end{pmatrix}, \quad	\mathbf\Omega_{m}= \text{diag} (1,\omega_{2m}^{1},\omega_{2m}^{2},...,\omega_{2m}^{m-1})
	\label{eq:3.3}
\end{equation}
è chiaro che $\mathbf{A}_j$ contiene solo 2 elementi diversi da zero in ogni riga e colonna.
\emph{Proprietà} La matrice $\frac{1}{\sqrt{2}}\mathbf{B}_{2m}$ è unitaria. Infatti
 $$\mathbf{B}_{2m} (\overline{\mathbf{B}}_{2m})^T = \begin{pmatrix}
 \mathbf{I}_{m}+\mathbf{\Omega}_{m} (\overline{\mathbf{\Omega}}_{m}) &\mathbf{I}_{m}-\mathbf{\Omega}_{m} (\overline{\mathbf{\Omega}}_{m})\\\mathbf{I}_{m}-\mathbf{\Omega}_{m} (\overline{\mathbf{\Omega}}_{m}) &\mathbf{I}_{m}+ \mathbf{\Omega}_{m} (\overline{\mathbf{\Omega}}_{m})
 \end{pmatrix}= 2\begin{pmatrix}\mathbf{I}_{m}&0\\0&\mathbf{I}_{m}\end{pmatrix}$$
 e quindi
 $$\mathbf{A}_j\overline{\mathbf{A}}_j^T=
 (\mathbf{I}_{2^{n-j}} \otimes \mathbf{B}_{2^j})(\overline{\mathbf{I}_{2^{n-j}} \otimes\mathbf{B}}_{2^j})^T
 =\mathbf{I}_{2^{n-j}} \otimes \mathbf{B}_{2^j}\overline{\mathbf{B}}_{2^j}^T=2\mathbf{I}_{N}$$
 Di conseguenza, per $0\leq j< k\leq n$
\begin{equation}
	 \left\|\mathbf{A}_{k}...\mathbf{A}_{j+1}\right\|_2=2^{(k-j)/2}
	\label{eq:3.4}
\end{equation}
Ovvero la norma di un vettore moltiplicato per $k-j$ matrici di tipo $\mathbf{A}_i$ viene amplificata di $ 2^{(k-j)/2}$.


\newtheorem{Teorema2}[Teorema]{Teorema}
\begin{Teorema2} \label{Teorema:bound-fft}
Sia $N=2^n (n\geq3)$ e assumiamo che i \emph{twiddle factor} siano calcolati con una precisine $c_N$
\begin{equation}
	|\hat{\omega}_{2^j}^k-\omega_{2^j}^k|=|\delta_{2^j}^k|\leq c_N u \qquad (j=3,...,n; k=1,...,2^{j-1}-1)
	\label{eq:3.12}
\end{equation}
Allora per l'Algoritmo di Cooley-Tukey
\[\left\|\hat{\mathbf{x}}_n-\mathbf{x}_n\right\|_2 \leq 2^{n/2}(2u +(n-2)((\sqrt{2}c_N+4+\sqrt{2})u + O(u^2)))\left\|\mathbf{x}\right\|_2\]
\end{Teorema2}

\begin{proof}\.\\Sia $\hat{\mathbf{x}}_0 = \mathbf{x}_0=\mathbf{P}^T\mathbf{x}$, essendo l'input perfettamente rappresentabile in virgola mobile. Indichiamo con $\hat{\mathbf{x}}_j$ il calcolo del vettore $\hat{\mathbf{A}}_j\hat{\mathbf{x}}_{j-1} $ $$\hat{\mathbf{x}}_j=fl(\hat{\mathbf{A}}_j\hat{\mathbf{x}}_{j-1}) \qquad (j=1,...,n)$$
introduciamo inoltre il vettore $\mathbf{e}_j\in\mathbb{C}^N$ dell'errore commesso al $j$-esimo passo
\begin{equation}
	\hat{\mathbf{x}}_j=\hat{\mathbf{A}}_j\mathbf{x}_{j-1}+\mathbf{e}_{j}\qquad(j=1,...,n)
	\label{eq:3.7}
\end{equation}
Ovvero
\begin{equation*}
	\frac{\left\|\Delta X\right\|_2}{\left\|X\right\|_2}=O(log(N)c_Nu)
\end{equation*}

\begin{enumerate}
	\item Passo $j=1$
	$$\hat{\mathbf{A}}_1 ={\mathbf{A}}_1=\mathbf{I}_{2^{n-1}}\otimes\mathbf{B}_2\quad \text{con}\quad \mathbf{B}_2=\begin{pmatrix}1 &1\\1 &-1  \end{pmatrix}
	$$
	Questo passo pertanto si costituisce di $n/2$ FFT su due elementi. I twiddle factor risultano banali e le operazioni si riducono a 
	\begin{align}\eta_1 &= \xi_1+\xi_2 \qquad(\xi_1,\xi_2\in \mathbb{C})\\
								\nonumber \eta_2 &= \xi_1-\xi_2
	\end{align}
	Per la \eqref{eq:error-sum} i valori calcolati in virgola mobile risultano essere
	\begin{align*}
	\hat{\eta}_1 &= (\xi_1 +\xi_2)(1+\varepsilon_1^+)=\eta_1+(\xi_1+\xi_2)\varepsilon_1^+ & (|\eta_1^+|,|\eta_1^+|\leq u)\\
	\hat{\eta}_2 &= (\xi_1 -\xi_2)(1+\varepsilon_1^+)=\eta_2+(\xi_1+\xi_2)\varepsilon_1^+
	\end{align*}
	da cui
	$$|\varepsilon_1|^2= |\hat{\eta_1}-\eta_1|^2+|\hat{\eta_2}-\eta_2|^2\leq u^2(|\xi_1+\xi_2|^2+|\xi_1-\xi_2|^2)= 2u^2(|\xi_1|^2+|\xi_2|^2)$$
	e quindi
	\begin{equation}
	\label{eq:3.9}
	\left\|\mathbf{e}_1\right\|_2\leq\sqrt{2}u \left\|\mathbf{x}_0\right\|_2= \sqrt{2}\left\|\mathbf{x}\right\|_2
\end{equation}
	
	\item Passo $j=2$. Notiamo che
		$$\hat{\mathbf{A}}_2 ={\mathbf{A}}_2=\mathbf{I}_{2^{n-2}}\otimes\mathbf{B}_4$$
		con
		$$\mathbf{B}_2=\begin{pmatrix}\mathbf{I}_2 &\mathbf{\Omega}_2\\\mathbf{I}_2 &-\mathbf{\Omega}_2 \end{pmatrix} \quad\mathbf{\Omega}_2=\begin{pmatrix}1 &0\\ 0& -i\end{pmatrix}\quad \text{e quindi}\quad \mathbf{B}_4=\begin{pmatrix}1&0&1&0\\0&1&0&-i\\1&0&-1&0\\0&1&0&-i\end{pmatrix}$$
		Il secondo passo consiste quindi in $N/4$ FFT di 4 elementi. I twiddle factor sono banali e le operazioni risultano essere $(\xi_1,\xi_2,\xi_3,\xi_4\in \mathbb{C})$
			\begin{align*}
			\eta_1 &= \xi_1+\xi_3 &
			\eta_2 &= \xi_2-i\xi_4\\
			\eta_3 &= \xi_1-\xi_3&
			\eta_4 &= \xi_2+i\xi_4
	\end{align*}
	Procedendo analogamente al caso precedente si ottiene la stima $\left\|\mathbf{e}_2\right\|_2\leq\sqrt{2}u \left\|\mathbf{x}_1\right\|_2$.
	Per la \eqref{eq:3.7} e la \eqref{eq:3.9} otteniamo che 
	\begin{equation*}
	\left\|\hat{\mathbf{x}}_1\right\|_2\leq \underbrace{\left\|\mathbf{A}_1\right\|_2}_{\sqrt{2}}\left\|\hat{\mathbf{x}}_0\right\|_2+\underbrace{\left\|\hat{\mathbf{e}}_1\right\|_2}_{\leq \sqrt{2} u \left\|\hat{\mathbf{x}}_0\right\|_2}\leq \sqrt{2} (1+u)\left\|\mathbf{x}\right\|_2
\end{equation*}
e quindi
\begin{equation}
	\left\|\mathbf{e}_2\right\|_2\leq (2u+O(u^2)) \left\|\mathbf{x}\right\|_2
	\label{eq:3.10}
\end{equation}
	%3
	\item Passo $j$ con $(j=3,...,n)$.\\
	Osserviamo che la matrice $\mathbf{A}_j$ presenta per ogni riga e colonna esattamente due elementi diversi da zero. In ogni riga inoltre un elemento è $1$ mentre l'altro è un generico \emph{twiddle factor}. Al passo $j$ pertanto vengono effettuate FFT di lunghezza $2^{n-j}$ e $2^{j-1}$ coppie di operazioni del tipo 
	\begin{align}
	\label{eq:3.11}
	\begin{split}
	\eta_1 &= \xi_1+\omega_{2^j}^k\xi_2 \qquad(\xi_1,\xi_2\in \mathbb{C}; k=0,...,2^{j-1}-1)\\
	\eta_2 &= \xi_1-\omega_{2^j}^k\xi_2
	\end{split}
	\end{align}
che calcolate in vigola mobile risultano
\begin{align}
\begin{split}
		\hat{\eta}_1 &= (\xi_1+\hat{\omega}_{2^j}^k\xi_2(1+\varepsilon_1^\times))(1+\varepsilon_1^+) \\
		\hat{\eta}_2 &= (\xi_1-\hat{\omega}_{2^j}^k\xi_2(1+\varepsilon_2^\times))(1+\varepsilon_2^+)
		\label{eq:3.13}
\end{split}
\end{align}
con
\begin{equation}
	|\varepsilon^\times|\leq 2\sqrt{2}u, \qquad |\varepsilon_1^+|,|\varepsilon_2^+|\leq u 
	\label{eq:3.14}
\end{equation}	
Dall'ipotesi \eqref{eq:3.12} sui \emph{twiddle factor} e dalla \eqref{eq:3.14} segue che
$$
\hat{\eta}_1-\eta_1=\xi_1\varepsilon_1^++\hat{\omega}_{2^j}^k\xi_2(\varepsilon^\times+\varepsilon_1^++\varepsilon^\times \varepsilon_1^+)+\delta_{2^j}^k \varepsilon_2+O(u^2)\
$$
usando la \eqref{eq:3.14}si ha
$$
|\hat{\eta}_1-\eta_1|=|\xi_1|u+|\xi_2|((2\sqrt{2}+1+c_N)u+O(u^2))
$$
e quindi
$$
|\hat{\eta}_1-\eta_1|^2=2((2\sqrt{2}+1+c_N)u+O(u^2))^2(|\xi_1|^2+|\xi_2|^2)
$$
Applicando lo stesso ragionamento a $|\hat{\eta}_2-\eta_2|^2$ si arriva a 
$$
|\hat{\eta}_1-\eta_1|^2+|\hat{\eta}_2-\eta_2|^2=4((2\sqrt{2}+1+c_N)u+O(u^2))^2(|\xi_1|^2+|\xi_2|^2)
$$

Per l'errore $\mathbf{e}_j$ otteniamo la stima
$$\left\|\mathbf{e}_j\right\|_2\leq 2((2\sqrt{2}+1+c_N)u+O(u^2))\left\|\mathbf{\hat   {x}}_{j-1}\right\|_2$$

Dalla \eqref{3.4} e \eqref{eq:3.12} segue che
$$
\left\|\mathbf{\hat   {x}}_{j-1}\right\|_2\leq (2^{(j-1)/2})+O(u))\left\|\mathbf{x}\right\|_2
$$
e quindi
\begin{align}
\begin{split}
	\left\|\mathbf{e}_j\right\|_2&\leq 2^{(j+1)/2}((2\sqrt{2}+1+c_N)u+O(u^2))\left\|\mathbf{x}\right\|_2\\
	&\leq 2^{j/2}((4+\sqrt{2}+\sqrt{2}c_N)u+O(u^2))\left\|\mathbf{x}\right\|_2
	\label{eq:3.15}
	\end{split}
\end{align}
	\item \. %4
 Ora valutiamo l'errore $\left\|\hat{x}_n-x_n\right\|_2$. Applicando ripetutamente la \eqref{eq:3.7} otteniamo

\begin{equation}\nonumber
 \begin{split}						  
		\hat{x}_n &= \hat{\mathbf{A}}_n\hat{\mathbf{x}}_{n-1}+ \mathbf{e}_{n}\\
							&= \hat{\mathbf{A}}_n\hat{\mathbf{A}}_{n-1}\hat{\mathbf{x}}_{n-2}		+	                         			\hat{\mathbf{A}}_n\mathbf{e}_{n-1}
								 +\mathbf{e}_{n}\\
							&\qquad \vdots\\
						  &=\hat{\mathbf{A}}_n...\hat{\mathbf{A}}_{1}\mathbf{x}+\hat{\mathbf{A}}_n ...\hat{\mathbf{A}}_{2}\mathbf{e}_{1} +...+\hat{\mathbf{A}}_n ...\hat{\mathbf{A}}_{j+1}\mathbf{e}_{j}+...+ \hat{\mathbf{A}}_n\mathbf{e}_{n-1}+ \mathbf{e}_{n}
	\end{split}
\end {equation}
Dall'algoritmo \ref{alg:ct-matrix} (CT-Matriciale) ricordiamo che $\mathbf{x}_n = \mathbf{A}_n ...\mathbf{A}_1\mathbf{P}^T\mathbf{x}_{n-1}$ e per el \eqref{eq:3.4},\eqref{eq:3.9},\eqref{eq:3.10},\eqref{eq:3.15}
%\left\|\mathbf{e}_1\right\|_2

\begin{equation}\nonumber						  
		\left\|\hat{\mathbf{x}}_n-\mathbf{x}_n\right\|_2 \leq \left\|\mathbf{A}_n... \mathbf{A}_2\right\|_2\left\|\mathbf{e}_1\right\|_2+...+\left\|\mathbf{A}_n\right\|_2\left\|\mathbf{e}_{n-1}\right\|_2 +\left\|\mathbf{e}_{n}\right\|_2 
\end {equation}

Osserviamo quindi che
\begin{align*}
\left\|\mathbf{A}_n... \mathbf{A}_2\right\|_2\left\|\mathbf{e}_1\right\|_2 &\leq 2^{(n-1)/2} \sqrt{2} u \left\|\mathbf{x}\right\|_2 = 2^{\frac{n}{2}}u\left\|\mathbf{x}\right\|_2\\
\left\|\mathbf{A}_n... \mathbf{A}_3\right\|_2\left\|\mathbf{e}_2\right\|_2 &\leq 2^{(n-2)/2} 2 u \left\|\mathbf{x}\right\|_2 = 2^{\frac{n}{2}}u \left\|\mathbf{x}\right\|_2\\
\left\|\mathbf{A}_n... \mathbf{A}_4\right\|_2\left\|\mathbf{e}_3\right\|_2 &\leq 
2^{(n-3)/2}2^{3/2}((4+\sqrt{2}+\sqrt{2}c_N)u + O(u^2))\left\|\mathbf{x}\right\|_2
\\&\vdots\\
\left\|\mathbf{A}_n... \mathbf{A}_{j+1}\right\|_2\left\|\mathbf{e}_j\right\|_2
&\leq2^{n/2}((4+\sqrt{2}+\sqrt{2}c_N)u + O(u^2))\left\|\mathbf{x}\right\|_2
\\&\vdots\\
\left\|\mathbf{e}_n\right\|_2
&\leq2^{n/2}((4+\sqrt{2}+\sqrt{2}c_N)u + O(u^2))\left\|\mathbf{x}\right\|_2
\end{align*}

Pertanto risulta
\begin{equation}
	\left\|\hat{\mathbf{x}}_n-\mathbf{x}_n\right\|_2 \leq 2^{n/2}(2u +(n-2)((\sqrt{2}c_N+4+\sqrt{2})u + O(u^2)))\left\|\mathbf{x}\right\|_2
\end{equation}

Ricordando che$\left\|\mathbf{X}\right\|_2=\sqrt{N}\left\|\mathbf{x}\right\|_2$,l'errore, come ordine di grandezza, risulta essere\\
$$\left\|\hat{\mathbf{X}}-\mathbf{X}\right\|_2=O(\log_2{N} c_Nu)\left\|\mathbf{X}\right\|_2$$


% 5 
%\item Nel caso di DFT unitaria è necessario operare la normalizzazione $\mathbf{y}=2^{-n/2}\mathbf{x}_n$ del risultato. Siamo nel caso in cui $\mathbf{\hat{y}}=fl(2^{-n/2}\mathbf{\hat{x}}_n)$ e l'operazione è una semplice moltiplicazione tra numero complesso e reale. Otteniamo quindi
%$$\left\|\mathbf{\hat{y}}-2^{-n/2}\mathbf{\hat{x}}_n\right\|_2\leq 2^{-n/2}u\left\|\mathbf{\hat{x}}_n\right\|_2\leq (u+O(u^2))\left\|\mathbf{x}\right\|_2$$
%
%e quindi
%\begin{align}
%\left\|\mathbf{\hat{y}}-\mathbf{y}\right\|_2&\leq\left\|\mathbf{\hat{y}}-2^{-n/2}\mathbf{\hat{x}}_n\right\|_2+\left\|2^{-n/2}\mathbf{\hat{x}}_n-2^{-n/2}\mathbf{x}_n \right\|_2\\
%&\leq\left\|\mathbf{\hat{y}}-2^{-n/2}\mathbf{\hat{x}}_n\right\|_2+2^{-n/2}\left\|\mathbf{\hat{x}}_n-\mathbf{x}_n \right\|_2\\
%&\leq ((\sqrt{2}c_N+4+\sqrt{2})(n-2)u + 3u+ O(u^2))\left\|\mathbf{x}\right\|_2
%\end{align}
%
%La FFT unitaria riduce quindi l'errore di un fattore $1/\sqrt{N}$ e risulta pertanto preferibile\\
%$$\left\|\hat{\mathbf{X}}-\mathbf{X}\right\|_2=O(\log_2{N} c_Nu)\left\|\mathbf{x}\right\|_2$$
\end{enumerate}
\end{proof}



\section{Confronto DFT FFT}
\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/errore-relativo-DFT-FFT}
  \caption{Norma 2 dell'errore tra $x_N$ e $\mathcal{F}^{-1}(\mathcal{F}(x_N))$}
\end{figure}

\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/Bound-DFT}
  \caption{Andamento dell'errore reale e dell'errore massimo per il calcolo della DFT attraverso definizione}
\end{figure}

\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/riepilogo-errore-DFT-FFT-bound}
  \caption{Riepilogo DFT FFT Bounds}
\end{figure}



%%
%
%  stabfinal.ps
%  oppure Computational frameworks for the fast fourier (van loan)
%  % tabella degli errori devi vari metodi
%%
\section{Calcolo dei \emph{twiddle factor}}
Nel calcolo della FFT riveste un'importanza cruciale l'accuratezza con cui vengono calcolati i \emph{twiddle factors}. Tutte le moltiplicazioni complesse infatti coinvolgono elementi dell'input e \emph{twiddle factors} appunto.
In generale per il calcolo di una DFT di lunghezza N è necessario valutare $\omega_N^{0}$, $\omega_N^{1}$, ..., $\omega_N^{N-1}$.
Queste valutazioni comportano il calcolo di funzioni trigonometriche che sono operazioni piuttosto coste.
Presentiamo di seguito alcune famose tecniche per il calcolo dei \emph{twiddle factors}.\\

\noindent Per semplificare la trattazione degli algoritmi presentati non si terrà conto di considerazioni estremamente importanti importanti dal punto di vista implementativo che permettono di ridurre il numero di \emph{twiddle factors} da calcolare sfruttando le proprietà delle radici ennesime dell'unità.
Infatti le radici dell'unità sono dispote sul cerchio immaginario in maniera regolare e questo permette, attraverso relazioni di simmetria, di ridurre di $1/8$ le valutazioni trigonometriche da effettuare.
Più in particolare, per $k=1,... ,N/8 $
\begin{align}
 \hat{\omega}_N^{\frac{N}{4}-k}=-i \overline{\hat{\omega}_N^{k}}, \quad &\text{simmetrie di $\pi/2$ tra i quadranti }\\ 
\hat{\omega}_N^{\frac{N}{4}+k}=-i\hat{\omega}_N^{k},\quad&\text{ I e IV,I e II}\\
\hat{\omega}_N^{\frac{N}{2}-k}=\overline{\hat{\omega}_N^{k}},\quad& \text{simmetrie rispetto asse y}\\
\hat{\omega}_N^{\frac{N}{2}+k}=-\hat{\omega}_N^{k} \quad&
\end{align} 
e inoltre , sfruttando la decomoposizione ricorsiva, $\omega_N^{kp}=w_{\frac{N}{k}}^p$ si può trarre vantaggio dal fatto che alcune radici sono già note\[ \hat{\omega}_N^{\frac{N}{8}}=\hat{\omega}_8=fl\left(\sqrt{2}/2\right)(1-i),\quad \hat{\omega}_N^{\frac{N}{4}}=\hat{\omega}_4=-i,\quad \hat{\omega}_N^{\frac{N}{2}}=\hat{\omega}_2=-1
\]

Queste conderazioni banalizzano alcune moltiplicazioni complesse riducendole a cambiamenti di segno e scambi tra parte reale ed immaginaria: questo si traduce in un numero minore di operazioni reali e pertanto, anche nella riduzione della propagazione degli errori di arrotondamento.
 \subsection{Metodo diretto}
 Consiste nella valutazione banale di ogni $\omega_N^k$ ed effettua 2N valutazioni trigonometriche
 
\begin{algorithm}[H]                      % enter the algorithm environment
\caption{Direct Call}          % give the algorithm a caption
\label{alg1}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
\REQUIRE $N = 2^\nu (\nu\geq3), \theta=2\pi/N$
\FOR{$k=1$ to $N$}
\STATE $\hat{\omega}_N^k \longleftarrow fl(\cos(k\theta)) - i fl(\sin(k\theta))$
\ENDFOR
\end{algorithmic}
\end{algorithm}

Se le funzioni $\cos$ e $\sin$ di libreria sono esatte allora
\begin{equation}
	|\hat{\omega}_N^j -\omega_N^j|=|\epsilon_{j}| \leq \sqrt{2}u/2 = O(u)
\end{equation}


\subsection{Moltiplicazione Ripetuta}
Si basa sulla scomposizione $\omega_N^k = \omega_N \times \omega_N^{k-1} $ ed effettua 2 valutazioni trigometriche e $(N-2)$ moltiplicazioni complesse

\begin{algorithm}[H]                      % enter the algorithm environment
\caption{Repeated Multiplication}          % give the algorithm a caption
\label{alg1}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
\REQUIRE $N = 2^\nu (\nu\geq3), \theta=2\pi/N$
\STATE $\hat{\omega}_N^0 \longleftarrow 1$
\STATE $\hat{\omega}_N \longleftarrow fl(\cos(\theta)) - i fl(\sin(\theta))$
\FOR{$k=2$ to $N-1$}
\STATE $\hat{\omega}_N^k \longleftarrow fl(\hat{\omega}_N \times \hat{\omega}_N^{k-1})$
\ENDFOR
\end{algorithmic}
\end{algorithm}

In questo caso $\hat{\omega}_N^j$ è il  risultato di $j-1$ moltiplicazioni e pertanto si ha che 
\begin{equation}
	|\epsilon_{j}| = O(ju)
\end{equation}

\subsection{Subvector Scaling}
L'idea alla base è la scomposizione 

\begin{align*}
[\underbrace{\omega_N^0,\omega_N^1,...,\omega_N^{\frac{N}{2}-1}}_{N/2},\underbrace{\omega_N^{\frac{N}{2}},\omega_N^{\frac{N}{2}+1}, ..., \omega_N^{N-1}}_{N/2}]=
[\underbrace{\omega_N^0,\omega_N^1,...,\omega_N^{\frac{N}{2}-1}}_{N/2},\omega_N^{\frac{N}{2}}\underbrace{\left(\omega_N^0,\omega_N^1,...,\omega_N^{\frac{N}{2}-1}\right)}_{N/2}]
\end {align*}
che comporta $2\log_2N$ valutazioni trigonometriche $\log_2N$addizioni reali e $2N$ moltiplicazioni complesse

\begin{algorithm}[H]                      % enter the algorithm environment
\caption{Subvector Scaling}          % give the algorithm a caption
\label{alg1}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
\REQUIRE $N = 2^\nu (\nu\geq3), \theta=2\pi/N$
\STATE $\hat{\omega}_N^0 \longleftarrow 1$
\STATE $\hat{\omega}_N \longleftarrow fl(\cos(\theta)) - i fl(\sin(\theta))$
\FOR{$j=1$ to $\nu-1$}
\STATE $u \longleftarrow 2^j \pi/N$
\STATE $\hat{\omega}_N^{2^j} \longleftarrow fl(\cos(u)) - i fl(\sin(u))$
\FOR{$k=1$ to $2^j-1$}
\STATE $\hat{\omega}_N^{k+2^j} \longleftarrow fl(\hat{\omega}_N^{2^j} \times \hat{\omega}_N^{k})$
\ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}

In questo caso $\omega_N^j$ è il risultato di circa $\log_2(j)$ moltiplicazioni di fattori calcolati attraverso direct call. Pertanto l'errore risulta essere: 
\begin{equation}
	|\epsilon_{j}| = O(\log_2(j)u)
\end{equation}


\subsection{Forward Recursion}
Questo metodo è presentato per completezza come esempio di metodo numericamente instabile. Il metodo discende da:
\begin{align}
\cos(A+B) + \cos(A-B) &= 2 \cos(A) \cos(B)\\
\sin(A+B) + \sin(A-B) &= 2 \sin(A) \cos(B)
\end{align}
da cui per $B=\theta$, $A=(j-1)\theta$
\begin{align}
\cos(j\theta) &= 2 \cos(\theta) \cos((j-1)\theta)-\cos((j-2)\theta)\\
\sin(j\theta) &= 2 \cos(\theta) \sin((j-1)\theta)-\sin((j-2)\theta)
\end{align}

\begin{algorithm}[H]                      % enter the algorithm environment
\caption{Forward Recursion}          % give the algorithm a caption
\label{alg1}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
\REQUIRE $N = 2^\nu (\nu\geq3), \theta=2\pi/N$
\STATE $\hat{\omega}_N^0 \longleftarrow 1$
\STATE $\hat{\omega}_N \longleftarrow fl(\cos(\theta)) - i fl(\sin(\theta))$
\STATE $\tau \longleftarrow fl(2\cos(\theta))$
\FOR{$j=1$ to $N-1$}
\STATE $\hat{\omega}_N^{k} \longleftarrow fl(\tau \hat{\omega}_N^{k-1}-\hat{\omega}_N^{k-2})$
\ENDFOR
\end{algorithmic}
\end{algorithm}

Il metodo comporta 2 valutazioni trigonometriche, $2N-1$ moltiplicazioni reali e $2(N-1)$ addizioni reali\\ 
In questo caso l'errore viene amplificato ad ogni step di $|\tau|=|2\cos(\theta)|$ che per $N\geq 6$ risulta già maggiore di 1.
\begin{equation}
	|\epsilon_{j}| = O(\tau^ju)
\end{equation}

\begin{table}[H]
  \caption{Riepilogo errori di arrotondamento per \emph{twiddle factors}}
  \begin{center}
\begin{tabular}{ll}
\toprule
\multicolumn{1}{c}{\emph {Metodo}} & \multicolumn{1}{c}{\emph{Errore in} $w_N^j$}  \\
\midrule
Direct Call & $O(u)$\\
Repeated multiplication & $O(uj)$\\
Subvector Scaling & $O(u\log j)$\\
Forward Recursion & $O(u\tau^j)$\\
\bottomrule
\end {tabular}
\end{center}
\end{table}

\section{Verifiche sperimentali}
I seguenti grafici illustrano l'errore ottenuto con i diversi metodi per il calcolo dei \emph{twiddle factor}.
Sono stati ottenuti generando in matlab un vettore casuale di lughezza $N=2^k$ con distribuzione uniforme e valori compresi tra 0 e 1. A questi vettori è stata quindi applicata FFT e IFFT con i vari metodi e quindi calcolato l'errore relativo$$ \frac{\left\|\text{IFFT}(\text{FFT}(x)) \right\|}{\left\|x\right\|}$$

Nel grafico \ref{tf:dc-rm-vs} sono riepilogati gli andamenti dei vari metodi stabili.
Si noti come direct call e subvector scaling sono praticamente indistinguibili e l'errore sia poco influenzato dalla taglia mentre per repeated multiplication la crescita dell'errore è circa lineare nelle dimensioni dell'ingresso. 
\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/twiddle_factor_cd_rm_vs}
  \caption{Twiddle Factors DC - RM - VS}
  \label{tf:dc-rm-vs}
\end{figure}

L'errore tra DC-VS non è significativamente distinguibile mentre il numero di operazioni richieste da VS è decisamente inferiore.
\
\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/confronto-dc-vs}
  \caption{Confronto DC-VS}
\end{figure}

Il metodo Forward Recursion è instabile ed il suo errore lo rende inutilizzabile già per taglie di poblemi non banali $(N\geq8)$. Il grafico compara l'errore con Forward Recursion e quello della DFT con definizione.
\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/errore-fft_fr_dft}
  \caption{Errore esponenziale}
\end{figure}

\chapter{Applicazioni}
 Per le applicazioni si può vedere Inside the FFT black box capitolo 16
%
% MURLI
%
%
\section{N-FFT di due funzioni reali}

%
% anche dal mitra oppure Brigham cap 1p pg 166
%
%

Nell'applicazione della FFT spesso consideriamo solo funzioni reali del tempo mentre le funzioni in frequenza utilizzate nei calcoli sono, in generale, funzioni complesse. Pertanto, un comune programma in grado determinare la DFT e la sua inversa è scritto in modo da ricevere in input una forma d'onda complessa
\begin{equation}
	H(k)=\sum_{n=0}^{N-1}\left[ h_{Re}(n)+ jh_{Im}(n)\right] e^{-j\frac{2\pi k}{N}n}
\end{equation}
Sfruttando la proprietà \eqref{eq:inverse_computing_rule} per il calcolo dell'inversa è possibile riscrivere
\begin{equation}
	h(n)=\frac{1}{N}{\left[\sum_{k=0}^{N-1}{\left[ H_{Re}(k)+ jH_{Im}(k)\right]}^* e^{-j\frac{2\pi k}{N}n}\right]}^*
\end{equation}
e poichè entrambe contengono $e^{-j\frac{2\pi k}{N}n}$ lo stesso programma può essere usato per calcolare sia la trasformata diretta che la sua inversa.

Se i dati in ingresso sono reali allora la loro parte immaginaria risulterà essere nulla. Tuttavia poichè i programmi effettuano comunque le operazioni anche per i coefficienti posti a zero, otteniamo uno spreco di capacità di calcolo. Varie tecniche possono essere adottate per aumentare l'efficienza di calcolo di sequenze rali.
\\
Volendo infatti calcolare le trasformate di $g(n)$ e $h(n)$ è possibile considerare l'ingresso fittizio $y(n)=g(n)+j \cdot h(n)$, considerando in questo modo $g(n) = {\rm Re}(y(n))$ e $h(n) = {\rm Imm}(y(n))$.
Dopo aver eseguito la N-DFT $Y(k)$ di $y(n)$ è possibile ricavare le DFT di $g(n)$ e $h(n)$:
\begin{equation*}
	G[k] = \frac{1}{2} \left\{ X[k] + X^*[(-k)modN]\right \}
\end{equation*}
\begin{equation*}
	H[k] = \frac{1}{2j} \left\{ X[k] - X^*[(-k)modN]\right \}
\end{equation*}

%Per la linearità della DFT
%\begin{align*}
%Y(k)&= H(k)+jG(k)\\
%&=[H_r(n)+jH_i(n)] + j[G_r(n)+jG_i(n)]\\
%&=[H_r(n)-G_i(n)] + j [H_i(n)+G_r(n)]\\
%&={\rm Re}(n)+j{\rm Imm}(n)
%\end{align*}

% \otimes _N CIRCOLARE SU N
% \odot LINEARE

\section{Convoluzione circolare}

La N-point DFT Y(k) della sequenza $y(n) = g(n) \otimes _N h(n)$ data dalla convoluzione ricolare tra g(n) e h(n) è data da:
\begin{equation}
\label{appl_conv_circ}
	Y(k) = DFT[y(n)] = DFT[g(n) \otimes _N h(n)] = G(k)H(k)
\end{equation}
Di conseguenza è possibile calcolare il risultato della convoluzione circolare y(n) eseguendo la IDFT sulla \eqref{appl_conv_circ}, com'è possibile osservare dalla seguente figura:
\\
\\
\textbf{FIGURA 5.11 pag 261 del MITRA}
\\
\\

\textbf{\textit{Esempio}}
\\
Date le due sequenze
\\$g(n)$ = [1 2 0 1]
\\$h(n)$ = [2 2 1 1]

per calcolare la convoluzione circolare
\begin{equation}
y_C(n) = g(n) \otimes _N h(n) = \sum_{m=0}^{3} g(m)x((n-m)mod4) \qquad 0 \leq n \leq 3
\end{equation}
è possibile considerare le DFT di $g(n)$ calcolata secondo la definizione e di $h(n)$ calcolata secondo la definizione matriciale:
\begin{eqnarray*}
  G(k) &=& g(0) + g(1)e^{-j(2\pi k/4)} + g(2)e^{-j(4\pi k/4)} + g(3)e^{-j(6\pi k/4)}
  \\
       &=& 1 + 2e^{-j(\pi k/2)} + e^{-j(3\pi k/2)} \qquad 0 \leq k \leq 3
  \\
  \\
  G(0) &=& 1 + 2 + 1 = 4
  \\
  G(1) &=& 1 - j2 + j = 1-j
  \\
  G(2) &=& 1 - 2 - 1 = -2
  \\
  G(3) &=& 1 + j2 - j = 1+j
\end{eqnarray*}

\begin{equation*}
  H(k)=
\begin{pmatrix}
H(0)\\
H(1)\\
H(2)\\	
H(3)\\
\end{pmatrix}
= D_4
\begin{pmatrix}
h0\\
h(1)\\
h(2)\\	
h(3)\\
\end{pmatrix}
\begin{pmatrix}1 & 1 & 1 & 1\\
1 & -j & -1 & j\\
1 & -1 & 1 & -1 \\
1 & j & -1 & -j\\	
\end{pmatrix}
\begin{pmatrix}
2\\
2\\
1\\	
1\\
\end{pmatrix}
=
\begin{pmatrix}6\\
1-j\\
0\\	
1+j\\
\end{pmatrix}
\end{equation*}

Applicando la IDFT al prodotto $Y_C(k) = G(k)H(k) = $[24 -j2 0 j2]
si ottiene
\begin{equation*}
  y_C(n)=
\begin{pmatrix}
y_C(0)\\
y_C(1)\\
y_C(2)\\	
y_C(3)\\
\end{pmatrix}
= \frac{1}{4} D_4^*  Y_C(k) = \frac{1}{4}
\begin{pmatrix}
1 & 1 & 1 & 1\\
1 & -j & -1 & j\\
1 & -1 & 1 & -1 \\
1 & j & -1 & -j\\	
\end{pmatrix}
\begin{pmatrix}24\\
-j2\\
0\\	
j2\\
\end{pmatrix}
=
\begin{pmatrix}
6\\
7\\
6\\	
5\\
\end{pmatrix}
\end{equation*}

\section{Convoluzione lineare}



Date due sequenze finite $g(n)$ e $h(n)$ di lunghezza N e M rispettivamente è possibile calcolare la convoluzione lineare
\begin{equation*}
	y_L(n) = g(n) \odot h(n)
\end{equation*}
eseguendo una convoluzione circolare. Definendo le sequenze estese 
\begin{equation*}
	g_e(n)=
	\begin{cases} 
  g(n) \qquad 0 \leq n \leq N-1 \\
  0 \qquad N \leq n \leq L-1
  \end{cases}
\end{equation*}
\begin{equation*}
	h_e(n)=
	\begin{cases} 
  h(n) \qquad 0 \leq n \leq M-1 \\
  0 \qquad M \leq n \leq L-1
  \end{cases}
\end{equation*}
la convoluzione lineare $y_L (n)$ di lunghezza $L = M + N - 1$ corrisponde alla convoluzione circolare tra le sequenza estese:
\begin{equation*}
	y_L(n)=y_C(n)=g_e(n) \otimes _L h_e(n)
\end{equation*}
\\
\\
\textbf{FIGURA 5.13 pag 269 del MITRA}
\\
\\
Nel caso in cui una delle due sequenze sia di durata molto maggiore dell'altra (si può pensare ad una sequenza $x(n)$ di durata infinita e ad una sequenza $h(n)$ di lunghezza M) è possibile utilizzare un metodo detto Overlap-Add, che prevede di suddividere la sequenza di partenza $x(n)$ in più sequenze $x_m(n)$ di campioni non sovrapposti:
\begin{equation*}
	x(n)= \sum_{m=0}^{\infty} x_m(n-mN)
\end{equation*}
dove
\begin{equation*}
	x_m(n)=
	\begin{cases} 
  x(n+mN) \qquad 0 \leq n \leq N-1 \\
  0 \qquad altrove
  \end{cases}	
\end{equation*}
E' possibile calcolare la convoluzione lineare
\begin{equation*}
	y(n)= h(n) \odot x(n) = \sum_{l=0}^{M-1} h(l)x(n-l)
\end{equation*}
come
\begin{eqnarray*}
	y(n)&=& \sum_{l=0}^{M-1} h(l) \left( \sum_{m=0}^\infty x_m(n-l-mN) \right)
	    \\
	    &=& \sum_{m=0}^{\infty} \left ( \sum_{l=0}^{M-1} h(l) x_m(n-l-mN) \right )
	    \\
	    &=& \sum_{m=0}^{\infty} y_m(n-mN)
\end{eqnarray*}
dove 
\begin{equation*}
	y_m(n)= h(n) \odot x_m(n)
\end{equation*}
La convoluzione lineare $y(n)$ viene così suddivisa in più convoluzioni lineari $y_m(n)$ di lunghezza minore $(N + M - 1)$.
Per esempio $y_0(n)= h(n) \odot x_0(n)$ è definita per $0 \leq n \leq N+M-2$ e $y_1(n)= h(n) \odot x_1(n)$ è definita per $N \leq n \leq 2N+M-2$; la sovrapposizione tra gli $M-1$ elementi di $y_0(n)$ e $y_1(n)$ viene risolta sommando tali elementi per otterenere la sequenza definitiva $y(n)$.
\\
\\
\textbf{FIGURA 5.15 DEL MITRA, PAG 272}
\\
\\

\section{Moltiplicazione di polinomi}

Un'altra applicazione della DFT che fa uso del prodotto di convoluzione riguarda il calcolo dei coefficienti del polinomio prodotto di due polinomi.
Siano ad esempio assegnati due polinomi
\begin{equation*}
	p(x) = 1 + 5x + 17x^2
\end{equation*}
\begin{equation*}
	q(x) = 11 +6x -4x^2
\end{equation*}
Definiti i vettori
\begin{equation*}
	a = [1,5,17,0,0] \qquad e \qquad b = [11,6,-4,0,0]
\end{equation*}
i coefficienti del polinomio z di quarto grado prodotto di p e di q si ottengono effettuando il prodotto di convoluzione lineare dei vettori a e b, ovvero:
\begin{equation*}
c = a \odot b = (11,61,213,82,-68,0,0,0,0)
\end{equation*}
che corrisponde al polinomio
\begin{equation*}
	z(x) = p(x)q(x) = 11 +61x +213x^2 +82x^3 -68x^4
\end{equation*}

Per determinare i coefficienti di z si può utilizzare l'operatore DFT. Posto:
\begin{equation*}
A = DFT[a] = (23, -11.2082 -i14.7476, 2.082 + i13.229, 2.2082 -i13.229, -11.2082 + i14.7476)
\end{equation*}
\begin{equation*}
B = DFT[b] = (13, 16.0902 - i3.3552, 4.9098 - i7.3309, 4.9098+ i7.3309, +16.0902+ i3.3552)
\end{equation*}
utilizzando il seguente teorema
\begin{equation*}
C = DFT(c) = DFT[a \odot b] = A .* B
\end{equation*}
si ottiene
\begin{equation*}
C = (299, -229.82 -i199.69, 107.82 + i48.76; 107.82 - i48.76, -229.82 + i199.69)
\end{equation*}
da cui:
\begin{equation*}
c := IDFT(C) = (11, 61, 213, 82, -68)
\end{equation*}
Il calcolo dei coefficienti del prodotto di due polinomi si riduce, quindi, al calcolo di 3 DFT.






\section{FFT N-dimensionale e immagini}
\begin{equation}
X_{k_1,k_2,...,k_d}=
\sum_{n_1=0}^{N_1-1}\left(
\sum_{n_2=0}^{N_2-1}...\left(
\sum_{n_d=0}^{N_d-1}
x_{k_1,k_2,...,k_d}
\omega_{N_d}^{k_dn_d}\right)
...\quad
\omega_{N_2}^{k_2n_2}\right)
\omega_{N_1}^{k_1n_1}
% \quad k=0,...,N-1
\end{equation}
con $k_l=0,1,...,N_l-1$
La DFT multidimensionale può essere calcolata, sfuttando la separabilità dell'operatore DFT, attraverso applicazioni successive della DFT monodimensionale per ciascuna delle $d$ dimensioni.\\


Nel caso delle immagini (2-D) questa si riduce a
\begin{equation}
	F(u,v)= \sum_{x=0}^{M-1} \sum_{y=0}^{N-1} f(x,y) e^{-j2\pi(\frac{ux}{M}+\frac{vy}{N})}
\end{equation}

Abbiamo sviluppato un semplice programma in C\# che è in grado di calcolare la 2D FFT di un'immagine e qualche operazione basilare di filtraggio.\\
La scelta del C\# è stata determinata dal fatto che il linguaggio offre la potenzialità dei costrutti C++ con in più notevoli classi di supporto al caricamento delle immagini da formati diversi e la loro conversione in bitmap, alla loro visualizzazione e manipolazione, e a basilari operazioni di editing e interazione con l'utente attraverso il modulo drawing.

\paragraph{Fasi}
\begin{enumerate}
	\item Moltiplicazione dell'immagine originale $f(x,y)$ per $(-1)^{x+y}$
	\item Calcolo DFT $F(u,v)$
	\item editing $F(u,v)$
	\item $f(x,y)=$IDFT$F(u,v)$
	\item Moltiplicazione di $f(x,y)$ per $(-1)^{x+y}$
\end{enumerate}




\include{appendice}
\include{bibliografia}
\end{document}