\documentclass[a4paper,14pt,openright]{report}

\usepackage[latin1]{inputenc}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{amsmath,amssymb,amsthm}
\usepackage[none]{hyphenat} 
\usepackage{float} % parametro H in figur : posizionamento esattamente li
\usepackage{verbatim}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage{algorithmic}
\usepackage[boxed]{algorithm}



\usepackage{fancyhdr}
\setcounter{tocdepth}{3}

\include{miei_comandi}
\frenchspacing
%\pagestyle{headings} % {headings,plain ,empty}
\linespread{1.3}
\DeclareGraphicsRule{.eps,.ps,.png}{bmp}{.bb}{} % formati utilizzabili con ordine di preferenza 
                                                % cosi non devo indicare le estensioni
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}


%\author{\emph{Marco Bettiol}\quad{} 586580\\\emph{Antonio Quercia}\quad{}  588537}

\title{}
\begin{document}

\include{mytitle}

\tableofcontents


\chapter{DFT}
La trasformata discreta di Fourier, talvolta chiamata anche \emph{trasformata di Fourier finita}, \`e la trasformata di Fourier di un segnale a tempo discreto e con \emph{dominio finito}. Come le altre trasformate di Fourier, essa esprime un segnale in termini di una somma di componenti sinusoidali, determinandone ampiezza e fase per ciascun componente. Tuttavia, la DFT si distingue dal fatto che la funzione d'ingresso \`e \emph{discreta e finita}: ossia \`e una sequenza finita di numeri reali o complessi, e questo fatto rende la DFT ideale per processare le informazioni memorizzate nei calcolatori. Nel seguito verranno discusse alcune applicazioni della DFT e come pu\`o essere efficientemente implementata in un calcolatore, attraverso algoritmi di \emph{FFT (Fast Fourier Transform)}.

\section{Definizione}

Un vettore $x$ di lunghezza N può essere visto come una sequenza $x_0,...,x_{N-1}$ di N numeri complessi. Si definisce $X$ \emph{trasformata discreta di Fourier (DFT, discrete Fourier transform)}  di $x$ la sequenza $X_0,...,X_{N-1}$ espressa dalla seguente relazione:
\begin{equation}
\label{eq:def-dft}
X_k=\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn} \quad k=0,...,N-1
\end{equation}
Ricordando la \emph{Formula di Eulero}

\begin{equation*} 
e^{\pm i 2\pi\omega x} = \cos( 2\pi \omega x) \pm i \sin(2\pi \omega x)
\end{equation*}
è evidente come, in generale, $X$ possa risultare in una sequenza complessa sebbene $x$ fosse reale.\\
La relazione inversa della \eqref{eq:def-dft}, chiamata \emph{trasformata discreta inversa di Fourier (IDFT, inverse discrete Fourier transform)} è data da:
\begin{equation}
x_n=\frac{1}{N}\sum_{k=0}^{N-1}X_ke^{\jmath\frac{2\pi}{N}kn} \quad k=0,...,N-1
\label{def_idft}
\end{equation}
Da \ref{def_idft} si può notare che i numeri complessi $X_k$ rappresentano l'ampiezza e la fase delle diverse componenti sinusoidali del "`segnale"' d'ingresso $x_n$.
\\Introduciamo quindi la seguente notazione per indicare DFT e IDFT
\begin{align*}
X &= \mathcal{F}x\\
x &= \mathcal{F}^{-1}X
\label{def_idft}
\end{align*}
e inoltre indichiamo esplicitamente con $x_N$ (pedice maiuscolo) un vettore $x$ $N$-dimensionale e con $X_N$ la sua trasformata.


%A normalization of 1/\sqrt{N} for both the DFT and IDFT makes the transforms unitary, which has some theoretical advantages, but it is often more practical in numerical computation to perform the scaling all at once as above (and a unit scaling can be convenient in other ways).

\section{Proprietà}

Descriviamo alcune delle proprietà più significative della DFT, ovvero consideriamo quelle proprietà che sono alla base delle applicazioni della DFT. Le prime proprietà discendono direttamente dalla definizione dell'operatore DFT e riguardano la linearità,la periodicità e la simmetria. La linearità viene utilizzata specialmente nelle applicazioni
in cui il vettore di cui bisogna calcolare la DFT si può decomporre nelle sue componenti armoniche e attraverso l'analisi della DFT di tali componenti si possono trarre informazioni significative sul vettore iniziale (questo è ad esempio il principio alla base dell'analisi armonica di funzioni periodiche). La proprietà di periodicità consente
di prolungare periodicamente il vettore di cui calcolare la DFT senza alterarne il risultato numerico. Infine la simmetria trova applicazione negli schemi di memorizzazione alla base degli algoritmi numerici per il calcolo di una DFT.\\
La maggior parte delle proprietà valide per la trasformata di Fourier a tempo continuo hanno un analogo equivalente anche per la DFT.\\ Il cambiamento più significativo da apportare ai teoremi per adattarli al caso finito-discreto è quello di modificare gli indici per tenere conto della periodicità della DFT, ovvero prendere gli indici modulo $\mathbf{N}$.

\noindent Date $X$ e $Y$ le DFT di $x$ e $y$ rispettivamente, valgono:

\begin{enumerate}[i.]
\item Completezza:\\
La DFT è una trasformazione \emph{lineare e invertibile}:
\begin{equation}
\mathcal{F} : \mathbb{C}^N\longrightarrow\mathbb{C}^N
\end{equation}
dove $\mathbb{C}$ è l'insieme complesso.
\[x\xrightleftharpoons[\mathcal{F}^{-1}]{\mathcal{F}} X \]
DFT e IDFT mappano vettori complessi $N$-dimensionali in vettori complessi $N$-dimensionali attraverso una corrispondenza biunivoca.

\item Ortogonalità:\\
I vettori $e^{\jmath \frac{2\pi}{N}kn}$ formano una \emph{base ortogonale} per l'insieme dei vettori complessi $N$-dimensionali:
\begin{equation}
\label{eq:dft-orthogonality}
\sum_{n=0}^{N-1}(e^{\jmath\frac{2\pi}{N} kn})(e^{-\jmath\frac{2\pi}{N}k'n})=N\delta_{kk'}
\end{equation}
dove $\delta_{kk'}$ \`e il delta di Kronecker. 
\[\delta_{kk'} = 
\begin{cases} 
1 & \text{if } k = k' \\
0 & \text{if } k \neq k'
\end{cases}\]
Questa condizione pu\`o essere sfruttata per ricavare la formula della IDFT dalla definizione di DFT.

\item Teorema di Parseval:\\
in generale per segnali ortognolali si ha che
\begin{equation}
\sum_{n=0}^{N-1}x_ny_n^*=\frac{1}{N}\sum_{k=0}^{N-1}X_kY_k^*
\end{equation}
se $y=x^*$ otteniamo il  \emph{teorema di Parseval}
\begin{equation}
\sum_{n=0}^{N-1}|x_n|^2=\frac{1}{N}\sum_{k=0}^{N-1}|X_k|^2
\end{equation}

\item Periodicità:\\
Se la relazione \ref{eq:def-dft} che definisce la DFT è valutata per tutti i $k$ interi anzichè soltanto $k=0,...,N-1$, allora la sequenza infinita risultante \`e un'\emph{estensione periodica} di periodo $N$ della DFT. Tale periodicità può essere mostrata direttamente dalla definizione:
\begin{eqnarray}
X_{k+N}&=&\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}(k+N)n}\\
&=&\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn}e^{-\jmath 2\pi n}\\
&=&\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn}\\
&=&X_k
\end{eqnarray}
dove si è utilizzato il fatto che $e^{-2\pi \jmath}=1$. Allo stesso modo pu\`o essere mostrato che la \ref{def_idft} porta a un'estensione periodica della IDFT.

\item Il \emph{Circular shift theorem}:\\
Moltiplicare $x_N$ per una fase lineare $e^{-\jmath\frac{2\pi}{N}nm}$, per un qualche $m$ intero, è equivalente ad uno shift circolare di $X_N$ di $m$ posizioni: $X_k$ diventa $X_{k-m}$, il cui pedice si deve intendere come \emph{modulo N}. Analogamente, uno shift circolare di $x_N$ corrisponde alla moltiplicazione di $X_N$ per una fase lineare.
\begin{equation}
se\;\mathcal{F}((x_n))_k=X_k
\end{equation}
\begin{equation}
allora\;\mathcal{F}((x_ne^{\jmath\frac{2\pi}{N}nm}))_k=X_{k-m}
\end{equation}
\begin{equation}
e\;\mathcal{F}((x_{n-m}))_k=X_ke^{-\jmath\frac{2\pi}{N}km}
\end{equation}

\item \emph{Linear Convolution Theorem}\\
Siano $x=x_N$ e $y=y_N$ due vettori arbitrari $N$-dimensionali e sia $z=x \ast y$, un vettore di $2N-1$ componenti ottenuto dalla convoluzione lineare $\ast$.\\ Allora,\\
\begin{equation}
	z_i=\sum_{j=\max\{0,i-N+1\}}^{\min\{i,N-1\}}{x_i y_{i-j}} \qquad 0\leq i \leq 2N-1
\end{equation}
\\
dove i limiti superiore e inferiore della sommatoria sono scelti in modo tale che $i$ e $i-j$ siano sempre nell'intervalllo $[0$ $N-1]$.
Possiamo calcolare la convoluzione lineare utilizzando la DFT nel seguente modo:\\
\begin{equation}	
	(z|0_1)= \mathcal{F}_{2N}^{-1}(\mathcal{F}_{2N} (x|0_{N}) \odot \mathcal{F}_{2N} (y|0_{N})
\end{equation}\\
dove $\odot$ indica il prodotto componente per componente e $(x|0_k)$ indica il vettore ottenuto estendendo il vettore $x_{N}$ con padding di $k$ zero in coda.

\item \emph{Cyclic Convolution Theorem}\\
Siano $x=x_N$ e $y=y_N$ due vettori arbitrari $N$-dimensionali, definiamo \emph{convoluzione ciclica} di $x$ e $y$, indicata con $x \circledast y$, il vettore w di $N$ componenti dato da:
\\
\begin{equation}
	w_i=\sum_{j=0}^{N-1}{x_i y_{(i-j) \mod N }} \qquad 0\leq i \leq N-1
\end{equation}
\\
Possiamo calcolare la convoluzione ciclica utilizzando la DFT nel seguente modo:\\
\begin{equation}	
	w= \mathcal{F}_{N}^{-1}(\mathcal{F}_{N} x \odot \mathcal{F}_{N} y)
\end{equation}\\
dove $\odot$ indica il prodotto componente per componente.

%
% Corollari convoluzione ciclica <--> lineare (pucci)
%
\end{enumerate}

\section{Defizione Matriciale}
Dalla definizione \eqref{eq:def-dft} di DFT emerge immadiatamente una interpretazione matriciale della \emph{trasformata discreta di Fourier} \\
\begin{equation}
X=\mathcal{F}(x) = F_N x
\end{equation}\\
con 
\begin{equation}
x=
\left(
\begin{array}{c}
x_0\\
x_1\\
...\\
x_{N-1}	
\end{array}\right)
\end{equation}
\vskip 5pt e\vskip 5pt
\begin{equation}
F_N=
\left(
\begin{array}{clrr}
\omega_N^{0\cdot0} & \omega_N^{0\cdot1} & ... & \omega_N^{0\cdot(N-1)}\\
\omega_N^{1\cdot0} & \omega_N^{1\cdot1} & ... & \omega_N^{1\cdot(N-1)}\\
      ...     &     ...       & ... &         ...\\
\omega_N^{(N-1)\cdot0} & \omega_N^{(N-1)\cdot1} & ... & \omega_N^{(N-1)\cdot(N-1)}	
\end{array}\right)
\end{equation}
Il termine 
\begin{equation}
\omega_N=e^{-\jmath \frac{2\pi}{N}}
\end{equation}
\`e una \emph{radice complessa N-esima dell'unita}.\\
L'elemento in posizione $(i,j)$ della matrice \`e $\omega_N^{ij}$, con $i,j=0,1,...,N-1$.\\

\noindent Analogamente è possibile esprimere la IDFT come:
\begin{equation}
x=\mathcal{F}^{-1}(X)=F_N^{-1}X
\end{equation}
Dove $F_N^{-1}$ \`e la \emph{matrice inversa} di $F_N$ e può essere facilmente ottenuta da $F$ attraverso
\begin{equation}
	F_N^{-1} =\frac{1}{N} F_N^{*}
\end{equation}
dove pertanto in posizione $(i,j)$ di $F_N^{-1}$ è presente il valore
 $\frac{1}{N}\omega_N^{-ij}$
 
Dalla proprietà \eqref{eq:dft-orthogonality} emerge che 
\begin{equation*}
	F_N^*F_N=N\cdot I
\end{equation*}
questo significa che le colonne di $F$ sono \emph{ortogonali}. Indicando con $F^j$ la j-esima colonna di $F_N$ possiamo scrivere:
\begin{align}
\mathbf{F}_N^*\mathbf{F}_N&=
\begin{bmatrix}
	\langle F^0, F^0\rangle & \left\langle F^0, F^1\right\rangle &\left\langle F^0, F^2\right\rangle & \cdots & \left\langle F^0, F^{N-1}\right\rangle\\
	\left\langle F^1, F^0\right\rangle & \left\langle F^1, F^1\right\rangle &\left\langle F^1, F^2\right\rangle & \cdots & \left\langle F^1, F^{N-1}\right\rangle\\
	\left\langle F^2, F^0\right\rangle & \left\langle F^2, F^1\right\rangle &\left\langle F^2, F^2\right\rangle & \cdots & \left\langle F^2, F^{N-1}\right\rangle\\
	\vdots &\vdots & \vdots & \ddots & \vdots \\
	\left\langle F^{N-1}, F^0\right\rangle & \left\langle F^{N-1}, F^1\right\rangle &\left\langle F^{N-1}, F^2\right\rangle & \cdots & \left\langle F^{N-1}, F^{N-1}\right\rangle\\
\end{bmatrix}\\
&=
\begin{bmatrix}
 N & 0 & 0 & ... & 0\\  0 & N & 0 & ... & 0\\  0 & 0 & N & ... & 0\\ \vdots &\vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & ... & N\\
\end{bmatrix} = N\cdot \mathbf{I}
\end{align}
Questo ci è utile per definire le versioni normalizzate  della DFT/IDFT con matrici unitarie
\begin{equation}
	\widetilde{F}_N=\frac{1}{\sqrt{N}} F_N  \qquad \qquad  \widetilde{F}_N^*=\frac{1}{\sqrt{N}} F_N^*
\end{equation}
Le matrici ortogonali (unitarie) sono infatti usate per garantire stabilità numerica e scarsa sensibilità agli errori di arrotondamento.\\
Riepiloghiamo brevemente alcune proprietà delle matrici ortogonali (unitarie):
\begin{itemize}
	\item $\left\|Sx\right\|_2=\left\|x\right\|_2 \qquad \forall x$
	\item $\left\|S\right\|_2=\left\|S^{-1}\right\|_2=1$
	\item $\left\|A\right\|_2=\left\|SAT\right\|_2 \qquad \forall S,T \quad \text{ortogonali (unitarie)}$
\end{itemize}
\subsection{Analogie tra DFT e IDFT}
Questa affinità tra $F_N$ e $F_N^{-1}$ mette in risalto come in realtà la procedura per il calcolo di DFT e IDFT sia esattamente la stessa a meno di minimi adattamenti.\\
In altre parole è possibile calcolare la IDFT attraverso lo stesso algoritmo di \emph{forward computation} della DFT attraverso un semplice preprocessing dell'input e moltiplicazione per un fattore di scala:
\begin{equation}
	\mathcal{F}^{-1}(\{x_n\})= \frac {1}{N}\mathcal{F}(\{x_{N-n}\})
\end{equation}
dove l'operazione effettuata sull'input risulta essere un \emph{inversione dell'input modulo $N$}:\vskip 5pt
\begin{equation}
\left(
\begin{array}{c}
x_0\\x_1\\x_2\\...\\x_{N-2}\\x_{N-1}\\
\end{array}\right)\longrightarrow
\left(
\begin{array}{c}
x_0\\x_{N-1}\\x_{N-2}\\...\\x_{2}\\x_{1}\\
\end{array}\right)
\end{equation}\vskip 5pt
Analogamente è possibile sfruttare la seguente proprietà per il calcolo della IDFT
\vskip 5pt
\begin{equation}	
	\mathcal{F}^{-1}\left( x \right) = \frac{1}{N}{(\mathcal{F} (x^*))}^*
	\label{eq:inverse_computing_rule}
\end{equation}
\vskip 5pt
coniugando l'input, applicando la DFT, coniugando l'output e quindi scalando.

\section{Segnali di durata finita: relazione tra trasformata di Fourier DTFT e DFT}

% CTFT Mitra 3.1.1
% DTFT M 3.2.1 3.2.2
% DFT intro pag 233, 5.3.1, (5.2.1) 5.3.2 5.3.3

In questo paragrafo si esaminerà la relazione fra la Discrete-Time Fourier Transform (DTFT) e la N-point DFT.

La DTFT  $X(e^{j\omega})$ di una sequenza $x[n]$ definita per $0 \leq n \leq N-1$ è data da:
\\
\begin{equation}
	X(e^{j\omega}) = \sum_{n=-\infty}^{\infty}{x_ne^{-j\omega n}} = \sum_{n=0}^{N-1}{x_ne^{-j\omega n}}
\end{equation}
\\
Campionando uniformemente $X(e^{j\omega})$ su N frequenze $\omega_k = \frac{2\pi k}{N} , 0 \leq k \leq N-1$, con $0 \leq \omega \leq 2\pi$, si ottiene
\\
\begin{equation}
\label{eq:dtft-campionamento}
	X(e^{j\omega})| _{\omega=\frac{2\pi k}{N}} = \sum_{n=0}^{N-1}{x_ne^{-j\frac{2\pi k}{N} n}} ,\qquad 0 \leq k \leq N-1
\end{equation}
\\
Confrontando la definizione di DFT (1.1)%\eqref{eq:def-dft}
\begin{equation*}
X_k=\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi k}{N}n} \quad k=0,...,N-1
\end{equation*}
con la \eqref{eq:dtft-campionamento}, è possibile osservare che la N-point DFT $X_k$ corrisponde esattamente alla DFTF $X(e^{j\omega})$ campionata  sulle frequenze $\omega_k = \frac{2\pi k}{N} , 0 \leq k \leq N-1$; di conseguenza la frequenza angolare $\omega$ associata all'elemento di indice $k$ è $\frac{2\pi k}{N}$.

La DFT costituisce un valido metodo per il calcolo della DTFT di una sequenza finita, in particolar modo se sono disponibili algoritmi efficienti (FFT) per la sua determinazione.

Si consideri di voler valutare $X(e^{j\omega})$, la DFTF di una sequenza $x_n$ di lunghezza N su un insieme più denso di frequenze $\omega _k=\frac{2\pi k}{M}, 0 \leq k \leq M-1$, dove $M>>N$:
\\
\begin{equation}
\label{eq:dtft-x-estesa-1}
	X(e^{j\omega _k}) = \sum_{n=0}^{N-1}{x_ne^{-j\omega _k n}} = \sum_{n=0}^{N-1}{x_ne^{-j\frac{2\pi k}{M} n}}
\end{equation}
\\
\'E possibile definire la sequenza $x_n^e$ ottenuta eseguendo su $x_n$ uno zero-padding di lunghezza $M - N$:

\begin{equation*}
\label{eq:dtft-x-estesa-2}
x_n^e = 
\begin{cases} 
x_n \qquad 0 \leq n \leq N-1 \\
0 \qquad N \leq n \leq M-1
\end{cases}
\end{equation*}
Tenendo in considerazione che le sequenze $x_n$ e $x_n^e$ sono definite su domini differenti, facendo uso della definizione di $x_n^e$ si giunge a:
\\
\begin{equation}
\label{eq:dtft-x-estesa-3}
	X(e^{j\omega _k}) = \sum_{n=0}^{M-1}{x_n^e e^{-j\frac{2\pi k}{M} n}} = X_k^e
\end{equation}
\\
che corrisponde alla M-point DFT $X_k^e$ (della sequenza $x_n^e$ di lunghezza M), che può essere facilmente calcolata avvalendosi della FFT se M è potenza di 2.
\\
\\
\textbf{DFTF come interpolazione della DFT}
\\
\\
Data la N-point DFT $X_k$ di una sequenza $x_n$ di lunghezza n è possibile determinare la DTFT $X(e^{j\omega})$ eseguendo l'operazione di intepolazione sui valori di  $X_k$.
Dalla definizione di DTFT
\\
\begin{equation}
\label{eq:dtft-def}
	X(e^{j\omega}) = \sum_{n=0}^{N-1}{x_n e^{-j\omega n}}
\end{equation}
\\
e dalla definizione di IDFT (1.2)
\\
\begin{equation*}
	x_n=\frac{1}{N}\sum_{k=0}^{N-1}X_ke^{\jmath\frac{2\pi}{N}kn}
\end{equation*}
\\
è possibile ricavare
\begin{eqnarray}
\label{eq:dft-interpolation-1}
	X(e^{j\omega}) &=& \sum_{n=0}^{N-1}{\left[\frac{1}{N}\sum_{k=0}^{N-1}X_ke^{\jmath\frac{2\pi}{N}kn}\right] e^{-j\omega n}}\\
	&=& \frac{1}{N}\sum_{k=0}^{N-1}{X_k \sum_{n=0}^{N-1}{e^{\jmath\frac{2\pi}{N}kn} e^{-j\omega n}}}
\end{eqnarray}
\\
Riscrivendo la parte destra della relazione precedente utilizzando la seguente proprietà
\\
\begin{equation*}
	\sum_{n=0}^{N-1}u^n = \frac{1-u^N}{1-u}
\end{equation*}
\\
si ottiene
\\
\begin{eqnarray}
\label{eq:dft-interpolation-2}
	\sum_{n=0}^{N-1}{e^{\jmath\frac{2\pi}{N}kn} e^{-j\omega n}} &=& \frac{1-e^{-j(\omega N-2\pi k)}}{1-e^{-j[\omega -(2\pi k/N)]}}
	\\
	&=& \frac{e^{-j[(\omega N-2\pi k)/2]}}{e^{-j[(\omega N-2\pi k)/2N)]}} \frac{\sin(\frac{\omega N-2\pi k}{2})}{\sin(\frac{\omega N-2\pi k}{2N})}
	\\
	&=& \frac{\sin(\frac{\omega N-2\pi k}{2})}{\sin(\frac{\omega N-2\pi k}{2N})} e^{-j[\omega -(2\pi k/N)][(N-1)/2]}
\end{eqnarray}
\\
Sostituendo la \eqref{eq:dft-interpolation-2} nella \eqref{eq:dft-interpolation-1} si giunge a
\\
\begin{equation}
\label{eq:dft-interpolation-3}
	X(e^{j\omega}) = \frac{1}{N}\sum_{k=0}^{N-1}{X_k \frac{\sin(\frac{\omega N-2\pi k}{2})}{\sin(\frac{\omega N-2\pi k}{2N})} e^{-j[\omega -(2\pi k/N)][(N-1)/2]} }
\end{equation}
\\
che può essere riscritta come
\\
\begin{equation}
\label{eq:dft-interpolation-4}
	X(e^{j\omega}) = \sum_{k=0}^{N-1}{X_k \phi(\omega -\frac{2\pi k}{N}) }
\end{equation}
\\
definendo
\\
\begin{equation}
\label{eq:dft-interpolation-5}
	\phi(\omega) = \frac{1}{N} \frac{\sin(\frac{\omega N}{2})}{\sin(\frac{\omega}{2})} e^{-j\omega[(N-1)/2]}
\end{equation}
\\
E' possibile verificare che
\\
\[\phi(\omega)|_{\omega=2\pi k/N} =  
\begin{cases} 
1 k = 0 \\
0 1 \leq k \leq N-1
\end{cases}\]
\\
e di conseguenza
\\
\begin{equation*}
	X(e^{j\omega})| _{\omega=2\pi k/N} = X_l \qquad 0 \leq k \leq N-1
\end{equation*}
\\
In definitiva è possibile ottenere $X(e^{j\omega})$ al variare di $\omega$ in $\mathbb{R}$ considerando gli elementi della DFT $X_k$ come i valori di $X(e^{j\omega})$ in \$omega = $ 2 \pi k \setminus N$, $0 \leq k \leq N-1$ e considerando, per gli altri valori di $\omega$, il risultato dell'interpolazione \eqref{eq:dft-interpolation-3}

\chapter{Calcolo della DFT}

La diffusione nell'utilizzo della DFT è principalmente dovuta all'introduzione, avvenuta negli anni '60, di una classe di algoritmi computazionale efficienti per la sua valutazione: la \emph{(Fast Fourier Transform, i.e. trasformata veloce di Fourier)}.\\ Essa rende possibile in taluni casi l'elaborazione in tempo reale (sistemi di navigazione, trasmissione e processo di segnali vocali o televisivi) e consente di risolvere alcuni problemi di grandi dimensioni che risulterebbero altrimenti intrattabili.\\
L'FFT viene normalmente attribuita a Cooley e Tukey. Di fatto questo particolare algoritmo venne scoperto (ed usato) da Gauss nel XIX secolo. Pare che in realtà l'algoritmo sia stato riscoperto ed utilizzato varie volte (anche prima del lavoro di Cooley e Tuckey menzionato sopra).
Grazie alla FFT, infatti, è possibile implementare al calcolatore operazioni nel dominio della frequenza, cioè utilizzando le trasformate di Fourier, con complessità di calcolo inferiore a quella ottenibile implementando lo stesso calcolo nel dominio del tempo.\\
\newpage
\section{Attraverso la definizione}
La tecnica di calcolo banale passa per la definizione stessa di DFT
\begin{equation*}
X_k=\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn} \quad k=0,...,N-1
\end{equation*}
ed essendo 
\begin{equation*}
\mathcal{F} : \mathbb{C}^N\longrightarrow\mathbb{C}^N
\end{equation*}
ci sono $N$ termini da calcolare, ognuno dei quali richiede $N$ moltiplicazioni e $N-1$ addizioni complesse. Anche evidando di calcolare le moltiplicazioni per $\omega_{N}^{0}=1$ si devono comunque effettuare in totale $2(N-1)^2$ operazioni complesse. Il costo è pertanto $O(N^2)$

Nel dettaglio ogni moltiplicazione complessa $\lambda = z_1 \cdot z_2 = (a + jb) \cdot (c + jd)$ si sviluppa in 
\begin{align*}
m1 &= (a + b) \cdot c\\
m2 &= (d + c) \cdot b\\
m3 &= (d - c) \cdot a\\
\rm{Re}(\lambda) &= m1 - m2\\
\rm{Im}(\lambda) &= m1 + m3\\
\end{align*}
richiedendo 4 moltiplicazioni reali e 2 addizioni e pertanto il numero di operazioni macchina totali risultante è $4(N-1)^2$ moltiplicazioni e $2N(N-1)+2(N-1)^2= 2(N-1)(2N-1)$ addizioni.

Nel modello di calcolo da noi considerato assumeremo, come effettivamente si verifica per i moderni apparecchi di calcolo, che il tempo impiegato per effetuare una addizione o moltiplicazione sia lo stesso.

Inoltre, poichè nel caso della FFT, tutte le moltiplicazioni complesse coinvolgono un "`twiddle factor"' $\omega_N^l = c + jd$, e un ulteriore termine è possibile precalcolare, oltre che precalcolarli è possibile salvarsi anche i risultati intermedi $c+d$ e $c-d$ in modo che una moltiplicazione complessa richeda solo $5$ operazioni totali. 

%Un'altra scomposizione che può risultare vantaggiosa è $(a+jb)(c+jd)=a(c+d)-d(a+b)+j[a(c+d)+c(b-a)]$
%3 moltiplicazioni e 5 addizioni reali.
%As noted earlier, most high-performance workstations can perform multiplications as additions
%fast as additions

\section{Algoritmi sequenziali per il calcolo di FFT}
Sia $T(N)$ il tempo di calcolo associato ad un problema di cardinalità $N$ e supponiamo per semplicità $N=2^\nu$.\\
Se partizioniamo gli $N$ dati in due sottoinsiemi di $N/2$ dati:
\begin{equation}
	N \longrightarrow \frac{N}{2} + \frac{N}{2},
\end{equation}
risolviamo i due sottoproblemi e ricombiniamo le due soluzioni, il tempo di calcolo diviene:
\begin{equation}	
	T(N) = 2 \cdot T\left(\frac{N}{2}\right)+ R(N)
\end{equation}
con $R(N)$ pari al costo di combinazione. Allo stesso risultato si arriva se $R(N)$ rappresenta il costo di costruzione e/o ricombinazione dei due sottoproblemi.

Non è difficile verificare che se $R(N)= O(N)$, cioè il costo di ricombinazione è lineare nei dati e si itera il procedimento fino ad $N$ sottoinsiemi di un solo dato, il tempo di calcolo relativo alla procedura diventa:
\begin{equation}
	T(N) = O(N \cdot \log_2(N))
\end{equation}
qualsiasi sia la complessita di calcolo originale $T(N)$, purchè di tipo polinomiale, cioè del tipo
\begin{equation}
T(N) = O(N^\alpha), \quad \alpha \in \mathbb{R}
\end{equation}
Ovviamente, minore è la complessità originaria (quindi l'esponente $\alpha$) e più piccolo sarà il tempo di calcolo al quare si arriva applicando il principio \emph{"`divide et impera"'}; in ogni caso, comunque, esso sarà dell'ordine di $N \cdot \log_2 N$

Osserviamo inoltre che il principio \emph{"`divide et impera"'} conduce spontaneamente a strutture di calcolo parallele. Con $N=2_\nu$, le partizioni dei dati più efficienti sono le più "`spontanee"', e sono "`schematizzate"' nella figura seguente per $N=8$
\vskip 30pt
\begin{figure}[h!]
  \centering
      \includegraphics[width=\textwidth]{immagini/tipi_algoritmi}
  \caption{Tipologie di FFT}
\end{figure}
%\includegraphics[scale=0.35]{tipi_algoritmi}
\vskip 10pt

\subsection{Cooley-Tukey Algorithm - DIT}

Il calcolo della DFT utilizzando la definizione richiede tempo $O(N^2)$, come \`e facilmente verificabile. Molti sono gli algoritmi studiati e progettati per ridurre questa complessit\`a computazionale.\\La DFT calcolata secondo questi algoritmi prende il nome di \textbf{Fast Fourier Transform} o \textbf{FFT}.\\Tra gli algoritmi studiati uno dei pi\`u famosi \`e l'algoritmo noto come Algoritmo di Cooley-Tukey con una delle sue implementazioni pi\`u frequenti che si articola in cinque fasi.\\

Dato un vettore $\mathbf{X}\in{}\mathbb{C}^n$, le cinque fasi dell'algoritmo di CT sono cos\`i articolate:
\begin{itemize}
\item Fase 1: il vettore di ingresso viene riorganizzato in forma matriciale pxq secondo un ordinamento row-major. Tipicamente o p o q \`e un fattore piccolo, non necessariamente primo, che \`e chiamato radice.\\Nelle pi\`u comuni implementazioni la DFT calcolata con l'algoritmo di Cooley-Tukey \`e di \textbf{radice 2} e, in particolare, se q \`e uguale a 2 si parla di decimazione in frequenza mentre se p \`e uaguale a 2 si parla di \textbf{decimazione nel tempo}.
\item Fase 2: q FFT vengono calcolate ricorsivamente sulle colonne della matrice ottenuta.
\item Fase 3: gli elementi della matrice risultante vengono moltiplicati per i twiddle factors, in particolare l'elemento di indice (i,j) viene moltiplicato per il fattore $\omega_n^{ij}$ ($i, j = 0,\ldots{},N-1$).
\item Fase 4: p FFT vengono calcolate ricorsivamente sulle righe della matrice risultante.
\item Fase 5: gli elementi della matrice vengono letti in ordine column-major al fine di ottenere il vettore finale.
\end{itemize}

Questo algoritmo \`e in grado di ridurre la complessit\`a computazionale a $O(Nlog_2N)$.\\

Gli algoritmi di decimazione radix-2 nel tempo si costituiscono a partire dalla seguente scomposizione ricorsiva.\\
Consideriamo un vettore $x$ di lunghezza $N=2^\nu$. Dividiamo i valori in ingresso in elementi di posizione pari e dispari\\
\[n = 
\begin{cases} 
2 \cdot r \\
2 \cdot r +1
\end{cases}\]

\subsubsection{Schema di scomposizione}

Sapendo che $\omega_N^2= \omega_{\frac{N}{2}}$, la componente $X_k$ della DFT può essere espressa come
\setlength{\jot}{17pt}{{\begin{align} 
X_k &=\sum_{n=0}^{N-1}x_n \omega_N^{nk} \qquad \text{con}\quad \omega_N=e^{-\jmath\frac{2\pi}{N}} \\
\label{eq:cooley-tukey-sommatorie-1}
&=\sum_{r=0}^{N/2-1}x_{2r} \omega_N^{2rk} + \sum_{r=0}^{N/2-1}x_{2r+1} \omega_N^{(2r+1)k}\\
\label{eq:cooley-tukey-sommatorie-2}
&=\underbrace{\sum_{r=0}^{N/2-1}x_{2r} \omega_{\frac{N}{2}}^{rk}}_{X_{even}} + \omega_N^{k} \underbrace{\sum_{r=0}^{N/2-1}x_{2r+1} \omega_{\frac{N}{2}}^{rk}}_{X_{odd}}\\
&=X_{even} \quad +\quad \omega_N^{k} \cdot X_{odd} \qquad k=0,1, ..., N-1
\end{align}}

Entrambe le sommatorie in \eqref{eq:cooley-tukey-sommatorie-2} possono quindi essere interpretate come DFT di taglia $N/2$: la prima coinvolge gli elementi in posizione pari $\{x_{2k}|k=0,1,...,N/2-1\}$ mentre la seconda gli elementi in posizione dispari $\{x_{2k+1}|k=0,1,...,N/2-1\}$. Ci siamo quindi ricondotti a due sottoproblemi analoghi a quello di partenza ma di daglia dimezzata.\\
Definiendo $y_r=x_{2r}$ e $z_r=x_{2r+1}$ e quindi le rispettive DFT
\begin{equation}
	Y_{k}=\sum_{r=0}^{\frac{N}{2}-1} y_r \omega_{\frac{N}{2}}^{rk}, \qquad k=0,1,...,N/2-1
\end{equation}
e
\begin{equation}
	Z_{k}=\sum_{r=0}^{\frac{N}{2}-1} z_r \omega_{\frac{N}{2}}^{rk}, \qquad k=0,1,...,N/2-1
\end{equation}
dopo che la soluzione di questi due problemi è stata ricorsivamente calcolata è possibile calcolare i primi $N/2$ termini di $X$ attraverso
\begin{equation}
\label{eq:CT-X_even}
	X_k= Y_k+\omega_N^k Z_k, \qquad k=0,1,...,N/2-1 
\end{equation}
e utilizzando il fatto che $\omega_N^{\frac{N}{2}+k}=-\omega_N^{k}$ e $\omega_{\frac{N}{2}}^{\frac{N}{2}}=1$, i rimanenti termini sono dati da:
\begin{align}
X_{k+\frac{N}{2}} &= \sum_{r=0}^{\frac{N}{2}-1} y_r \omega_{\frac{N}{2}}^{(r+\frac{N}{2})k}+\omega_{N}^{(k+\frac{N}{2})} \sum_{r=0}^{\frac{N}{2}-1} z_r \omega_{\frac{N}{2}}^{(r+\frac{N}{2})k}\\
&= \sum_{r=0}^{\frac{N}{2}-1} y_r \omega_{\frac{N}{2}}^{rk}+\omega_{N}^{k} \sum_{r=0}^{\frac{N}{2}-1} z_r \omega_{\frac{N}{2}}^{rk}\\
\label{eq:CT-X_odd}
&= Y_k-\omega_N^k Z_k, \qquad k=0,1,...,N/2-1
\end{align}
Solitamente le relazioni di calcolo espresse in \eqref{eq:CT-X_even} e \eqref{eq:CT-X_odd} sono graficamente rappresentate in un grafo computazione come \emph{"`Cooley-Tukey butterly"'}

\begin{figure}[h!]
  \centering
      \includegraphics[width=0.5\textwidth]{immagini/cooley-tukey-butterfly}
  \caption{Cooley-Tukey butterfly}
\end{figure}

\subsubsection{Complessità}
Il costo di ricombinazione è dato da $3N$ dovuto alla moltiplicazione per il "`twiddle factor"' e $2N$ dovuto alle somme. Pertanto risulta
\[T(N) =
\begin{cases} 
2T(\frac{N}{2}) + 5N & \text{se } N\geq 2 \\
0 & \text{se } N=1 
\end{cases}\]
e quindi
\begin{equation}
	T(N)= 5N\log(N)
\end{equation}

%!COMPLETARE!
%
% vedere se completare qui o dedicargli più spazio
% cooley-tukey N=pq paragrafo a parte?
%
%
 
\subsection{Gentleman-Sande Algorithm - DIF}
Una strategia leggermente diversa da quella dello schema di Cooley e Tukey sta alla base la versione dell'algoritmo FFT radix-2 introdotta da Gentleman e Sande. Tale variante si basa sul decomporre ripetutamente il vettore DFT da calcolare. Si osserva che le componoenti con indice pari della DFT si possono esprimere come una DFT di lunghezza $N/2$ costruita a partire da un vettore ottenuto combinando le componenti del vettore di input che distano di $N/2$. Analogo ragionamento si fa per le componenti con indice dispari della DFT da calcolare.

\subsubsection{Schema di scomposizione}
Se dividiamo gli $N=2^\nu$ elementi di $x_N$ nelle due sotto sequenze $x_{head}=(x_0,x_1,...,x_{\frac{N}{2}-1})$ e $x_{tail}=(x_{\frac{N}{2}},x_{\frac{N}{2}+1},...,x_{N-1})$, la DFT di $x_N$ si può scrivere nella forma

\setlength{\jot}{17pt}{\begin{align} 
X_k &=\sum_{n=0}^{N-1}x_n \omega_N^{nk} \qquad \text{con}\quad \omega_N=e^{-\jmath\frac{2\pi}{N}} \\
&=\sum_{n=0}^{N/2-1}x_n \omega_N^{nk} + \sum_{n=N/2-1}^{N-1}x_{n} \omega_N^{nk} \qquad \text{per} \quad n'=n-\frac{N}{2}\\
\label{eq:dft-dif-div}
&=\sum_{n=0}^{N/2-1}x_n \omega_N^{nk} + \sum_{n'=0}^{N/2-1}x_{\frac{N}{2}+n'} \omega_N^{(\frac{N}{2}+n')k} \qquad  \quad \omega_N^{N\frac{k}{2}}= (-1)^k\\
&=\sum_{n=0}^{N/2-1}\left[x_n  + (-1)^k x_{\frac{N}{2}+n}\right]
\end{align}}

Notiamo che la \eqref{eq:dft-dif-div} non è una DFT su $N/2$ punti in quanto è presente il termine $\omega_N^{nk}$ invece di $\omega_{\frac{N}{2}}^{nk}$

Procedendo separatamente con il calcolo dei valori di $X_k$ di posto pari $\left((-1)^K=1\right)$ e dispari $\left((-1)^K=-1\right)$ si ottiene


\setlength{\jot}{17pt}{\begin{align} 
X_{2r} &=\sum_{n=0}^{N/2-1}\left[\underbrace{x_n  + x_{\frac{N}{2}+n}}_{y_{n}}\right] \omega_{N/2}^{rn} \qquad r=0,1,...,N/2-1\\
X_{2r+1} &=\sum_{n=0}^{N/2-1}\left[(\underbrace{x_n  - x_{\frac{N}{2}+n}}_{z_{n}}) \omega_{N}^{n} \right] \omega_{N/2}^{rn}
\end{align}}

Il calcolo della DFT su $N=2^\nu$ punti viene quindi ricondotto a

\begin{enumerate}
	\item il calcolo di due segnali di lunghezza $N/2$ corrispondenti rispettivamente alla somma di $x_{head} +x_{tail}$ e alla differenza $x_{head}-x_{tail}$
	\setlength{\jot}{17pt}{\begin{align} 
	y_{n}&=x_{n}+x_{\frac{N}{2}+n} \qquad n=0,1,...,N/2-1\\
	z_{n}&=x_{n}-x_{\frac{N}{2}+n}
	\end{align}}
	che corrisponde a $N/2$ DFT su coppie punti, [$x_{n}$ $x_{\frac{N}{2}+n}$]. Infatti
	
			\begin{equation}
		F_2=
		\left(
		\begin{array}{cr}
		1 & 1\\1 & -1	
		\end{array}\right)
		\end{equation}
	\item alla moltiplicazione di $z_{n}$ per $\omega_{N}^{n}$
	\item al calcolo di due DFT su $N/2$ punti, una su $y_{n}$ e l'altra su $z_{n}\omega_{N}^{n}$
\end{enumerate}

Con l'algoritmo DIF quindi si precondizionano i dati dei due blocchi di lunghezza $N/2$ in modo che una trasformata su $N/2$ dati dia i valodi di $X_k$ per $k$ pari e l'altra sempre su $N/2$ dati dia i valori di $X_k$ per $k$ dispari.
Tutto il lavoro è quindi effettuato nel passo \emph{"`divide"'} che richiede di effettuare somma e sottrazione di coppie e moltiplicazione per il \emph{"`twiddle factor"'} mentre il passo \emph{"`conquer"'} è banale poichè l'output delle due trasformate, prese "`alternativamente"',fornisce immediatamente la trasformata dell'ingresso originale.

Solitamente il passo di suddivisione è graficamente rappresentato in un grafo computazione come \emph{"`Gentleman-Sande butterly"'}

\begin{figure}[h!]
  \centering
      \includegraphics[width=0.5\textwidth]{immagini/gentleman-sande-butterfly}
  \caption{Gentleman-Sande butterfly}
\end{figure}

\subsubsection{Complessità}

Il passo di suddivisione richiede $N$ addizioni complesse e $N/2$ moltiplicazioni complesse e pertanto anche in questo caso la complessità risulta $T(N)= 5N\log(N)$.
%!COMPLETARE!
%
% Manca analisi della complessità, dire che si usa sempre la radice N-esima dell'unità e che l'output è non ordinato (vedi slide), vedi mian pg 173
%
%
%
\subsection{Split-radix Algorithm}
L'idea che sta alla base dell'algoritmo Split-radix è quella di usare la decomposizione radix-2 e radix-4 contemporaneamente, ovvero il problema iniziale di taglia $N$ viene scomposto in un problema di taglia $N/2$ e 2 problemi di taglia $N/4$. La scomposizione di seguito è della tipologia DIT.

\subsubsection{Schema di scomposizione}
\begin{align}
X_r &= \sum_{l=0}^{N-1}{x_l\omega_N^{rl}}, \qquad r=0,1,...,N-1\\
&=\sum_{k=0}^{\frac{N}{2}-1}{x_{2k}\omega_N^{r(2k)}}+\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+1}\omega_N^{r(4k+1)}}+\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+3}\omega_N^{r(4k+3)}}\\
&=\sum_{k=0}^{\frac{N}{2}-1}{x_{2k}\omega_N^{r(2k)}}+\omega_N^{r}\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+1}\omega_N^{r(4k)}}+\omega_N^{3r}\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+3}\omega_N^{r(4k)}}
\end{align}
$x_N$ è quindi scomposto in 3 sottosequenze: $\{y_k|y_k= x_{2k}, 0\leq k \leq N/2-1\}$ , 
$\{z_k|z_k= x_{4k+1}, 0\leq k \leq N/4-1\}$ , $\{h_k|h_k= x_{4k+3}, 0\leq k \leq N/4-1\}$ e sono deviniti 3 sotto problemi sfruttando il fatto che $\omega_{\frac{N}{2}} = \omega_{N}^2$ e
$\omega_{\frac{N}{4}}= \omega_{N}^4$

\begin{equation}
Y_r=\sum_{k=0}^{\frac{N}{2}-1}{x_{2k}\omega_{N}^{r(2k)}} =\sum_{k=0}^{\frac{N}{2}-1}{x_{2k}{(\omega_{N}^{2})}^{rk}} =\sum_{k=0}^{\frac{N}{2}-1}{y_{k}\omega_{\frac{N}{2}}^{rk}}, \qquad r=0,1,... ,N/2-1
\end{equation}

\begin{equation}
Z_r=\sum_{k=0}^{\frac{N}{2}-1}{x_{4k+1}\omega_{N}^{r(4k)}} =\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+1}{(\omega_{N}^{4})}^{rk}} =\sum_{k=0}^{\frac{N}{4}-1}{z_{k}\omega_{\frac{N}{4}}^{rk}}, \qquad r=0,1,... ,N/4-1
\end{equation}

\begin{equation}
H_r=\sum_{k=0}^{\frac{N}{2}-1}{x_{4k+3}\omega_{N}^{r(4k)}} =\sum_{k=0}^{\frac{N}{4}-1}{x_{4k+3}{(\omega_{N}^{4})}^{rk}} =\sum_{k=0}^{\frac{N}{4}-1}{h_{k}\omega_{\frac{N}{4}}^{rk}}, \qquad r=0,1,... ,N/4-1
\end{equation}

dopo che ognuno dei tre sottoproblemi è stato risolto, ricordando che $Y_r$ è periodico di periodo $N/2$ e $Z_r$ e $H_R$ sono periodici di  $N/4$, la soluzione al problema originale di taglia N può essere ottenuta come:

\begin{align}
\label{eq:split-radix-conquer-1}
X_r &= Y_r+\omega_N^rZ_r+\omega_N^{3r}H_r \nonumber \\ 
&= Y_r+\left(\omega_N^rZ_r+\omega_N^{3r}H_r\right), \qquad 0\leq r\leq\frac{N}{4}-1,\\
\label{eq:split-radix-conquer-2}
X_{r+\frac{N}{4}} &= Y_{r+\frac{N}{4}}+\omega_N^{r+\frac{N}{4}}Z_r+\omega_N^{3({r+\frac{N}{4}})}H_r \nonumber\\
&= Y_{r+\frac{N}{4}}- j\left(\omega_N^{r}Z_r-\omega_N^{3r}H_r\right), \qquad 0\leq r\leq\frac{N}{4}-1,\\
\label{eq:split-radix-conquer-3}
X_{r+\frac{N}{2}} &= Y_{r}+\omega_N^{r+\frac{N}{2}}Z_r+\omega_N^{3({r+\frac{N}{2}})}H_r \nonumber\\
&= Y_{r}-\left(\omega_N^{r}Z_r+\omega_N^{3r}H_r\right), \qquad 0\leq r\leq\frac{N}{4}-1,\\
\label{eq:split-radix-conquer-4}
X_{r+\frac{3N}{4}} &= Y_{r+\frac{N}{4}}+\omega_N^{r+\frac{3N}{4}}Z_r+\omega_N^{3({r+\frac{3N}{4}})}H_r \nonumber\\
&= Y_{r+\frac{N}{4}}+ j\left(\omega_N^{r}Z_r-\omega_N^{3r}H_r\right), \qquad 0\leq r\leq\frac{N}{4}-1,
\end{align}

Le relazioni espresse in \eqref{eq:split-radix-conquer-1} \eqref{eq:split-radix-conquer-2} \eqref{eq:split-radix-conquer-3} \eqref{eq:split-radix-conquer-4} sono solitamente rappresentate in un grafo computazione come \emph{"`unsymmetric DIT split-radix butterly"'}
\vskip 10pt
\begin{figure}[h!]
  \centering
      \includegraphics[width=\textwidth]{immagini/split-radix-dit-butterfly}
  \caption{split-radix butterfly}
\end{figure}
Proprio questa struttura irregolare dello split-radix, sebbene non comporti problemi per le implementazioni sequenziali, rende molto difficile l'organizzazione del calcolo su sistemi paralleli.
%http://cnx.org/content/m12031/latest/#Bruun
       

\subsubsection{Complessità}
Essendo $Z_r$ e $H_r$ di taglia $N/4$ il calcolo dei prodotti $\omega_N^rZ_r$ e $\omega_N^{3r}H_r$ richiede in totale $N/2$ moltiplicazioni complesse e le somme parziali in \eqref{eq:split-radix-conquer-1} \eqref{eq:split-radix-conquer-2} \eqref{eq:split-radix-conquer-3} \eqref{eq:split-radix-conquer-4} richiedono in totale altre $N/2$ addizioni complesse.\\
Sfruttando le proprietà delle radici $\omega_N^{0}$, $\omega_N^{\pm\frac{N}{2}}$,$\omega_N^{\pm\frac{N}{4}}$, $\omega_N^{\pm\frac{N}{8}}$ $\omega_N^{\pm\frac{3N}{8}}$ è possibile ridurre ulteriormente il numero di moltiplicazioni complesse.\\
Riassumendo, il costo computazionale complessivo di una chiamata risorsiva è di $6N-16$ operazioni
Otteniamo quindi la relazione
\[T(N) =
\begin{cases} 
T(\frac{N}{2}) + 2T(\frac{N}{4})+6N-16 & \text{se } N=4^\nu > 4 \\
16 & \text{se } N=4\\
4 & \text{se } N=2\\ 
\end{cases}\]

\noindent e che, risolvendo, fornisce
\begin{equation}
	T(N)= 4N\log(N) -6N +8
\end{equation}
Il guadagno asintotico rispetto alle implementazioni radix-2 è quindi circa del 25\%.
\subsection{Altri Algoritmi}

\subsubsection*{Goertzel's Algorithm} %fft-lecture.pdf
Questo algoritmo, implementato come filtro IIR, è utilizzato in DSP quando si è interessati a conoscere solo alcune delle componenti in frequenza $X_k$ di una sequenza $x_N$

\begin{align*}
	X_{k} &\stackrel{\text{\emph{def}}}{=} \sum_{n=0}^{N-1} x[n] \omega_N^{nk} = 1 \cdot \sum_{n=0}^{N-1} x[n] \omega_N^{nk}, \quad \text{con}\quad \omega_N^{-kN}=1\\
	&= \omega_N^{-kN} \sum_{n=0}^{N-1} x[n] \omega_N^{nk} = \sum_{n=0}^{N-1} x[n] \omega_N^{-k(N-n)}\\
	\left.y_k[n]\right|_{n=N}&= \left.\left[x[n]\ast \left( \omega_N^{-nk} u[n]\right)\right]\right|_{n=N}
\end{align*}
che è una convoluzione discreta.
\begin{equation*}
	x[n] \longrightarrow \fbox{$h[n]=\omega_N^{-nk} u[n]$} \longrightarrow y_k[n]
\end{equation*}
L'algoritmo, espresso come equazione alle differenze del primo ordine, fornisce
\begin{equation*}
	y_k[n] = x [n] +  \omega_N^{-k} y_k[n-1]  \quad \text{con} \quad y_k[-1]=0
\end{equation*}
Notiamo che $x[n]$ è definito solo per $0\leq n \leq N-1$ e perciò $x[N]=0$ e che per calcolare la $k$-esima componente $X_k$  si utilizza solo la radice $\omega_N^{-k}$.
Il calcolo di $X_k$ richiede tempo $O(N)$. Quindi per calcolare tutta la DFT si ha complessità $O(N^2)$. Tuttavia se si è interessati solo a $M$ frequenze risulta vantaggiosa rispetto agli algoritmi FFT $O(N \log2(N))$ fin tanto che $ M\leq\log2(N)$
%
% propagazione errore veloce....
%
%

\subsubsection*{Good-Thomas - Prime Factor Algorithm} %fft-lecture.pdf
Il \emph{Prime Factor Algorithm (PFA)}, anche chiamato \emph{Good-Thomas algorithm}, permettere di ridefinire una FFT con $N=N_1\times N_2$ come \emph{DFT bidimensionali} $N_1\times N_2$, ma solo nel caso che $N_1$ e $N_2$ siano \emph{coprimi}. La valutazione di queste DFT di taglia $N_1$ o $N_2$ può essere effettuato applicando ricorsivamente PFA stesso, se possibile, o qualunque altro algoritmo FFT.
Avere $N_1$ e $N_2$ coprimi permette di individuare facilmente una funzione biettiva per ri-indicizzare l'input e l'output di \eqref{eq:def-dft}.
Ciò ci permette di scrivere
\begin{align}
n &=n_1 N_2 + n_2 N_1  \mod N,\\ \nonumber
k &= k_1 N_2^{-1} N_2 + k_2 N_1^{-1} N_1 \mod N,\\
X_{k_1 N_2^{-1} N_2 + k_2 N_1^{-1} N_1} &=\sum_{n_1=0}^{N_1-1} \left( \sum_{n_2=0}^{N_2-1} x_{n_1 N_2 + n_2 N_1}e^{-\frac{2\pi i}{N_2} n_2 k_2 } \right)e^{-\frac{2\pi i}{N_1} n_1 k_1 }.
\end{align}
dove $N_1^{-1}$ è l'inverso di $N_1$ in aritmetica modulo $N_2$ e analogamente per $N_2^{-1}$.
La complessità dopo la scomposizione è $N\cdot (N_1+N_2)$ e iterando $O(N\log(N))$. Il numero di operazioni complessive è confrontabile con quello dello split-radix ma il numero di moltiplicazioni globale è inferiore.

\section{Algoritmi paralleli per il calcolo di FFT}

Gli algoritmi fino a questo momento presentati sono algoritmi prettamente sequenziali che, se pur diminuendo notevolmente la complessit\`a di calcolo rispetto all'algoritmo di base, non sfruttano il fatto che il calcolo della FFT presenta un elevato grado di parallelismo, che pu\`o essere sfruttato al meglio in presenza di pi\`u processori a patto di progettare algoritmi corretti ed adeguati alle risorse di sistema presenti.\\

Non \`e scopo di questa relazione discutere approfonditamente l'argomento ma \`e utile fornire comunque una panoramica sulla struttura e l'efficienza di due algoritmi paralleli molto utilizzati nel calcolo della FFT, il primo dei quali utilizza una struttura nota come rete ascendente per il calcolo mentre il secondo \`e un'opportuna rivisitazione dell'algoritmo gi\`a presentato di Cooley-Tukey.
Quest'ul\-ti\-mo algoritmo \'e stato realizzato utilizzando il linguaggio di programmazione C e testato su due diversi input su un'apposita macchina parallela a pi\`u vie, l'IBM RS/6000 di propriet\`a del Dipartimento di In\-ge\-gne\-ria dell'Informazione dell'U\-ni\-ver\-sit\`a di Padova. Le simulazioni sono state effettuate utilizzando una libreria pro\-prie\-ta\-ria IBM, di nome \emph{hmp Count}, in grado di accedere ai contatori hardware della macchina in questione. Le librerie utilizzate per le comunicazioni inter-processo sono le librerie standard MPI.\\Nella discussione che segue viene indicata con $n$ la lunghezza del vettore di ingresso e con \emph{size} il numero totale di processi utilizzati (numerati da $0$ a $size-1$).

\subsection{Primo algoritmo: Computazione in rete ascendente}
In questa sezione viene presentato il primo algoritmo che calcola la FFT utilizzando una rete ascendente (rete $\Omega^{-1}$) con i collegamenti tra le linee che rappresentano i cosiddetti operatori \emph{butterfly} (Figura 2.5).
\begin{figure}[h!]
\centering
\includegraphics[width=13cm,height=5cm]{immagini/rete-ascendente.eps}
\caption{Esempio di rete ascendente con 8 linee e illustrazione di un \emph{butterfly operator}. In figura il simbolo $\omega{}i$ rappresenta $\omega^i$.}
\end{figure}\\
Su ogni linea all'ingresso della rete va posto un elemento del vettore di ingresso, ed ogni processo \`e responsabile di una o pi\`u linee a seconda del numero di processi lanciati. Per semplicit\`a si assume che il numero di linee (e quindi la dimensione n del vettore di ingresso), cos\`i come il numero di processi, sia sempre una potenza di due con ovviamente il vincolo che il numero di processi sia minore o uguale ad n.

Nell'implementazione dell'algoritmo i dati di ingresso (elementi del vettore $\mathbf{X}$) vengono letti da un file di input dove ogni valore, composto dalla sua parte reale e dalla parte immaginaria, \`e scritto su una riga separata. Il processo 0 \`e il processo che si occupa sempre di leggere i valori di ingresso e salvarli opportunamente in un array \emph{double} di dimensione doppia rispetto alla dimensione del vettore $\mathbf{X}$, dato che la sistemazione dei valori all'interno dell'array avviene in maniera tale che l'elemento i-esimo abbia la sua parte reale salvata in posizione $2*i$ e la parte immaginaria in posizione $2*i+1$ nell'array di input.\\Successivamente, completata l'acquisizione, il processo 0 esegue un riordinamento \emph{bit-reversing} dei dati sulle linee ed infine esegue un broadcast dell'intero contenuto dell'array verso i rimanenti processi\footnote{L'acquisizione dei valori di ingresso potrebbe essere gestita meglio con le librerie MPI-IO, che avrebbero consentito ai vari processi l'accesso simultaneo al file di input. Tuttavia le suddette librerie non sono sempre disponibili sulle macchine parallele, per questo motivo si \`e presentato questo tipo di strategia cre prevede il broadcast.}.

Dopo questa prima fase, ogni processo calcola indipendentemente i twiddle factors che saranno necessari durante la computazione. Ogni processo calcola gli stessi twiddle factors, in particolare le potenze di $\omega_n$ necessarie e calcolate vanno da $\omega_n^0$ a $\omega_n^{\frac{n}{2}-1}$.\\

Fatto ci\`o la computazione vera e propria ha inizio: essa si compone di $log_2(n)$ passi dove ogni passo coincide con un ``settore'' della rete ascendente. All'inizio di ogni passo ogni processo, se necessario, prima di effettuare qualunque calcolo esegue la primitiva non bloccante \verb+MPI_Irecv+ un numero di volte pari al numero di linee che gestisce al fine di preparare il buffer di ricezione per i dati che verranno ricevuti dai dovuti \emph{peers} al termine del passo. Conseguentemente, al termine di ogni passo e prima dell'inizio del successivo, se necessario ogni processo invia il/i dato/i calcolato/i durante il passo appena terminato al peer opportuno utilizzando una primitiva non bloccante \verb+MPI_Isend+. Prima del passaggio al passo successivo ogni processo attende il completamento delle operazioni di ricezione dati avviate all'inizio del passo precedente, dato che ovviamente tali dati saranno necessari per le prossime fasi.\\Al termine della computazione, infine, ogni processo invia al processo 0 i dati appartenenti alle linee di propria competenza affinch\`e vengano posti in un array comune ed infine visualizzati.

\subsection{Secondo algoritmo: Adattamento dell'algoritmo standard di Cooley-Tukey}

L'implementazione \emph{divide and conquer} tradizionale dell'algoritmo di CT richiede sostanzialmente cinque fasi per calcolare correttamente la FFT.\\
Nella versione parallela proposta le suddette cinque fasi sono state cos\`i adattate:
\begin{itemize}
 \item Fase 1: il vettore di ingresso $\mathbf{X}$, che per semplicit\`a si assume avere un numero pari ad una potenza di due, con esponente pari, di elementi, \`e riorganizzato idealmente in forma matriciale di tipo $\sqrt{n}$ x $\sqrt{n}$. Tale matrice \`e poi suddivisa secondo un layout organizzato per righe tra i vari processi disponibili (Figura 1.2). Si assume, conseguentemente, che il numero di processi totali \`e minore o uguale a $\sqrt{n}$. 
Dal punto di vista implementativo le righe di cui ogni processo \`e responsabile sono salvate consecutivamente in un array A, di dimensione $2*n/size$ dove \emph{size} \`e il numero di processi disponibili ed il coefficiente moltiplicativo 2 \`e dovuto al modo con cui vengono salvati i valori complessi, analogamente a quanto illustrato nel precedente algoritmo.
\item Fase 2: viene effettuata una prima trasposizione matriciale globale atta a fare in modo che ogni processo conservi nel proprio array locale A un numero pari a $\sqrt{n}/size$ colonne della matrice globale. In questo modo ogni processo pu\`o poi effettuare la FFT, sulle colonne di competenza, localmente, senza richiedere ulteriori comunicazioni inter-processore.
\item Fase 3: al termine della FFT calcolata sulle colonne, ogni processo moltiplica i propri elementi di competenza per i corrispondenti twiddle factors. Si noti a tal proposito che le potenze di $\omega_n$ che ogni processo calcola indipendentemente all'inizio dell'algoritmo vanno da $\omega_n^{0}$ a $\omega_n^{{(\sqrt{n}-1)}^2}$.
\item Fase 4: la quarta fase richiede una nuova trasposizione matriciale atta a trasferire localmente ad ogni processo le dovute $\sqrt{n}/size$ righe della matrice ideale su cui poi poter eseguire nuovamente un totale di $\sqrt{n}/size$ FFT locali, analogamente a quanto fatto per le colonne alla Fase 2.
\item Fase 5: completata la Fase 4 viene eseguita un'ultima trasposizione matriciale atta a trasferire ad ogni processo le colonne di competenza della matrice ideale. In questo modo la lettura dei valori finali, che come noto deve essere effettuata in ordine column-major, risulta pi\`u semplice dato che \`e sufficiente che tutti i processi comunichino al processo 0 i dati in loro possesso, quindi che 0 li disponga nell'ordine opportuno nel proprio array A (i $2*n/size$ elementi del processo i andranno di\-spo\-sti consecutivamente a partire dalla posizione $2*n*i/size$ nell'array finale) e che, infine, li visualizzi poi semplicemente scandendo l'array.
\end{itemize}

\begin{figure}[h!]
\centering
\includegraphics[width=10cm,height=5cm]{immagini/CT-processi.eps}
\caption{Esempio di suddivisione di una matrice 4x4 tra 4 processi secondo il layout proposto.}
\end{figure}
Come nel precedente algoritmo, anche in questo la raccolta dei valori iniziali e la distribuzione opportuna ai vari processi avviene ad opera del processo 0. Un'importante differenza \`e data dalla quantit\`a di dati distribuiti: se nel primo algoritmo il processo 0 effettuava un broadcast dell'intero array ini\-zia\-le verso tutti i processi, in questa versione 0 distribuisce soltanto i valori strettamente necessari ad ogni processo, ovvero un totale di $2*n/size$ valori.\\

Appare chiaro, dalla descrizione effettuata, che questo algoritmo richiede comunicazioni tra i processi solo durante le trasposizioni matriciali. Durante la singola trasposizione ogni processo deve inviare e ricevere un totale di $2*(n/size - n/size^2)$ valori double, essendo $2*n/size$ il totale di elementi che sono contenuti nell'array locale e $2*{(\sqrt{n}/size)}^2$ gli elementi che rimangono nel pool locale (ovvero il numero di colonne di competenza del processo elevato al quadrato) durante la trasposizione. L'algoritmo di trasposizione implementato, invocato contemporaneamente da tutti i processi, opera scandendo l'array a disposizione di ogni processo e determinando, sulla base dell'ID del processo (e quindi della disposizione dei suoi dati nella matrice ideale globale) se il singolo elemento, dopo la trasposizione, apparterr\`a ancora al pool di competenza del medesimo processo oppure se \`e richiesta una comunicazione con un peer. In quest'ultimo caso l'ID del peer viene determinato ed il valore inviatogli con l'uso della primitiva \verb+MPI_Isend+. Chiaramente, ad ogni elemento inviato corrisponde un elemento che deve essere ricevuto dallo stesso peer, perci\`o il processo si mette in attesa della ricezione con la primitiva \verb+MPI_Irecv+. In questa implementazione \`e fondamentale l'uso di primitive non bloccanti, a differenza del precedente algoritmo, in virt\`u del fatto che l'ordine di determinazione dei peers da parte dei processi che devono comunicare non \`e lo stesso, ovvero non \`e detto che se il processo i, arrivato alla scansione dell'elemento k nel proprio array di competenza, ha richiesto l'invio di A[k] al processo j, a sua volta j si sia messo in attesa della ricezione, anzi pu\`o capitare che j abbia richiesto a sua volta l'invio di un altro valore ad un altro processo. Tutto ci\`o, se usate primitive bloccanti, porterebbe a \emph{deadlock}.\\
\`E anche importante osservare che i valori scambiati tra due processi i e j (valori che possono essere in numero superiore ad 1) non occupano le stesse posizioni relative all'interno dei singoli array perci\`o \`e indispensabile fare un uso attento dei \emph{tags} nelle comunicazioni al fine di non rischiare di confondere i dati ricevuti.\\

L'algoritmo utilizzato per il calcolo locale della FFT \`e il tradizionale algoritmo ricorsivo di natura D\verb+&+C che spezza l'array in due parti uguali, calcola ricorsivamente su queste parti la FFT, e ricompone correttamente in un unico array il tutto.


\subsection{Analisi delle prestazioni}
Le simulazioni svolte consistono nel calcolo della FFT con il secondo algoritmo parallelo proposto su vettori di elementi casuali di lunghezza pari a $2^8$ e $2^{12}$.\\

La seguente tabella mostra, quindi, l'andamento del WCT (in secondi) ed il numero di istruzioni eseguite dal secondo algoritmo. La tabella \'e ordinata secondo il numero di processi utilizzati (nell'ordine 1, 2, 4, 8 e 16):
\begin{center}
\begin{tabular}{|c|c|}
\hline
 & FFT (WCT / N. Ist.) \\
\hline
$2^8$ & $0.0014$ / 388817 \\
\hline
$2^{12}$ & $0.0278$ / 7927024 \\
\hline
\end{tabular}

\begin{tabular}{|c|c|}
\hline
 & FFT (WCT / N. Ist.) \\
\hline
$2^8$ & $0.0030$ / 781344 \\
\hline
$2^{12}$ & $0.0748$ / 19849491 \\
\hline
\end{tabular}

\begin{tabular}{|c|c|}
\hline
 & FFT (WCT / N. Ist.) \\
\hline
$2^8$ & $0.0023$ / 574317 \\
\hline
$2^{12}$ & $0.0444$ / 11983612 \\
\hline
\end{tabular}

\begin{tabular}{|c|c|}
\hline
 & FFT (WCT / N. Ist.) \\
\hline
$2^8$ & $0.0018$ / 560944 \\
\hline
$2^{12}$ & $0.0224$ / 7265946 \\
\hline
\end{tabular}

\begin{tabular}{|c|c|}
\hline
 & FFT (WCT / N. Ist.) \\
\hline
$2^8$ & $0.0013$ / 452222 \\
\hline
$2^{12}$ & $0.0098$ / 4679321 \\
\hline
\end{tabular}
\end{center}

\'E possibile considerare che l'algoritmo proposto \`e molto efficiente in ambito sequenziale (un processo) sia in termini di numero di istruzioni eseguite che di WCT. Tuttavia le cose cambiano anche notevolmente se si aumenta il numero di processi: con due processi si verifica un aumento del numero di istruzioni eseguite dal singolo processo rispetto al caso precedente. Ci\`o si spiega in parte con il fatto che, in presenza di due o pi\`u processi, l'algoritmo deve eseguire un numero molto maggiore di istruzioni, dovendo predisporre i dati necessari alle comunicazioni da effettuare per le trasposizioni matriciali (si pensi al gi\`a citato calcolo dei \emph{tags} e alla determinazione del peer con cui comunicare).

Le comunicazioni crescono con l'aumentare della dimensione del pool di elementi di competenza del singolo processo ed \`e questo il motivo per cui l'effetto descritto \`e parzialmene mitigato dall'aumentare del numero di processi, ovvero con la diminuzione sia della dimensione del pool di competenza del singolo processo, che del numero di invocazioni delle funzioni MPI che il processo deve eseguire.\\

Il fenomeno descritto sarebbe del tutto assente nel secondo algoritmo: infatti, nel primo algoritmo \`e quasi immediata la determinazione del peer con cui comunicare e non vi \`e bi\-so\-gno, per il modo in cui \`e strutturato l'algoritmo stesso, di tag diversi tra loro nelle comunicazioni. Tuttavia, quando il numero degli elementi del vettore di ingresso aumenta troppo ed il numero dei processi \`e superiore ad uno ma non ele\-va\-to l'alto numero di buffer pre\-di\-spo\-sti per le comunicazioni inciderebbe in maniera notevolissima sulle prestazioni, causando un notevole degrado della performance.\\

Concludendo, quindi, si pu\`o dedurre che la prima versione dell'algoritmo per il calcolo della FFT \`e consigliabile solo in presenza di grandi vettori di input e pochi processi a disposizione (purch\`e pi\`u di uno) mentre la seconda versione dell'algoritmo \`e teoricamente tanto pi\`u efficiente, in presenza di comunicazioni inter-processore, quanto pi\`u il rapporto tra dimensione del vettore di ingresso e numero dei processi tende a 0.


\chapter{Stabilità Numerica}
Fin'ora abbiamo trattato la \emph{discrete Fourier transform} e la \emph{fast Fourier transform} pensando che potessero idealmente essere calcolate con assoluta precisione.\\
Tuttavia i calcolatori reali utilizzano parole di lunghezza finita e quindi anche i numeri e le operazioni aritmetiche sono soggetti ai limiti della 	\emph{rappresentazione in virgola mobile}.\\
E' fondamentale infatti che un algoritmo, oltre ad essere veloce, sia anche stabile quando opera in un contesto in virgola mobile con errore di arrotondamento $u$.\\
Mostreremo quindi come DFT e FFT siano estremamente sensibili rispetto alla precisione con cui vengono precalcolati i \emph{twiddle factors}, quale rapporto intercorre tra l'errore con DFT e FFT e come, sotto opportune ipotesi, gli algoritmi FFT possano essere considerati stabili.

Utilizando un modello standard di aritmetica binaria reale a precisione finita \cite{higham} se $x$ e $y$ sono numeri complessi esattamente rappresentabili si assume che

%ROUNDOFF ERROR pg 565
\newtheorem{lemma}{Lemma}
\begin{lemma}\textbf{Modello di Wilkinson}
Siano $x,y \in \mathbb{C}$, allora
\begin{alignat}{3}
fl(x\pm y) = (x\pm y) (1+\delta) 	\qquad \qquad && |\delta| &\leq u\\
fl(x\ast y) = (x\ast y) (1+\delta) 	\qquad \qquad&& |\delta| &\leq \sqrt{2}\frac{2u}{1-2u}=2\sqrt{2}u+ O(u^2)\\
fl(x\div y) = (x\div y) (1+\delta) 	\qquad \qquad && |\delta| &\leq \sqrt{2}\frac{4u}{1-4u}=4\sqrt{2}u+ O(u^2)\\
\end{alignat}
\end{lemma}

dove $\delta\approx 2^{-b}$ con $b$ lunghezza della mantissa.
Indichiamo con $\mathbf{\hat{z}}$ il risultato ottenuto da $fl(x \circ y)$ mentre con $\mathbf {z}$ il risultato esatto di $(x \circ y)$ dove l'operazione $\circ \in\{+,-,\cdot,\div\}$\\
\noindent Si suppone inoltre che gli esponenziali complessi $\omega_k$ siano pre-calcolati e su di essi sia stato commesso un errore $|\epsilon_{ik}|$ tale che:

\begin{equation*}
\hat{\omega}_j^k= fl(\omega_j^k)=\omega_j^k+\epsilon_{jk} \qquad |\epsilon_{jk}|\leq u
\end{equation*}

Generalmente, per lo standar IEEE 754, operando in doppia precisione, la mantissa è lunga 52 bit per cui $u\approx 2.22 \times 10^{-16}$
\section{Worst Case Error DFT}

\newtheorem{lemma2}[lemma]{Lemma}
\begin{lemma2}\label{wilkinson}
\textbf{(di Wilkinson)}
Se $\mathbf{A}$ è una matrice reale $p \times q$, $\mathbf{B}$ è una matrice reale $q \times r$ e  $b$ è il numero di bit della mantissa, Allora
\begin{equation}
\left\|{fl(\mathbf{AB})-\mathbf{AB}}\right\|_2\leq 1.06 \cdot q\cdot 2^{-b} \left\|\mathbf{A}\right\|_2 \left\|\mathbf{B}\right\|_2
\end{equation}
\end{lemma2}
\vskip 15pt
\newtheorem{Teorema}{Teorema}
\begin{Teorema} \textbf{(Gentleman-Sande)}\label{Teorema:bound-dft}
Se si utilizza la definizione di DFT per calcolare la trasformata di Fourier discreta $\mathbf{X}$ di una sequenza $\mathbf{x}$ di lunghezza $N$ in aritmetica a virgola mobile a lunghezza di parola costante con mantissa di $b$ bit, Allora
\begin{equation}
\left\|\mathbf{\hat{X}-X}\right\|_2\leq 1.06 \;{(2N)}^{3/2} 2^{-b} \left\|\mathbf{X}\right\|_2
\end{equation}
\end{Teorema}
\begin{proof}
Il calcolo per definizione della DFT è esprimibile attraverso una matrice $\mathbf{F} \in \mathbb{C}^{N \times N}$ dove $$\mathbf{F}_{i,j} =(\omega_N^{ij})_{i,k=0}^{N-1}$$
\begin{equation}
	\mathbf{\hat{x}}=\mathbf{F}\mathbf{x}
\end{equation}
$\mathbf{x}$ può essere visto come $\mathbf{x}={\rm Re}(\mathbf{x})+i{\rm Im}(\mathbf{x}) \leftrightarrow [{\rm Re}(\mathbf{x}), {\rm Im}(\mathbf{x})]$, vettore di lunghezza $2N$
Per definizione
\begin{align}
\label{eq:def-dft}
X_k&=\sum_{n=0}^{N-1}x_ne^{-\jmath\frac{2\pi}{N}kn} \quad k=0,...,N-1\\
&= \sum_{n=0}^{N-1}({\rm Re}(x)+\jmath{\rm Im}(x)) \left[ \cos\left( \frac{2\pi}{N}kn\right) - \jmath \sin \left(\frac{2\pi}{N}kn\right)\right]
\end{align}
Le operazioni complesse possono quindi essere espresse come operazioni reali attraverso una matrice $2N \times 2N$:
\[ \begin{bmatrix}
  {\rm Re}(\mathbf{\hat{x}}) \\
	{\rm Im}(\mathbf{\hat{x}})
 \end{bmatrix}= 
 \begin{bmatrix}
  \mathbf{C} & -\mathbf{S} \\
  \mathbf{S} & \mathbf{C}
 \end{bmatrix}
  \begin{bmatrix}
  {\rm Re}(\mathbf{x}) \\
	{\rm Im}(\mathbf{x}) \end{bmatrix} = \mathbf{\Phi}
  \begin{bmatrix}
  {\rm Re}(\mathbf{x}) \\
	{\rm Im}(\mathbf{x}) \end{bmatrix}
\]
dove $\mathbf{C}_{i,j}=\cos\left(\frac{2\pi i j}{N}\right)$ e $\mathbf{S}_{i,j}=\sin\left(\frac{2\pi i j}{N}\right)$. Inoltre la norma 2 della matrice è

\begin{align*}
 \left\|\mathbf{\Phi}\right\|_2&=\sqrt{\sum_{i=0}^{N-1}\sum_{j=0}^{N-1}\left\{ \cos^2\left(\frac{2\pi ij}{N}\right) +\sin^2\left(\frac{2\pi ij}{N}\right)+\cos^2\left(\frac{2\pi ij}{N}\right)+\sin^2\left(\frac{2\pi ij}{N}\right) \right\}}\\
 &=\sqrt{2N^2}
\end{align*}
\begin{align*}
\Phi^*\Phi= \underbrace{\begin{bmatrix}
1 & 0 & ... & 0\\ 0 & 1 & ... & 0\\ \vdots & \vdots & \ddots & \vdots\\ 0 & 0 & ... & 1\\
\end{bmatrix}}_{2N} \longrightarrow \left\|\Phi^*\Phi \right\|_2=\sqrt{2N}
\end{align*}
\begin{equation}
\mathbf{X} = \Phi \mathbf{x} \longrightarrow \left\|\mathbf{X}\right\|_2=\frac{\left\|\Phi \right\|_2}{\left\|\Phi^*\Phi \right\|_2}\left\|\mathbf{x} \right\|_2 = \frac{\sqrt{2}N}{\sqrt{2N}}\left\|\mathbf{x} \right\|_2=\sqrt{N} \left\|\mathbf{x}\right\|_2
\end{equation}

Applicando il \emph{Lemma di Wilkinson} con, nel nostro caso $q=2N$, $\left\|\mathbf{\Phi}\right\|_2=\sqrt{2} N$, ricordando che $\left\|\mathbf{X}\right\|_2=\sqrt N \left \| \mathbf{x} \right \|_2$
\begin{align*}
\left\|{fl(\mathbf{\Phi x})-\mathbf{\Phi x}}\right\|_2&\leq 1.06 \cdot q \cdot 2^{-b} \left\|\mathbf{\Phi}\right\|_2 \left\|\mathbf{x}\right\|_2\\ 
\left\|{fl(\mathbf{X})-\mathbf{X}}\right\|_2&\leq 1.06 \cdot 2N \cdot 2^{-b} \sqrt{2}N \frac{\left\|\mathbf{X}\right\|_2}{\sqrt{N}}\\ 
\left\|\mathbf{\hat{X}-X}\right\|_2&\leq 1.06 {(2N)}^{3/2} 2^{-b} \left\|\mathbf{X}\right\|_2
\end{align*}
\end{proof}

\section{Worst Case Error FFT}
\section{Confronto DFT FFT}
\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/errore-relativo-DFT-FFT}
  \caption{Norma 2 dell'errore tra $x_N$ e $\mathcal{F}^{-1}(\mathcal{F}(x_N))$}
\end{figure}

\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/Bound-DFT}
  \caption{Andamento dell'errore reale e dell'errore massimo per il calcolo della DFT attraverso definizione}
\end{figure}

\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/riepilogo-errore-DFT-FFT-bound}
  \caption{Riepilogo DFT FFT Bounds}
\end{figure}



%%
%
%  stabfinal.ps
%  oppure Computational frameworks for the fast fourier (van loan)
%  % tabella degli errori devi vari metodi
%%
\section{Calcolo dei \emph{twiddle factor}}
Nel calcolo della FFT riveste un'importanza cruciale l'accuratenzza con cui vengono calcolati i \emph{twiddle factors}. Tutte le moltiplicazioni complesse infatti coinvolgono elementi dell'input e \emph{twiddle factors} appunto.
In generale per il calcolo di una DFT di lunghezza N è necessario valutare $\omega_N^{0}$, $\omega_N^{1}$, ..., $\omega_N^{N-1}$.
Queste valutazioni comportano il calcolo di funzioni trigonometriche che sono operazioni piuttosto coste.
Presentiamo di seguito alcune famose tecniche per il calcolo dei \emph{twiddle factors}.\\

\noindent Per semplificare la trattazione degli algoritmi presentati non si terrà conto di considerazioni estremamente importanti importanti dal punto di vista implementativo che permettono di ridurre il numero di \emph{twiddle factors} da calcolare fruttando le proprietà delle radici ennesime dell'unità.
Infatti le radici dell'unità sono dispote sul cerchio immaginario in maniera regolare e questo permette, attraverso relazioni di simmetria, di ridurre di $1/8$ le valutazioni trigonometriche da effettuare.
Più in particolare, per $k=1,... ,N/8 $
\begin{align}
 \hat{\omega}_N^{\frac{N}{4}-k}=-i \overline{\hat{\omega}_N^{k}}, \quad &\text{simmetrie di $\pi/2$ tra i quadranti }\\ 
\hat{\omega}_N^{\frac{N}{4}+k}=-i\hat{\omega}_N^{k},\quad&\text{ I e IV,I e II}\\
\hat{\omega}_N^{\frac{N}{2}-k}=\overline{\hat{\omega}_N^{k}},\quad& \text{simmetrie rispetto asse y}\\
\hat{\omega}_N^{\frac{N}{2}+k}=-\hat{\omega}_N^{k} \quad&
\end{align} 
e inoltre , sfruttando la decomoposizione ricorsiva, $\omega_N^{kp}=w_{\frac{N}{k}}^p$ si può trarre vantaggio dal fatto che alcune radici sono già note\[ \hat{\omega}_N^{\frac{N}{8}}=\hat{\omega}_8=fl\left(\sqrt{2}/2\right)(1-i),\quad \hat{\omega}_N^{\frac{N}{4}}=\hat{\omega}_4=-i,\quad \hat{\omega}_N^{\frac{N}{2}}=\hat{\omega}_2=-1
\]

Queste conderazioni banalizzano alcune moltiplicazioni complesse riducendole a cambiamenti di segno e scambi tra parte reale ed immaginaria: questo si traduce in un numero minore di operazioni reali e pertanto, anche nella riduzione della propagazione degli errori di arrotondamento.
 \subsection{Metodo diretto}
 Consiste nella valutazione banale di ogni $\omega_N^k$ ed effettua 2N valutazioni trigonometriche
 
\begin{algorithm}[H]                      % enter the algorithm environment
\caption{Direct Call}          % give the algorithm a caption
\label{alg1}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
\REQUIRE $N = 2^\nu (\nu\geq3), \theta=2\pi/N$
\FOR{$k=1$ to $N$}
\STATE $\hat{\omega}_N^k \longleftarrow fl(\cos(k\theta)) - i fl(\sin(k\theta))$
\ENDFOR
\end{algorithmic}
\end{algorithm}

Se le funzioni $\cos$ e $\sin$ di libreria sono esatte allora
\begin{equation}
	|\hat{\omega}_N^j -\omega_N^j|=|\epsilon_{j}| \leq \sqrt{2}u/2 = O(u)
\end{equation}


\subsection{Moltiplicazione Ripetuta}
Si basa sulla scomposizione $\omega_N^k = \omega_N \times \omega_N^{k-1} $ ed effettua 2 valutazioni trigometriche e $(N-2)$ moltiplicazioni complesse

\begin{algorithm}[H]                      % enter the algorithm environment
\caption{Repeated Multiplication}          % give the algorithm a caption
\label{alg1}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
\REQUIRE $N = 2^\nu (\nu\geq3), \theta=2\pi/N$
\STATE $\hat{\omega}_N^0 \longleftarrow 1$
\STATE $\hat{\omega}_N \longleftarrow fl(\cos(\theta)) - i fl(\sin(\theta))$
\FOR{$k=2$ to $N-1$}
\STATE $\hat{\omega}_N^k \longleftarrow fl(\hat{\omega}_N \times \hat{\omega}_N^{k-1})$
\ENDFOR
\end{algorithmic}
\end{algorithm}

In questo caso $\hat{\omega}_N^j$ è il  risultato di $j-1$ moltiplicazioni e pertanto si ha che 
\begin{equation}
	|\epsilon_{j}| = O(ju)
\end{equation}

\subsection{Subvector Scaling}
L'idea alla base è la scomposizione 

\begin{align*}
[\underbrace{\omega_N^0,\omega_N^1,...,\omega_N^{\frac{N}{2}-1}}_{N/2},\underbrace{\omega_N^{\frac{N}{2}},\omega_N^{\frac{N}{2}+1}, ..., \omega_N^{N-1}}_{N/2}]=
[\underbrace{\omega_N^0,\omega_N^1,...,\omega_N^{\frac{N}{2}-1}}_{N/2},\omega_N^{\frac{N}{2}}\underbrace{\left(\omega_N^0,\omega_N^1,...,\omega_N^{\frac{N}{2}-1}\right)}_{N/2}]
\end {align*}
che comporta $2\log_2N$ valutazioni trigonometriche $\log_2N$addizioni reali e $2N$ moltiplicazioni complesse

\begin{algorithm}[H]                      % enter the algorithm environment
\caption{Subvector Scaling}          % give the algorithm a caption
\label{alg1}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
\REQUIRE $N = 2^\nu (\nu\geq3), \theta=2\pi/N$
\STATE $\hat{\omega}_N^0 \longleftarrow 1$
\STATE $\hat{\omega}_N \longleftarrow fl(\cos(\theta)) - i fl(\sin(\theta))$
\FOR{$j=1$ to $\nu-1$}
\STATE $u \longleftarrow 2^j \pi/N$
\STATE $\hat{\omega}_N^{2^j} \longleftarrow fl(\cos(u)) - i fl(\sin(u))$
\FOR{$k=1$ to $2^j-1$}
\STATE $\hat{\omega}_N^{k+2^j} \longleftarrow fl(\hat{\omega}_N^{2^j} \times \hat{\omega}_N^{k})$
\ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}

In questo caso $\omega_N^j$ è il risultato di circa $\log_2(j)$ moltiplicazioni di fattori calcolati attraverso direct call. Pertanto l'errore risulta essere: 
\begin{equation}
	|\epsilon_{j}| = O(\log_2(j)u)
\end{equation}


\subsection{Forward Recursion}
Questo metodo è presentato per completezza come esempio di metodo numericamente instabile. Il metodo discende da:
\begin{align}
\cos(A+B) + \cos(A-B) &= 2 \cos(A) \cos(B)\\
\sin(A+B) + \sin(A-B) &= 2 \sin(A) \cos(B)
\end{align}
da cui per $B=\theta$, $A=(j-1)\theta$
\begin{align}
\cos(j\theta) &= 2 \cos(\theta) \cos((j-1)\theta)-\cos((j-2)\theta)\\
\sin(j\theta) &= 2 \cos(\theta) \sin((j-1)\theta)-\sin((j-2)\theta)
\end{align}

\begin{algorithm}[H]                      % enter the algorithm environment
\caption{Forward Recursion}          % give the algorithm a caption
\label{alg1}                           % and a label for \ref{} commands later in the document
\begin{algorithmic}                    % enter the algorithmic environment
\REQUIRE $N = 2^\nu (\nu\geq3), \theta=2\pi/N$
\STATE $\hat{\omega}_N^0 \longleftarrow 1$
\STATE $\hat{\omega}_N \longleftarrow fl(\cos(\theta)) - i fl(\sin(\theta))$
\STATE $\tau \longleftarrow fl(2\cos(\theta))$
\FOR{$j=1$ to $N-1$}
\STATE $\hat{\omega}_N^{k} \longleftarrow fl(\tau \hat{\omega}_N^{k-1}-\hat{\omega}_N^{k-2})$
\ENDFOR
\end{algorithmic}
\end{algorithm}

Il metodo comporta 2 valutazioni trigonometriche, $2N-1$ moltiplicazioni reali e $2(N-1)$ addizioni reali\\ 
In questo caso l'errore viene amplificato ad ogni step di $|\tau|=|2\cos(\theta)|$ che per $N\geq 6$ risulta già maggiore di 1.
\begin{equation}
	|\epsilon_{j}| = O(\tau^ju)
\end{equation}

\begin{table}[H]
  \caption{Riepilogo errori di arrotondamento per \emph{twiddle factors}}
  \begin{center}
\begin{tabular}{ll}
\toprule
\multicolumn{1}{c}{\emph {Metodo}} & \multicolumn{1}{c}{\emph{Errore in} $w_N^j$}  \\
\midrule
Direct Call & $O(u)$\\
Repeated multiplication & $O(uj)$\\
Subvector Scaling & $O(u\log j)$\\
Forward Recursion & $O(uc^j)$\\
\bottomrule
\end {tabular}
\end{center}
\end{table}

\subsection{Verifica sperimentale}
I seguenti grafici illustrano l'errore ottenuto con i diversi metodi per il calcolo dei \emph{twiddle factor}.
Sono stati ottenuti generando in matlab un vettore casuale di lughezza $N=2^k$ con distribuzione uniforme e valori compresi tra 0 e 1. A questi vettori è stata quindi applicata FFT e IFFT con i vari metodi e quindi calcolato l'errore relativo$$ \frac{\left\|\text{IFFT}(\text{FFT}(x)) \right\|}{\left\|x\right\|}$$

Nel grafico \ref{tf:dc-rm-vs} sono riepilogati gli andamenti dei vari metodi stabili.
Si noti come direct call e subvector scaling sono praticamente indistinguibili e l'errore sia poco influenzato dalla taglia mentre per repeated multiplication la crescita dell'errore è circa lineare nelle dimensioni dell'ingresso. 
\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/twiddle_factor_cd_rm_vs}
  \caption{Twiddle Factors DC - RM - VS}
  \label{tf:dc-rm-vs}
\end{figure}

L'errore tra DC-VS non è significativamente distinguibile mentre il numero di operazioni richieste da VS è decisamente inferiore.
\
\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/confronto-dc-vs}
  \caption{Confronto DC-VS}
\end{figure}

Il metodo Forward Recursion è instabile ed il suo errore lo rende inutilizzabile già per taglie di poblemi non banali $(N\geq8)$. Il grafico compara l'errore con Forward Recursion e quello della DFT con definizione.
\begin{figure}[H]
  \centering
      \includegraphics[width=\textwidth]{immagini/errore-fft_fr_dft}
  \caption{Errore esponenziale}
\end{figure}

\chapter{Applicazioni}
%
% MURLI
%
%
\section{N-FFT di due funzioni reali}

%
% anche dal mitra oppure Brigham cap 1p pg 166
%
%

Nell'applicazione della FFT spesso consideriamo solo funzioni reali del tempo mentre le funzioni in frequenza utilizzate nei calcoli sono, in generale, funzioni complesse. Pertanto, un comune programma in grado determinare la DFT e la sua inversa è scritto in modo da ricevere in input una forma d'onda complessa
\begin{equation}
	H(k)=\sum_{n=0}^{N-1}\left[ h_{Re}(n)+ jh_{Im}(n)\right] e^{-j\frac{2\pi k}{N}n}
\end{equation}
Sfruttando la proprietà \eqref{eq:inverse_computing_rule} per il calcolo dell'inversa è possibile riscrivere
\begin{equation}
	h(n)=\frac{1}{N}{\left[\sum_{k=0}^{N-1}{\left[ H_{Re}(k)+ jH_{Im}(k)\right]}^* e^{-j\frac{2\pi k}{N}n}\right]}^*
\end{equation}
e poichè entrambe contengono $e^{-j\frac{2\pi k}{N}n}$ lo stesso programma può essere usato per calcolare sia la trasformata diretta che la sua inversa.

Se i dati in ingresso sono reali allora la loro parte immaginaria risulterà essere nulla. Tuttavia poichè i programmi effettuano comunque le operazioni anche per i coefficienti posti a zero, otteniamo uno spreco di capacità di calcolo. Varie tecniche possono essere adottate per aumentare l'efficienza di calcolo di sequenze rali.
\\
Volendo infatti calcolare le trasformate di $g(n)$ e $h(n)$ è possibile considerare l'ingresso fittizio $y(n)=g(n)+j \cdot h(n)$, considerando in questo modo $g(n) = {\rm Re}(y(n))$ e $h(n) = {\rm Imm}(y(n))$.
Dopo aver eseguito la N-DFT $Y(k)$ di $y(n)$ è possibile ricavare le DFT di $g(n)$ e $h(n)$:
\begin{equation*}
	G[k] = \frac{1}{2} \left\{ X[k] + X^*[(-k)modN]\right \}
\end{equation*}
\begin{equation*}
	H[k] = \frac{1}{2j} \left\{ X[k] - X^*[(-k)modN]\right \}
\end{equation*}

%Per la linearità della DFT
%\begin{align*}
%Y(k)&= H(k)+jG(k)\\
%&=[H_r(n)+jH_i(n)] + j[G_r(n)+jG_i(n)]\\
%&=[H_r(n)-G_i(n)] + j [H_i(n)+G_r(n)]\\
%&={\rm Re}(n)+j{\rm Imm}(n)
%\end{align*}
%\section{Convoluzione lineare}

\section{Convoluzione ciclica}

\section{Moltiplicazione di polinomi}

\section{FFT N-dimensionale e immagini}



\include{appendice}
\include{bibliografia}
\end{document}